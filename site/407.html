
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 407 &#x2022; Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="/pagefind/pagefind-ui.css">
    <!-- Google Analytics -->
    <script>
        // Only load GA if consent is given
        function loadGA() {
            const script = document.createElement('script');
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-MDFXJY3FCY';
            script.async = true;
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }

            gtag('js', new Date());
            gtag('config', 'G-MDFXJY3FCY');
        }

        // Check if consent was previously given
        if (localStorage.getItem('cookieConsent') === 'accepted') {
            loadGA();
        }
    </script>
    <!-- End Google Analytics -->
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline underline"
               href="index.html"> Home </a><a
                aria-current="" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline " href="about.html">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>


<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-4061">
            <a href="https://ayende.com/blog/165091/strings-are-annoying" target="_blank">
                <h2 class="title mb-6" id="article-4061">Strings are annoying</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 13, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I hate a love/hate/hate relationship with .NET strings. That is because they are both incredibly convenient and horribly inefficient in a bad way. Let us look at the following file:      1: &quot;first_name&quot;,&quot;last_name&quot;,&quot;company_name&quot;,&quot;address&quot;,&quot;city&quot;,&quot;county&quot;,&quot;state&quot;,&quot;zip&quot;,&quot;phone1&quot;,&quot;phone2&quot;,&quot;email&quot;,&quot;web&quot;   2: &quot;James&quot;,&quot;Butt&quot;,&quot;Benton, John B Jr&quot;,&quot;6649 N Blue Gum St&quot;,&quot;New Orleans&quot;,&quot;Orleans&quot;,&quot;LA&quot;,70116,&quot;504-621-8927&quot;,&quot;504-845-1427&quot;,&quot;jbutt@gmail.com&quot;,&quot;http://www.bentonjohnbjr.com&quot;   3: &quot;Josephine&quot;,&quot;Darakjy&quot;,&quot;Chanay, Jeffrey A Esq&quot;,&quot;4 B Blue Ridge Blvd&quot;,&quot;Brighton&quot;,&quot;Livingston&quot;,&quot;MI&quot;,48116,&quot;810-292-9388&quot;,&quot;810-374-9840&quot;,&quot;josephine_darakjy@darakjy.org&quot;,&quot;http://www.chanayjeffreyaesq.com&quot;   4: &quot;Art&quot;,&quot;Venere&quot;,&quot;Chemel, James L Cpa&quot;,&quot;8 W Cerritos Ave #54&quot;,&quot;Bridgeport&quot;,&quot;Gloucester&quot;,&quot;NJ&quot;,&quot;08014&quot;,&quot;856-636-8749&quot;,&quot;856-264-4130&quot;,&quot;art@venere.org&quot;,&quot;http://www.chemeljameslcpa.com&quot;&#xA;Reading this is a simple matter of writing something like this:&#xA;&#xA;&#xA;   1: var headerLine = reader.ReadLine();   2: var headers = headerLine.Split(&#x27;,&#x27;).Select(h=&gt;h.Trim(&#x27;&quot;&#x27;)).ToArray();   3:&#xA0;    4: while(reader.EndOfStream == false)   5: {   6:     var line = reader.ReadLine();   7:     var columns = line.Split(&quot;,&quot;);   8:     var dic = new Dictionary&lt;string,string&gt;();   9:     for(var i=0;i&lt;headers.Length;i&#x2B;&#x2B;)  10:     {  11:         dic[headers[i]] = columns[i].Trim(&#x27;&quot;&#x27;);  12:     }  13:     yield return dic;  14: }&#xA;Now, let us look at the same code again, but this time, I marked places where we are doing string allocation:&#xA;&#xA;&#xA;   1: var headerLine = reader.ReadLine();   2: var headers = headerLine.Split(&#x27;,&#x27;).Select(h=&gt;h.Trim(&#x27;&quot;&#x27;)).ToArray();   3:&#xA0;    4: while(reader.EndOfStream == false)   5: {   6:     var line = reader.ReadLine();   7:     var columns = line.Split(&quot;,&quot;);   8:     var dic = new Dictionary&lt;string,string&gt;();   9:     for(var i=0;i&lt;headers.Length;i&#x2B;&#x2B;)  10:     {  11:         dic[headers[i]] = columns[i].Trim(&#x27;&quot;&#x27;);  12:     }  13:     yield return dic;  14: }&#xA;&#xA;Those are a lot of strings that we are allocating. And if we are reading a large file, that can very quickly turn into a major performance issue. If I was writing the same in C, for example, I would be re-using the allocated string multiple times, but here we&#x2019;ve to allocate and discard them pretty much continuously.&#xA;The really sad thing about it, it is incredibly easy to do this, usually without paying any attention. But even if you know what you are doing, you pretty much have to roll your own everything to get it to work. And that sucks quite badly.</p>
        </article>
        <article id="article-4062">
            <a href="https://benfoster.io/blog/aspnet-mvc-custom-error-pages/" target="_blank">
                <h2 class="title mb-6" id="article-4062">Custom error pages in ASP.NET MVC. Easy, right?</h2>
            </a>
            <p class="mb-2">by Ben Foster</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 11, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">If you&#x2019;ve ever struggled to configure custom error pages in ASP.NET MVC then this post is for you.</p>
        </article>
        <article id="article-4063">
            <a href="https://ayende.com/blog/165090/early-lock-release-transactions-and-errors" target="_blank">
                <h2 class="title mb-6" id="article-4063">Early lock release, transactions and errors</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 10, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">There has been quite a lot of research on the notion of early lock release as a way to improve database concurrency. For a while, Voron actually supported that, mostly because I thought that this is a good idea. Lately, however, I decided that it is anything but for modern databases. In short, this is how transactions behave:    Standard transaction Early Lock Release Transaction    Take locks Perform work Commit transaction in memory Flush transaction to log file Release locks Notify user that the transaction successfully completed   Take locks  Perform work  Commit transaction in memory  Flush transaction to log file async Release locks  Notify user that the transaction successfully completed when the log flush competes As you note, the major difference is when we release the locks. In the case of ELR, we release the locks immediately when start flushing the transaction state to log. The idea is that we don&#x2019;t need to wait for potentially length I/O to allow the next transaction to start running. However, we don&#x2019;t report the transaction as completed before we flushed the transaction. There is a tiny complication in there, the next transaction cannot start doing the async flushing to log before our transaction is also over, but that is fine and expected, anyway. However, what about error conditions? What happens if we&#x2019;ve started to flush the transaction to disk in an async manner, then we got an error. Well, the obvious thing to do here (and as called out in the paper) is to abort the transaction, and then abort any transaction that has started after the failed transaction released its locks. This is usually okay, because in general, that is no big deal at all. Aside from something like out of disk space errors (which can be resolved by pre-allocating the data), there aren&#x2019;t really any non catastrophic disk errors. So usually if the disk give you a hard time, it pretty much time to give up and go home. However, with the use of cloud computing, it is actually pretty common (however much it is a bad idea) to have a &#x201C;networked disk&#x201D;. This means that it can certainly be the case that a I/O request you made to the disk can get lost, delayed and just appear to fail (but actually go through). It is the last scenario in particular that worries me. If you actually wrote to the log, but you think that you didn&#x2019;t, what is your state now? And while I can handle that in a case where I can fail the transaction and rollback all the previous state, it is much harder to do that if I&#x2019;ve already committed the transaction in memory, since we might need to do a memory only rollback, and that isn&#x2019;t something that we are actually setup to do. In short, we&#x2019;ll be rolling back early lock release in Voron, it isn&#x2019;t worth the complexity involved, especially since we already have better ways to handle concurrency.</p>
        </article>
        <article id="article-4064">
            <a href="https://ayende.com/blog/165057/voron-time-series-data" target="_blank">
                <h2 class="title mb-6" id="article-4064">Voron &amp; time series data</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 09, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">One of the things that Voron does very well is the ability to read a lot of data fast. One of the interesting scenarios we deal with is when we want to deal with time series data. For example, let us say that we have a bunch of sensors reporting on the temperature metrics within an area (said while the heaviest storm in 5 decades is blowing outside). Every minute, we have some data coming in. For fun, we will make the following assumptions:  We have do deal with late writes (a sensor sending us updates from 1 hour ago because of communication update). Dates aren&#x2019;t unique. All queries will take into account the dates. First, let me show you the full code for that, then we can talk about how it works:      1: public class DateTimeSeries : IDisposable   2: {   3:     private readonly JsonSerializer _serializer = new JsonSerializer();   4:     private readonly StorageEnvironment _storageEnvironment;   5:     private long _last;   6:     private readonly Slice _lastKey;   7:&#xA0;    8:     public DateTimeSeries(string path)   9:     {  10:         _lastKey = &quot;last-key&quot;;  11:         _storageEnvironment = new StorageEnvironment(StorageEnvironmentOptions.ForPath(path));  12:         using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))  13:         {  14:             _storageEnvironment.CreateTree(tx, &quot;data&quot;);  15:             var read = tx.State.Root.Read(tx, _lastKey);  16:&#xA0;   17:             _last = read != null ? read.Reader.ReadInt64() : 1;  18:&#xA0;   19:             tx.Commit();  20:         }  21:     }  22:&#xA0;   23:     public void AddRange&lt;T&gt;(IEnumerable&lt;KeyValuePair&lt;DateTime, T&gt;&gt; values)  24:     {  25:         using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))  26:         {  27:             var data = tx.GetTree(&quot;data&quot;);  28:             var buffer = new byte[16];  29:             var key = new Slice(buffer);  30:             var ms = new MemoryStream();  31:             foreach (var kvp in values)  32:             {  33:                 var date = kvp.Key;  34:                 EndianBitConverter.Big.CopyBytes(date.ToBinary(), buffer, 0);  35:                 EndianBitConverter.Big.CopyBytes(_last&#x2B;&#x2B;, buffer, 8);  36:                 ms.SetLength(0);  37:                 _serializer.Serialize(new StreamWriter(ms), kvp.Value);  38:                 ms.Position = 0;  39:&#xA0;   40:                 data.Add(tx, key, ms);  41:             }  42:&#xA0;   43:             tx.State.Root.Add(tx, _lastKey, new MemoryStream(BitConverter.GetBytes(_last)));  44:             tx.Commit();  45:         }  46:     }  47:&#xA0;   48:     public IEnumerable&lt;T&gt; ScanRange&lt;T&gt;(DateTime start, DateTime end)  49:     {  50:         using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.Read))  51:         {  52:             var data = tx.GetTree(&quot;data&quot;);  53:             var startBuffer = new byte[16];  54:             EndianBitConverter.Big.CopyBytes(start.ToBinary(), startBuffer, 0);  55:             var startKey = new Slice(startBuffer);  56:&#xA0;   57:             using (var it = data.Iterate(tx))  58:             {  59:                 var endBuffer = new byte[16];  60:                 EndianBitConverter.Big.CopyBytes(end.ToBinary(), endBuffer, 0);  61:                 EndianBitConverter.Big.CopyBytes(long.MaxValue, endBuffer, 8);  62:&#xA0;   63:                 it.MaxKey = new Slice(endBuffer);  64:                 if (it.Seek(startKey) == false)  65:                     yield break;  66:                 do  67:                 {  68:                     var reader = it.CreateReaderForCurrent();  69:                     using (var stream = reader.AsStream())  70:                     {  71:                         yield return _serializer.Deserialize&lt;T&gt;(new JsonTextReader(new StreamReader(stream)));  72:                     }  73:                 } while (it.MoveNext());  74:             }  75:         }  76:               77:     }  78:&#xA0;   79:     public void Dispose()  80:     {  81:         _storageEnvironment.Dispose();  82:     }  83: }&#xA;In line 14, we create the data tree, which will hold the actual time series data, and the last-key, which I&#x2019;ll explain in a bit.&#xA;The AddRange method in line 23 is probably the most interesting. We create a key that is composed of the date of the entry, and an incrementing number. Note that we use big endian encoding because that allow easy byte string sorting. The implications of this sort of key is that the values are actually sorted by the date, but if we have multiple values for the same millisecond, we don&#x2019;t overwrite the data. Along with adding the actual data, we record the change in the incrementing counter ,so if we need to restart, we&#x2019;ll continue from where we left off.&#xA;Finally, we have the actual ScanRange method. Here we basically start from the minimum value for the start date, and set the MaxKey as the stop condition for the maximum value for the end date. And then it is just getting the values out.&#xA;Pretty simple, I think.</p>
        </article>
        <article id="article-4065">
            <a href="https://ayende.com/blog/164963/working-with-the-freedb-dataset-in-voron" target="_blank">
                <h2 class="title mb-6" id="article-4065">Working with the FreeDB dataset in Voron</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 08, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Reminder, the FreeDB data set is a 3.32 million records. Containing most of the albums that came out in the past few decades. We created the following Voron database to handle it:      1: _storageEnvironment = new StorageEnvironment(StorageEnvironmentOptions.ForPath(&quot;FreeDB&quot;));   2: using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))   3: {   4:     _storageEnvironment.CreateTree(tx, &quot;albums&quot;);   5:     _storageEnvironment.CreateTree(tx, &quot;ix_diskids&quot;);   6:     _storageEnvironment.CreateTree(tx, &quot;ix_artists&quot;);   7:     _storageEnvironment.CreateTree(tx, &quot;ix_titles&quot;);   8:     tx.Commit();   9: }&#xA;The albums tree contains the actual information about the album, as a json string. And the ix_* trees contains back references to it. They are our indexes. For what it is worth, you might want to note that this is pretty much how most RDBMS implements their indexing. We&#x2019;re now working at a pretty low level.&#xA;Note also that we need to define those trees whenever we start the database.&#xA;Now, let us do some queries, shall we?&#xA;We are going to start with the simplest option, given a disk id, give me the matching disk. Because disk ids are only nearly unique, we have the possibility of multiple results returning.&#xA0; &#xA;&#xA;Side note, the DB now is 9.00 GB in size.&#xA;Let us see how we query it. It pains me to write it, but I created a &#x201C;repository like&#x201D; interface, because Voron is way too low level for us to expose to user code. This is actually one of the few places where a repository like interface is good. Because it hides the extra complexity and the rigidity of the structure is justified.&#xA;The interface looks like: &#xA;&#xA;&#xA;Now, let us see how we actually implement this guy. We&#x2019;ll start from the simplest thing, doing a search by a disk id, which is a nearly unique value that identify a disk.&#xA;&#xA;&#xA;   1: public IEnumerable&lt;Disk&gt; FindByDiskId(string diskId)   2: {   3:     using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.Read))   4:     {   5:         var dix = tx.GetTree(&quot;ix_diskids&quot;);   6:         var albums = tx.GetTree(&quot;albums&quot;);   7:&#xA0;    8:         using (var it = dix.MultiRead(tx, diskId))   9:         {  10:             if (it.Seek(Slice.BeforeAllKeys) == false)  11:                 yield break;  12:             do  13:             {  14:                 var readResult = albums.Read(tx, it.CurrentKey);  15:                 using (var stream = readResult.Reader.AsStream())  16:                 {  17:                     yield return _serializer.Deserialize&lt;Disk&gt;(new JsonTextReader(new StreamReader(stream)));  18:                 }  19:             } while (it.MoveNext());  20:         }  21:&#xA0;   22:         tx.Commit();  23:     }  24: }&#xA;Let us go over this code in detail. We are using a read transaction, because we aren&#x2019;t doing any writes.&#xA;We are using two trees here, the ix_diskids, which is the index on the disks, and the albums tree, which contains the actual data.&#xA;On line 8, we do a multi read. This is done because a single disk id value may belong to multiple albums.&#xA;Lines 10 and 11 are needed in case there are no results. And the line 14 is where the important thing happen. The result of the MultiRead is an iterator that contains all the ids of the albums with this disk id. We then read it from the albums tree, deserialize it and hand it to the user. Pretty simple, overall.&#xA;Now, let us go to the more complex scenario, where we want to do a search by artist or album title.&#xA;&#xA;&#xA;   1: public IEnumerable&lt;Disk&gt; FindByArtist(string prefix)   2: {   3:     return FindByMultiValueIterator(prefix, &quot;ix_artists&quot;);   4: }   5:&#xA0;    6: public IEnumerable&lt;Disk&gt; FindByAlbumTitle(string prefix)   7: {   8:     return FindByMultiValueIterator(prefix, &quot;ix_titles&quot;);   9: }  10:&#xA0;   11: private IEnumerable&lt;Disk&gt; FindByMultiValueIterator(string prefix, string treeIndexName)  12: {  13:     using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.Read))  14:     {  15:         var dix = tx.GetTree(treeIndexName);  16:         var albums = tx.GetTree(&quot;albums&quot;);  17:&#xA0;   18:         using (var multiValueIterator = dix.Iterate(tx))  19:         {  20:             multiValueIterator.RequiredPrefix = prefix.ToLower();  21:             if (multiValueIterator.Seek(multiValueIterator.RequiredPrefix) == false)  22:                 yield break;  23:             do  24:             {  25:                 using (var albumsIterator = multiValueIterator.CreateMutliValueIterator())  26:                 {  27:                     if (albumsIterator.Seek(Slice.BeforeAllKeys) == false)  28:                         continue;  29:                     do  30:                     {  31:                         var readResult = albums.Read(tx, albumsIterator.CurrentKey);  32:                         using (var stream = readResult.Reader.AsStream())  33:                         {  34:                             yield return _serializer.Deserialize&lt;Disk&gt;(new JsonTextReader(new StreamReader(stream)));  35:                         }  36:                     } while (albumsIterator.MoveNext());  37:                 }  38:             } while (multiValueIterator.MoveNext());  39:         }  40:&#xA0;   41:         tx.Commit();  42:     }  43: }&#xA;You can see that in both cases, we handle it the same, because the actual behavior is the same. We don&#x2019;t want to do just an exact match. If we wanted that, we could use the exact same logic as we did in FindByDiskId. But we want to do something more, we want to be able to search by prefix, not just by exact match. That means that we have to iterate over the tree. The only difference between FindByAlbumTitle and FindByArtist is the tree index that they use.&#xA;We start out as before, iterating over the index (line 18). Note that in line 20, we defined a required prefix, and we use the lower case form of the prefix. We also entered that to the index as lower case. This is how we are able to get case insensitive searches.&#xA;Line 21 actually take us to the beginning of all the entries greater or equal to the prefix, and by setting RequiredPrefix we ensure that we can&#x2019;t go to any entry that is doesn&#x2019;t have this prefix. This is an interesting example, because we are now iterating over all the index entries that have the same prefix. But the values of the index is also a list. That is why we do in line 25. Get all the values that match a particular entry with that particular prefix.&#xA;The value of that is the actual id that we use to go into the albums tree. And there you have in, non trivial search with Voron.</p>
        </article>
        <article id="article-4066">
            <a href="https://ayende.com/blog/164962/voron-the-freedb-dataset" target="_blank">
                <h2 class="title mb-6" id="article-4066">Voron &amp; the FreeDB dataset</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 07, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I got tired of doing arbitrary performance testing, so I decided to take the FreeDB dataset and start working with that. FreeDB is a data set used to look up CD information based on the a nearly unique disk id. This is a good dataset, because it contains a lot of data (over three million albums, and over 40 million songs), and it is production data. That means that it is dirty. This makes it perfect to run all sort of interesting scenarios. The purpose of this post (and maybe the new few) is to show off a few things. First, we want to see how Voron behaves with realistic data set. Second, we want to show off the way Voron works, its API, etc. To start with, I run my FreeDB parser, pointing it at /dev/null. The idea is to measure what is the cost of just going through the data is. We are using freedb-complete-20130901.tar.bz2 from Sep 2013. After 1 minute, we went through 342,224 albums, and after 6 minutes we were at 2,066,871 albums. Reading the whole 3,328,488 albums took about a bit over ten minutes. So just the cost of parsing and reading the FreeDB dataset&#xA0; is pretty expensive. The end result is a list of objects that looks like this:  Now, let us see how we want to actually use this. We want to be able to:  Lookup an album by the disk ids  Lookup all the albums by an artist*.  Lookup albums by album title*. This gets interesting, because we need to deal with questions such as: &#x201C;Given Pearl Jam, if I search for Pearl, do I get them? Do I get it for jam?&#x201D; For now, we are going to go with case insensitive, but we won&#x2019;t be doing full text search, we will allow, however, prefix searches.  We are using the following abstraction for the destination:      1: public abstract class Destination   2: {   3:     public abstract void Accept(Disk d);   4:     public abstract void Done();   5: }&#xA;Basically, we read data as fast as we can, and we shove it to the destination, until we are done. Here is the Voron implementation:&#xA;&#xA;&#xA;   1: public class VoronDestination : Destination   2: {   3:     private readonly StorageEnvironment _storageEnvironment;   4:     private WriteBatch _currentBatch;   5:     private readonly JsonSerializer _serializer = new JsonSerializer();   6:     private int counter = 1;   7:&#xA0;    8:     public VoronDestination()   9:     {  10:         _storageEnvironment = new StorageEnvironment(StorageEnvironmentOptions.ForPath(&quot;FreeDB&quot;));  11:         using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))  12:         {  13:             _storageEnvironment.CreateTree(tx, &quot;albums&quot;);  14:             _storageEnvironment.CreateTree(tx, &quot;ix_artists&quot;);  15:             _storageEnvironment.CreateTree(tx, &quot;ix_titles&quot;);  16:             tx.Commit();  17:         }  18:         _currentBatch = new WriteBatch();  19:     }  20:&#xA0;   21:     public override void Accept(Disk d)  22:     {  23:         var ms = new MemoryStream();  24:         _serializer.Serialize(new JsonTextWriter(new StreamWriter(ms)), d);  25:         ms.Position = 0;  26:         var key = new Slice(EndianBitConverter.Big.GetBytes(counter&#x2B;&#x2B;));  27:         _currentBatch.Add(key, ms, &quot;albums&quot;);  28:&#xA0;   29:         if(d.Artist != null)  30:             _currentBatch.MultiAdd(d.Artist.ToLower(), key, &quot;ix_artists&quot;);  31:         if (d.Title != null)  32:             _currentBatch.MultiAdd(d.Title.ToLower(), key, &quot;ix_titles&quot;);  33:&#xA0;   34:         if (counter%1000 == 0)  35:         {  36:             _storageEnvironment.Writer.Write(_currentBatch);  37:             _currentBatch = new WriteBatch();  38:         }  39:&#xA0;   40:     }  41:&#xA0;   42:     public override void Done()  43:     {  44:         _storageEnvironment.Writer.Write(_currentBatch);  45:     }  46: }&#xA;Let us go over this in detail, shall we?&#xA;In line 10 we create a new storage environment. In this case, we want to just import the data, so we can create the storage inline. On lines 13 &#x2013; 15, we create the relevant trees.&#xA;You can think about Voron trees in a very similar manner to the way you think about tables. They are a way to separate data into different parts of the storage. Note that this still all reside in a single file, so there isn&#x2019;t a physical separation. &#xA;Note that we created an albums tree, which will contain the actual data. And ix_artists, ix_titles trees. Those are indexes into the albums tree. You can see them being used just a little lower.&#xA;In the Accept method, you can see that we use a WriteBatch, a native Voron notion that allows us to batch multiple operations into a single transaction. In this case, for every album, we are making 3 writes.&#xA;First, we write all of the data, as a JSON string, into a stream and put it in the albums tree. Then we create a simple incrementing integer to be the actual album key. Finally, we add the artist and title entries (lower case, so we don&#x2019;t have to worry about case sensitivity in searches) into the relevant indexes.&#xA;At 60 seconds, we written 267,998 values to Voron. In fact, I explicitly designed it so we can see the relevant metrics. At 495 seconds we have reads 1,995,385 entries from the FreeDB file, we parsed&#xA0; 1,995,346 of them and written to Voron&#xA0; 1,610,998. As you can imagined, each step is running in a dedicated thread, so we can see how they behave on an individual basis. The good thing about this is that I can physically see the various costs, it is actually pretty cool&#xA;Here is the Voron directory at 60 seconds:&#xA;&#xA;You can see that we have two journal files active (haven&#x2019;t been applied to the data file yet) and the db.voron file is at 512 MB. The compression buffer is at 32 MB (this is usually twice as big as the biggest transaction, uncompressed).&#xA;The scratch buffer is used to hold in flight transaction information (until we send it to the data file), and you can see it is sitting on 256MB in size.&#xA;At 15 minutes, we have the following numbers: 3,035,452 entries read from the file,&#xA0; 3,035,426 parsed and 2,331,998 written to Voron. Note that we are reading the file &amp; writing to Voron on the same disk, so that might impact the read performance. &#xA;At that time, we can see the following on the disk:&#xA;&#xA;Note that we increase the size of most of our files by factor of 2, so some of the space in the db.voron file is probably not used. Note that we needed more scratch space to handle the in flight information. &#xA;The entire process took 22 minutes, start to finish. Although I have to note that this hasn&#x2019;t been optimized at all, and I know we are doing a lot of stupid stuff through it.&#xA;You might have noticed something else, we actually &#x201C;crashed&#x201D; closed the Voron db, this was done to see what would happen when we open a relatively large db after an unordered shutdown.&#xA;We&#x2019;ll actually get to play with the data in my next post. So far this has been pretty much just to see how things are behaving. And&#x2026; I just realized something, I forgot to actually add an index on disk id .&#xA;Which means that I have to import the data again. But before that, I also wrote the following:&#xA;&#xA;&#xA;   1: public class JsonFileDestination : Destination   2: {   3:     private readonly GZipStream _stream;   4:     private readonly StreamWriter _writer;   5:     private readonly JsonSerializer _serializer = new JsonSerializer();   6:&#xA0;    7:     public JsonFileDestination()   8:     {   9:         _stream = new GZipStream(new FileStream(&quot;freedb.json.gzip&quot;, FileMode.CreateNew, FileAccess.ReadWrite), CompressionLevel.Optimal);  10:         _writer = new StreamWriter(_stream);  11:     }  12:&#xA0;   13:     public override void Accept(Disk d)  14:     {  15:         _serializer.Serialize(new JsonTextWriter(_writer), d);  16:         _writer.WriteLine();  17:     }  18:&#xA0;   19:     public override void Done()  20:     {  21:         _writer.Flush();  22:         _stream.Dispose();  23:     }  24: }&#xA;This completed in ten minutes, for 3,328,488 entries. Or a rate of about 5,538 per / second. The result is a 845MB gzip file. &#xA;I had twofold reasons to want to do this. First, this gave me something to compare ourselves to, and more to the point, I can re-use this gzip file for my next tests, without having to go through the expensive parsing of the freedb file.&#xA;I did just that and ended up with the following:&#xA;&#xA;&#xA;   1: public class VoronEntriesDestination : EntryDestination   2: {   3:     private readonly StorageEnvironment _storageEnvironment;   4:     private WriteBatch _currentBatch;   5:     private int counter = 1;   6:&#xA0;    7:     public VoronEntriesDestination()   8:     {   9:         _storageEnvironment = new StorageEnvironment(StorageEnvironmentOptions.ForPath(&quot;FreeDB&quot;));  10:         using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))  11:         {  12:             _storageEnvironment.CreateTree(tx, &quot;albums&quot;);  13:             _storageEnvironment.CreateTree(tx, &quot;ix_diskids&quot;);  14:             _storageEnvironment.CreateTree(tx, &quot;ix_artists&quot;);  15:             _storageEnvironment.CreateTree(tx, &quot;ix_titles&quot;);  16:             tx.Commit();  17:         }  18:         _currentBatch = new WriteBatch();  19:     }  20:&#xA0;   21:     public override int Accept(string d)  22:     {  23:         var disk = JObject.Parse(d);  24:&#xA0;   25:         var ms = new MemoryStream();  26:         var writer = new StreamWriter(ms);  27:         writer.Write(d); writer.Flush();  28:         ms.Position = 0;  29:         var key = new Slice(EndianBitConverter.Big.GetBytes(counter&#x2B;&#x2B;));  30:         _currentBatch.Add(key, ms, &quot;albums&quot;);  31:         int count = 1;  32:&#xA0;   33:         foreach (var diskId in disk.Value&lt;JArray&gt;(&quot;DiskIds&quot;))  34:         {  35:             count&#x2B;&#x2B;;  36:             _currentBatch.MultiAdd(diskId.Value&lt;string&gt;(), key, &quot;ix_diskids&quot;);  37:         }  38:&#xA0;   39:         var artist = disk.Value&lt;string&gt;(&quot;Artist&quot;);  40:         if (artist != null)  41:         {  42:             count&#x2B;&#x2B;;   43:             _currentBatch.MultiAdd(artist.ToLower(), key, &quot;ix_artists&quot;);  44:         }  45:         var title = disk.Value&lt;string&gt;(&quot;Title&quot;);  46:         if (title != null)  47:         {  48:             count&#x2B;&#x2B;;   49:             _currentBatch.MultiAdd(title.ToLower(), key, &quot;ix_titles&quot;);  50:         }  51:&#xA0;   52:         if (counter % 100 == 0)  53:         {  54:             _storageEnvironment.Writer.Write(_currentBatch);  55:             _currentBatch = new WriteBatch();  56:         }  57:         return count;  58:     }  59:&#xA0;   60:     public override void Done()  61:     {  62:         _storageEnvironment.Writer.Write(_currentBatch);  63:         _storageEnvironment.Dispose();  64:     }  65: }&#xA;Now we are actually properly disposing of things, and I also decreased the size of the batch, to see how it would respond. Note that it is now being fed directly from the gzip file, at a greatly reduced cost.&#xA;I also added tracking note only for how many albums we write, but also how many entries. By entries I mean, how many Voron entries (which include the values we add to the index). &#xA;I did find a bug where we would just double the file size without due consideration to its size, so now we are doing smaller file size increases.&#xA;&#xA;Word of warning: I didn&#x2019;t realized until after I was done with all the benchmarks, but I actually run all of those in DEBUG configuration, which basically means that it is utterly useless as a performance metric. That is especially true because we have a lot of verifier code that runs in DEBUG mode. So please don&#x2019;t take those numbers as actual performance metrics, they aren&#x2019;t valid.&#xA;&#xA;&#xA;&#xA;Time&#xA;# of albums&#xA;# of entries&#xA;&#xA;4 minutes&#xA;773,398&#xA;3,091,146&#xA;&#xA;6 minutes&#xA;1,126,998&#xA;4,504,550&#xA;&#xA;8 minutes&#xA;1,532,858&#xA;6,126,413&#xA;&#xA;18 minutes&#xA;2,781,698&#xA;11,122,799&#xA;&#xA;24 minutes&#xA;3,328,488&#xA;13,301,496&#xA;The status of the file system midway during the run. You can see that now we increase the file is smaller increments. And that we are using more scratch space, probably because we are under very heavy write load.&#xA;&#xA;After the run:&#xA;&#xA;Scratch &amp; compression are only used when the database is running, and deleted on close. The database is 7GB in side, which is quite respectable. Now, to working with it, but I&#x2019;ll save that for my next post, this one is long enough already.</p>
        </article>
        <article id="article-4067">
            <a href="https://benfoster.io/blog/proxying-httpclient-requests-through-fiddler/" target="_blank">
                <h2 class="title mb-6" id="article-4067">Proxying HttpClient requests through Fiddler</h2>
            </a>
            <p class="mb-2">by Ben Foster</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 07, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">How to proxy requests made with .NET&#x2019;s HttpClient through Fiddler, the web debugging proxy tool.</p>
        </article>
        <article id="article-4068">
            <a href="https://ayende.com/blog/164993/performance-testing-with-voron-omg" target="_blank">
                <h2 class="title mb-6" id="article-4068">Performance Testing with Voron OMG</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 06, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I am not going to have a lot of commentary here, I think that I can let the numbers speak for themselves. Here are the current performance test of Voron vs. Esent on my machine.  Note, the numbers are in millions of writes per second here! For Random Writes, the numbers are in thousands of writes per second:  Okay, I lied about no commentary. What you can see is that in our test, inserting 1.5 million items to storage. In sequential runs, we get such big variance because the test run itself is so short. (Nitpicker, yes, we&#x2019;ll post longer benchmarks). Note that this was running on a pretty good SSD drive, but what about HDD? Yes, that isn&#x2019;t a mistake, Esent is doing 901 writes per second.   As we have seen, we are pretty good at reading, but what are the current results?  As you can see, we are significantly better than Esent for reads in single and dual threaded modes, but Esent is faster when it can use more threads. That annoyed me, so I set out to figure out what was blocking us. As it turned out, searching the B-tree was quite expensive, but when I added a very small optimization (remember the last few searched pages), we saw something very interesting).  (The Esent results are different than the previous run because we run it on a different disk (still SSD)). What about random reads?   Now, one area where we currently suck is large writes, where we are doing really bad, but we&#x2019;re working on that. Overall, I am pretty happy about it all.</p>
        </article>
        <article id="article-4069">
            <a href="https://ardalis.com/when-should-you-refactor/" target="_blank">
                <h2 class="title mb-6" id="article-4069">When Should You Refactor</h2>
            </a>
            <p class="mb-2">by Ardalis</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 03, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">A common question teams face is, when should we take the time to refactor our code? Refactoring is defined as improving the design or&#x2026;Keep Reading &#x2192;</p>
        </article>
        <article id="article-4070">
            <a href="https://ayende.com/blog/164961/growable-memory" target="_blank">
                <h2 class="title mb-6" id="article-4070">Growable memory</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 03, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I wish that I could have more control over virtual memory. In particular, what I would really like at this time is the ability to map two virtual address ranges to the same physical memory. And yes, I am well aware (and already using) the ability to do just that using memory mapped files.&#xA0; However, what I would like to do is to have a pure memory based system, without any files being involved. This is meant to be used for the memory only system, which is commonly meant to be be used for unit testing. The reason that I want to be able to map the physical memory multiple times is that I have a buffer. Let us say that it is 1MB in size. And now I need to grow it. I can&#x2019;t ask the OS to just grow the buffer, since it might not have the virtual address available past the buffer end by the time I request it. What I would like to do is to request a new virtual allocation, let us say of 2 MB, and then ask the OS to map the same physical memory for the first buffer to the first section of the new buffer, and new memory for the rest.  The end result is that the first part of the buffer is mapped twice, and any changes you make there will be visible in both locations. Now, it is pretty easy to do this with memory mapped files, but I couldn&#x2019;t find a way to do it sans files. What I ended up doing is reserve a large portion of the virtual address space (using VirtualAlloc) and then committing it on demand. But I would really have liked to do something better, because now just moved the problem to when I run out of the reserved buffered space.</p>
        </article>
        <div class="button flex justify-between">
            <a href="406.html"><span class="back arrow"></span></a>

            <a href="408.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>

<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;🚀&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="about.html"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="/pagefind/pagefind-ui.js"></script>

<!-- Cookie Consent Banner -->
<div class="cookie-consent" id="cookieConsent">
    <div>
        <p class="text-sm">We use cookies to analyze our website traffic and provide a better browsing experience. By
            continuing to use our site, you agree to our use of cookies.</p>
    </div>
    <div class="cookie-consent-buttons">
        <button class="cookie-consent-decline" onclick="declineCookies()">Decline</button>
        <button class="cookie-consent-accept" onclick="acceptCookies()">Accept</button>
    </div>
</div>

<script>
    // Cookie consent management
    function showCookieConsent() {
        const consent = localStorage.getItem('cookieConsent');
        if (!consent) {
            document.getElementById('cookieConsent').classList.add('show');
        }
    }

    function acceptCookies() {
        localStorage.setItem('cookieConsent', 'accepted');
        document.getElementById('cookieConsent').classList.remove('show');
        loadGA(); // Load Google Analytics after consent
    }

    function declineCookies() {
        localStorage.setItem('cookieConsent', 'declined');
        document.getElementById('cookieConsent').classList.remove('show');
    }

    // Show the consent banner only for EU visitors (you can add more country codes as needed)
    fetch('https://ipapi.co/json/')
            .then(response => response.json())
            .then(data => {
                const euCountries = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE'];
                if (euCountries.includes(data.country_code)) {
                    showCookieConsent();
                } else {
                    // For non-EU visitors, automatically load GA
                    if (!localStorage.getItem('cookieConsent')) {
                        localStorage.setItem('cookieConsent', 'accepted');
                        loadGA();
                    }
                }
            })
            .catch(() => {
                // If we can't determine location, show the consent banner to be safe
                showCookieConsent();
            });
</script>
</body>
</html>
