
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 391 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-3901">
            <a href="https://ayende.com/blog/165153/big-data-search-the-index-format-is-horrible" target="_blank">
                <h2 class="title mb-6" id="article-3901">Big Data Search</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 22, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I have completed my own exercise, and while I did wanted to try it with &#x201C;few allocations&#x201D; rule, it is interesting to see just how far out there the code is. This isn&#x2019;t something that you can really for anything except as a basis to see how badly you are doing. Let us start with the index format. It is just a CSV file with the value and the position in the original file. That means that any search we want to do on the file is actually a binary search, as discussed in the previous post. But doing a binary search like that is an absolute killer for performance. Let us consider our 15TB data set. In my tests, a 1GB file with 4.2 million rows produced roughly 80MB index. Assuming the same is true for the larger file, that gives us a 1.2 TB file. In my small index, we have to do 24 seeks to get to the right position in the file. And as you should know, disk seeks are expensive. They are in the order of 10ms or so. So the cost of actually searching the index is close to quarter of a second.&#xA0; Now, to be fair, there is going to be a lot of caching opportunities here, but probably not that many if we have a lot of queries to deal with ere.  Of course, the fun thing about this is that even with a 1.2 TB file, we are still talking about less than 40 seeks (the beauty of O(logN) in action), but that is still pretty expensive. Even worse, this is what happens when we are running on a single query at a time. What do you think will happen if we are actually running this with multiple threads generating queries. Now we will have a lot of seeks (effective random) that would generate a big performance sink. This is especially true if we consider that any storage solution big enough to store the data is going to be composed of an aggregate of HDD disks. Sure, we get multiple spindles, so we get better performance overall, but still&#x2026; Obviously, there are multiple solutions for this issue. B&#x2B;Trees solve the problem by packing multiple keys into a single page, so instead of doing a O(log2N), you are usually doing O(log36N) or O(log100N). Consider those fan outs, we will have 6 &#x2013; 8 seeks to do to get to our data. Much better than the 40 seeks required using plain binary search. It would actually be better than that in the common case, since the first few levels of the trees are likely to reside in memory (and probably in L1, if we are speaking about that). However, given that we are storing sorted strings here, one must give some attention to Sorted Strings Tables. The way those work, you have the sorted strings in the file, and the footer contains two important bits of information. The first is the bloom filter, which allows you to quickly rule out missing values, but the more important factor is that it also contains the positions of (by default) every 16th entry to the file. This means that in our 15 TB data file (with 64.5 billion entries), we will use about 15GB just to store pointers to the different locations in the index file (which will be about 1.2 TB). Note that the numbers actually are probably worse. Because SST (note that when talking about SST I am talking specifically about the leveldb implementation) utilize many forms of compression, it is actually that the file size will be smaller (although, since the &#x201C;value&#x201D; we use is just a byte position in the data file, we won&#x2019;t benefit from compression there). Key compression is probably a lot more important here. However, note that this is a pretty poor way of doing things. Sure, the actual data format is better, in the sense that we don&#x2019;t store as much, but in terms of the number of operations required? Not so much. We still need to do a binary search over the entire file. In particular, the leveldb implementation utilizes memory mapped files. What this ends up doing is rely on the OS to keep the midway points in the file in RAM, so we don&#x2019;t have to do so much seeking. Without that, the cost of actually seeking every time would make SSTs impractical. In fact, you would pretty much have to introduce another layer on top of this, but at that point, you are basically doing trees, and a binary tree is a better friend here. This leads to an interesting question. SST is probably so popular inside Google because they deal with a lot of data, and the file format is very friendly to compression of various kinds. It is also a pretty simple format. That make it much nicer to work with. On the other hand, a B&#x2B;Tree implementation is a lot more complex, and it would probably several orders of magnitude more complex if it had to try to do the same compression tricks that SSTs do. Another factor that is probably as important is that as I understand it, a lot of the time, SSTs are usually used for actual sequential access (map/reduce stuff) and not necessarily for the random reads that are done in leveldb. It is interesting to think about this in this fashion, at least, even if I don&#x2019;t know what I&#x2019;ll be doing with it.</p>
        </article>
        <article id="article-3902">
            <a href="https://www.meziantou.net/mots-de-passe-oublies.htm" target="_blank">
                <h2 class="title mb-6" id="article-3902">Mots de passe oubli&#xE9;s</h2>
            </a>
            <p class="mb-2">by G&#xE9;rald Barr&#xE9;</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 22, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">J&#x27;ai &#xE9;crit un article sur un autre blog:Les utilisateurs sont des &#xEA;tres humains normaux. Ils ont donc des probl&#xE8;mes de m&#xE9;moire comme tout le monde. Ainsi ils leur arrivent d&#x27;oublier leur mot de passe de temps en temps Le but de cet article est de montrer comment leur redonner un acc&#xE8;s &#xE0; votreL&#x27;arti</p>
        </article>
        <article id="article-3903">
            <a href="https://ayende.com/blog/165441/the-ravendb-conference-april-7-11" target="_blank">
                <h2 class="title mb-6" id="article-3903">The RavenDB Conference &#x2013; April 7 - 11</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 21, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">We have been working on this for a while now, and now I am very proud to announce that we are having the first RavenDB conference in April 7 &#x2013; 11 in Raleigh, NC. You can register to the conference right now and please do so, since we have limited number of places.  This conference is also going to be the platform for RavenDB 3.0 launch, and we&#x2019;ll expose a lot of new things about the new stuff there. In additional to that, the conference will also offer many talks by RavenDB experts and users, deep guidance on how to get the best out of it and a lot more.  We are going to have two days days of talks, and a 3 days in depth workshop that will give you everything you need to know about RavenDB 3.0.  As I said, we have a limited amount of places for the conference, so please register soon.  The conference alone (excluding the 3 days workshop) is going to cost you 89$. And just to make sure that you won&#x2019;t have any price issues, we will give you a 90$ coupon for a RavenDB purchase.</p>
        </article>
        <article id="article-3904">
            <a href="https://ayende.com/blog/165124/big-data-search-binary-search-of-textual-data" target="_blank">
                <h2 class="title mb-6" id="article-3904">Big Data Search</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 20, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The index I created for the exercise is just a text file, sorted by the indexed key. When doing a search by a human, that make it very easy to work with. Much easier than trying to work with a binary file, it also helps debugging. However, it does make it running a binary search on the data a bit harder. Mostly because there isn&#x2019;t a nice way to say &#x201C;give me the #th line&#x201D;. Instead, I wrote the following:      1: public void SetPositionToLineAt(long position)   2: {   3:     // now we need to go back until we either get to the start of the file   4:     // or find a \n character   5:     const int bufferSize = 128;   6:     _buffer.Capacity = Math.Max(bufferSize, _buffer.Capacity);   7:&#xA0;    8:     var charCount = _encoding.GetMaxCharCount(bufferSize);   9:     if (charCount &gt; _charBuf.Length)  10:         _charBuf = new char[Utils.NearestPowerOfTwo(charCount)];  11:&#xA0;   12:     while (true)  13:     {  14:         _input.Position = position - (position &lt; bufferSize ? 0 : bufferSize);  15:         var read = ReadToBuffer(bufferSize);  16:         var buffer = _buffer.GetBuffer();  17:         var chars = _encoding.GetChars(buffer, 0, read, _charBuf, 0);  18:         for (int i = chars - 1; i &gt;= 0; i--)  19:         {  20:             if (_charBuf[i] == &#x27;\n&#x27;)  21:             {  22:                 _input.Position = position - (bufferSize - i) &#x2B; 1;  23:                 return;  24:             }  25:         }  26:         position -= bufferSize;  27:         if (position &lt; 0)  28:         {  29:             _input.Position = 0;  30:             return;  31:         }  32:     }  33: }&#xA;This code starts at an arbitrary byte position, and go backward until it find the new line character &#x2018;\n&#x2019;. This give me the ability to go to a rough location and get the line oriented input.&#xA;Once I have that, the rest is pretty easy. Here is the binary search:&#xA;&#xA;&#xA;   1: while (lo &lt;= hi)   2: {   3:     position = (lo &#x2B; hi) / 2;   4:     _reader.SetPositionToLineAt(position);   5:&#xA0;    6:     bool? result;   7:     do   8:     {   9:         result = _reader.ReadOneLine();  10:     } while (result == null); // skip empty lines  11:&#xA0;   12:     if (result == false)  13:         yield break; // couldn&#x27;t find anything  14:&#xA0;   15:     var entry = _reader.Current.Values[0];  16:     match = Utils.CompareArraySegments(expectedIndexEntry, entry);  17:&#xA0;   18:     if (match == 0)  19:     {  20:         break;  21:     }  22:     if (match &gt; 0)  23:         lo = position &#x2B; _reader.Current.Values.Sum(x =&gt; x.Count) &#x2B; 1;  24:     else  25:         hi = position - 1;  26: }  27:&#xA0;   28: if (match != 0)  29: {  30:     // no match  31:     yield break;  32: }&#xA;The idea is that this positions us on the location of the index that has an entry with a value that is equal to what we are searched on.&#xA;We then write the following to actually get the data from the actual data file:&#xA;&#xA;&#xA;   1: // we have a match, now we need to return all the matches   2: _reader.SetPositionToLineAt(position);   3:&#xA0;    4: while(true)   5: {   6:     bool? result;   7:     do   8:     {   9:         result = _reader.ReadOneLine();  10:     } while (result == null); // skip empty lines  11:&#xA0;   12:     if(result == false)  13:         yield break; // end of file  14:&#xA0;   15:     var entry = _reader.Current.Values[0];  16:     match = Utils.CompareArraySegments(expectedIndexEntry, entry);  17:     if (match != 0)  18:         yield break; // out of the valid range we need  19:&#xA0;   20:     _buffer.SetLength(0);  21:     _data.Position = Utils.ToInt64(_reader.Current.Values[1]);  22:&#xA0;   23:     while (true)  24:     {  25:         var b = _data.ReadByte();  26:         if (b == -1)  27:             break;  28:         if (b == &#x27;\n&#x27;)  29:         {  30:             break;  31:         }  32:         _buffer.WriteByte((byte)b);  33:     }  34:&#xA0;   35:     yield return _encoding.GetString(_buffer.GetBuffer(), 0, (int)_buffer.Length);  36: }&#xA;As you can see, we are moving forward in the index file, reading one line at a time. Then we take the second value, the position of the relevant line in the data file, and read that. &#xA;We continue to do so as long as the indexed value is the same. Pretty simple, all told. But it comes with its own set of problems. I&#x2019;ll discuss that in my next post.</p>
        </article>
        <article id="article-3905">
            <a href="https://ayende.com/blog/165123/big-data-search-setting-up" target="_blank">
                <h2 class="title mb-6" id="article-3905">Big Data Search</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 17, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The interesting thing about this problem is that I was very careful in how I phrased things. I said what I wanted to happen, but didn&#x2019;t specify what needs to be done. That was quite intentional. For that matter, the fact that I am posting about what is going to be our acceptance criteria is also intentional. The idea is to have a non trivial task, but something that should be very well understood and easy to research. It also means that the candidate needs to be able to write some non trivial code. And I can tell a lot about a dev from such a project. At the same time, this is a very self contained scenario. The idea is that this is something that you can do in a short amount of time. The reason that this is an interesting exercise is that this is actually at least two totally different but related problems. First, in a 15TB file, we obviously cannot rely on just scanning the entire file. That means that we have to have an index. And that mean that we have to build it. Interestingly enough, an index being a sorted structure, that means that we have to solve the problem of sorting more data than can fit in main memory. The second problem is probably easier, since it is just an implementation of external sort, and there are plenty of algorithms around to handle that. Note that I am not really interested in actual efficiencies for this particular scenario. I care about being able to see the code. See that it works, etc. My solution, for example, is a single threaded system that make no attempt at parallelism or I/O optimizations. It clocks at over 1 GB / minute and the memory consumption is at under 150MB. Queries for a unique value return the result in 0.0004 seconds. Queries that returned 153K results completed in about 2 seconds. When increasing the used memory to about 650MB, there isn&#x2019;t really any difference in performance, which surprised me a bit. Then again, the entire code is probably highly inefficient. But that is good enough for now. The process is kicked off with indexing:      1: var options = new DirectoryExternalStorageOptions(&quot;/path/to/index/files&quot;);   2: var input = File.OpenRead(@&quot;/path/to/data/Crimes_-_2001_to_present.csv&quot;);   3: var sorter = new ExternalSorter(input, options, new int[]   4: {   5:     1,// case number   6:     4, // ICHR   7:&#xA0;    8: });   9:&#xA0;   10: sorter.Sort();&#xA;I am actually using the Chicago crime data for this. This is a 1GB file that I downloaded from the Chicago city portal in CSV format. This is what the data looks like:&#xA;&#xA;The ExternalSorter will read and parse the file, and start reading it into a buffer. When it gets to a certain size (about 64MB of source data, usually), it will sort the values in memory and output them into temporary files.&#xA;Those file looks like this:&#xA;&#xA;Initially, I tried to do that with binary data, but it turns out that that was too complex to be easy, and writing this in a human readable format made it much easier to work with. The format is pretty simple, you have the value of the left, and on the right you have start position of the row for this value. &#xA;We generate about 17 such temporary files for the 1GB file. One temporary file per each 64 MB of the original file. This lets us keep our actual memory consumption very low, but for larger data sets, we&#x2019;ll probably want to actually do the sort every 1 GB or maybe more. Our test machine has 16 GB of RAM, so doing a sort and outputting a temporary file every 8 GB can be a good way to handle things. But that is beside the point.&#xA;The end result is that we have multiple sorted files, but they aren&#x2019;t sequential. In other words, in file #1 we have values 1,4,6,8 and in file #2 we have 1,2,6,7. We need to merge all of them together. Luckily, this is easy enough to do. We basically have a heap that we feed entries from the files into. And that pretty much takes care of this. See merge sort if you want more details about this.&#xA;The end result of merging all of those files is&#x2026; another file, just like them, that contains all of the data sorted. Then it is time to actually handle the other issue, actually searching the data.&#xA;We can do that using simple binary search, with the caveat that because this is a text file, and there is no fixed size records or pages, it is actually a big hard to figure out where to start reading.&#xA;In effect, what I am doing is to select an arbitrary byte position, then walk backward until I find a &#x2018;\n&#x2019;. Once I found the new line character, I can read the full line, check the value, and decide where I need to look next. Assuming that I actually found my value, I can now go to the byte position of the value in the original file and read the original line, giving it to the user.&#xA;Assuming an indexing rate of 1 GB / minute a 15 TB file would take about 10 days to index. But there are ways around that as well, but I&#x2019;ll touch on them in my next post. What all of this did was bring home just how much we usually don&#x2019;t have to worry about such things. But I consider this research well spent, we&#x2019;ll be using this in the future.</p>
        </article>
        <article id="article-3906">
            <a href="https://ayende.com/blog/165122/big-data-search" target="_blank">
                <h2 class="title mb-6" id="article-3906">Big Data Search</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 16, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I got tired of the old questions that we were asking candidates, so I decided to add a new one. This one is usually something that we&#x2019;ll give the candidates to do at home, at their leisure. Let us imagine the following file:      1: &quot;first_name&quot;,&quot;last_name&quot;,&quot;company_name&quot;,&quot;address&quot;,&quot;city&quot;,&quot;county&quot;,&quot;state&quot;,&quot;zip&quot;,&quot;phone1&quot;,&quot;phone2&quot;,&quot;email&quot;,&quot;web&quot;   2: &quot;James&quot;,&quot;Butt&quot;,&quot;Benton, John B Jr&quot;,&quot;6649 N Blue Gum St&quot;,&quot;New Orleans&quot;,&quot;Orleans&quot;,&quot;LA&quot;,70116,&quot;504-621-8927&quot;,&quot;504-845-1427&quot;,&quot;jbutt@gmail.com&quot;,&quot;http://www.bentonjohnbjr.com&quot;   3: &quot;Josephine&quot;,&quot;Darakjy&quot;,&quot;Chanay, Jeffrey A Esq&quot;,&quot;4 B Blue Ridge Blvd&quot;,&quot;Brighton&quot;,&quot;Livingston&quot;,&quot;MI&quot;,48116,&quot;810-292-9388&quot;,&quot;810-374-9840&quot;,&quot;josephine_darakjy@darakjy.org&quot;,&quot;http://www.chanayjeffreyaesq.com&quot;   4: &quot;Art&quot;,&quot;Venere&quot;,&quot;Chemel, James L Cpa&quot;,&quot;8 W Cerritos Ave #54&quot;,&quot;Bridgeport&quot;,&quot;Gloucester&quot;,&quot;NJ&quot;,&quot;08014&quot;,&quot;856-636-8749&quot;,&quot;856-264-4130&quot;,&quot;art@venere.org&quot;,&quot;http://www.chemeljameslcpa.com&quot;   5: &quot;Lenna&quot;,&quot;Paprocki&quot;,&quot;Feltz Printing Service&quot;,&quot;639 Main St&quot;,&quot;Anchorage&quot;,&quot;Anchorage&quot;,&quot;AK&quot;,99501,&quot;907-385-4412&quot;,&quot;907-921-2010&quot;,&quot;lpaprocki@hotmail.com&quot;,http://www.feltzprintingservice.com&#xA;As you can see, this is a pretty trivial CSV file. However, let assume that it is a small example of a CSV file that is 15 TB in size. The requirement is to be able to query on that file. We need to be able to query by email or all the people with in a particular zip code. Because of the size, the solution can be composed of two parts, a prepare part (which can run for as long as it is needed) and answer to queries part. Maximum time to answer any query must be under 30 seconds.&#xA;&#xA;You can assume that the file never changes, and that once the prepare part is done, it will never need to be run again. &#xA;The answer to a query is the full CSV row.&#xA;You can assume a machine with a single machine 100TB disk, 16 GB RAM and 8 CPU cores. &#xA;The solution cannot use any existing databases.&#xA;The solution needs to include explanation of the various options that were available and why this specific solution was chosen.&#xA;After the prepare phase is done, the solution has to take less than 30TB of data (including the original file).&#xA;The solution should be easy to apply to different CSV file.&#xA;I decided that it wouldn&#x2019;t be fair to ask candidates to do something like that without doing it myself. Mostly because the fact that I have a good idea about how to do something doesn&#x2019;t meant that I understand the actual implementation issues that might pop up.&#xA;I actually gave myself a somewhat harder task, do the above mention task, but do it without access to any library other than the BCL and do so with a minimal amount of memory usage. The entire thing took less than a day, and it solves the problem quite a bit more efficiently than I actually anticipated.&#xA;But I&#x2019;ll discuss the details of this in my next post.</p>
        </article>
        <article id="article-3907">
            <a href="https://www.meziantou.net/stockage-des-mots-de-passe.htm" target="_blank">
                <h2 class="title mb-6" id="article-3907">Stockage des mots de passe</h2>
            </a>
            <p class="mb-2">by G&#xE9;rald Barr&#xE9;</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 16, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">J&#x27;ai &#xE9;crit un article sur un autre blog:Il s&#x27;agit de stocker des informations permettant d&#x27;authentifier une personne sur une application. Il faut garder &#xE0; l&#x27;esprit que ces donn&#xE9;es sont sensibles et doivent donc &#xEA;tre s&#xE9;curis&#xE9;es.On voit souvent des news indiquant que des mots de passe ont fuit&#xE9;. Cela</p>
        </article>
        <article id="article-3908">
            <a href="https://ayende.com/blog/165313/the-cost-of-working-with-strings" target="_blank">
                <h2 class="title mb-6" id="article-3908">The cost of working with strings</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 15, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Following my last post, I decided that it might be better to actually show what the difference is between direct string manipulation and working at lower levels. I generated a sample CSV file with 10 million lines and 6 columns. The file size was 658MB. I then wrote the simplest code that I could possibly think of:      1: public class TrivialCsvParser   2: {   3:     private readonly string _path;   4:&#xA0;    5:     public TrivialCsvParser(string path)   6:     {   7:         _path = path;   8:     }   9:&#xA0;   10:     public IEnumerable&lt;string[]&gt; Parse()  11:     {  12:         using (var reader = new StreamReader(_path))  13:         {  14:             while (true)  15:             {  16:                 var line = reader.ReadLine();  17:                 if (line == null)  18:                     break;  19:                 var fields = line.Split(&#x27;,&#x27;);  20:                 yield return fields;  21:             }  22:         }  23:     }  24: }&#xA;This run in 8.65 seconds (with a no-op action) and kept the memory utilization at about 7MB. &#xA;Then next thing to try was just reading through the file without doing any parsing. So I wrote this:&#xA;&#xA;&#xA;   1: public class NoopParser   2: {   3:     private readonly string _path;   4:&#xA0;    5:     public NoopParser(string path)   6:     {   7:         _path = path;   8:     }   9:&#xA0;   10:     public IEnumerable&lt;object&gt; Parse()  11:     {  12:         var buffer = new byte[1024];  13:         using (var stream = new FileStream(_path,FileMode.Open, FileAccess.Read))  14:         {  15:             while (true)  16:             {  17:                 var result = stream.Read(buffer, 0, buffer.Length);  18:                 if (result == 0)  19:                     break;  20:                 yield return null; // noop  21:             }  22:         }  23:     }  24: }&#xA;Note that this isn&#x2019;t actually doing anything. But this took 0.83 seconds, so we see a pretty important big difference here. By the way, the amount of memory used isn&#x2019;t noticeably different here. Both use about 7 MB. Probably because we aren&#x2019;t actually holding up to any of the data in any meaningful way.&#xA;I have run the results using release build, and I run it multiple times, so the file is probably all in the OS cache. So I/O cost is pretty minimal here. However, note that we aren&#x2019;t doing a lot of stuff that is being done by the TrivialCsvParser. For example, doing line searches, splitting the string to fields, etc. But interestingly enough, just removing the split will reduce the cost from 8.65 seconds to 3.55 seconds.</p>
        </article>
        <article id="article-3909">
            <a href="https://ayende.com/blog/165121/without-strings-it-is-a-dark-cold-place" target="_blank">
                <h2 class="title mb-6" id="article-3909">Without strings, it is a dark, cold place&#x2026;</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 14, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">So I set out to do some non trivial stuff with file parsing. The file format is CSV, and I am explicitly trying to do it with as few string allocations as possible. In effect, I am basically relying on a char array that I manually manage. But as it turns out, this is not so easy. To start with, 65279 should be taken out and shot. That is the BOM marker (U&#x2B;FEFF), and it is has a very nasty habit of showing up when you are mixing StreamWriter and reading from a byte stream, even when I made sure to use the UTF8 encoding anyway. It is possible, as I said, but it is anything but nice. I set out to do non trivial stuff using this approach, but I wonder how useful this actually is. From experience, this can kill a system performance. This has been more than just my experience: http://joeduffyblog.com/2012/10/30/beware-the-string Of course, the moment that you start dealing with your own string type, it is all back in the good bad days of C&#x2B;&#x2B; and BSTR vs cstr vs std::string vs. MyString vs OmgStr. For example, how do you look at the value during debug&#x2026; I am pretty sure that in general, that isn&#x2019;t something that you&#x2019;ll want to do. In my spike, quite a lot of the issues that came up were directly associated with this. On the other hand, this did let me do things like string pooling, efficient parsing with no allocations, etc. But I&#x2019;ll talk about that specific project in my next post.</p>
        </article>
        <article id="article-3910">
            <a href="https://ayende.com/blog/165091/strings-are-annoying" target="_blank">
                <h2 class="title mb-6" id="article-3910">Strings are annoying</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 13, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I hate a love/hate/hate relationship with .NET strings. That is because they are both incredibly convenient and horribly inefficient in a bad way. Let us look at the following file:      1: &quot;first_name&quot;,&quot;last_name&quot;,&quot;company_name&quot;,&quot;address&quot;,&quot;city&quot;,&quot;county&quot;,&quot;state&quot;,&quot;zip&quot;,&quot;phone1&quot;,&quot;phone2&quot;,&quot;email&quot;,&quot;web&quot;   2: &quot;James&quot;,&quot;Butt&quot;,&quot;Benton, John B Jr&quot;,&quot;6649 N Blue Gum St&quot;,&quot;New Orleans&quot;,&quot;Orleans&quot;,&quot;LA&quot;,70116,&quot;504-621-8927&quot;,&quot;504-845-1427&quot;,&quot;jbutt@gmail.com&quot;,&quot;http://www.bentonjohnbjr.com&quot;   3: &quot;Josephine&quot;,&quot;Darakjy&quot;,&quot;Chanay, Jeffrey A Esq&quot;,&quot;4 B Blue Ridge Blvd&quot;,&quot;Brighton&quot;,&quot;Livingston&quot;,&quot;MI&quot;,48116,&quot;810-292-9388&quot;,&quot;810-374-9840&quot;,&quot;josephine_darakjy@darakjy.org&quot;,&quot;http://www.chanayjeffreyaesq.com&quot;   4: &quot;Art&quot;,&quot;Venere&quot;,&quot;Chemel, James L Cpa&quot;,&quot;8 W Cerritos Ave #54&quot;,&quot;Bridgeport&quot;,&quot;Gloucester&quot;,&quot;NJ&quot;,&quot;08014&quot;,&quot;856-636-8749&quot;,&quot;856-264-4130&quot;,&quot;art@venere.org&quot;,&quot;http://www.chemeljameslcpa.com&quot;&#xA;Reading this is a simple matter of writing something like this:&#xA;&#xA;&#xA;   1: var headerLine = reader.ReadLine();   2: var headers = headerLine.Split(&#x27;,&#x27;).Select(h=&gt;h.Trim(&#x27;&quot;&#x27;)).ToArray();   3:&#xA0;    4: while(reader.EndOfStream == false)   5: {   6:     var line = reader.ReadLine();   7:     var columns = line.Split(&quot;,&quot;);   8:     var dic = new Dictionary&lt;string,string&gt;();   9:     for(var i=0;i&lt;headers.Length;i&#x2B;&#x2B;)  10:     {  11:         dic[headers[i]] = columns[i].Trim(&#x27;&quot;&#x27;);  12:     }  13:     yield return dic;  14: }&#xA;Now, let us look at the same code again, but this time, I marked places where we are doing string allocation:&#xA;&#xA;&#xA;   1: var headerLine = reader.ReadLine();   2: var headers = headerLine.Split(&#x27;,&#x27;).Select(h=&gt;h.Trim(&#x27;&quot;&#x27;)).ToArray();   3:&#xA0;    4: while(reader.EndOfStream == false)   5: {   6:     var line = reader.ReadLine();   7:     var columns = line.Split(&quot;,&quot;);   8:     var dic = new Dictionary&lt;string,string&gt;();   9:     for(var i=0;i&lt;headers.Length;i&#x2B;&#x2B;)  10:     {  11:         dic[headers[i]] = columns[i].Trim(&#x27;&quot;&#x27;);  12:     }  13:     yield return dic;  14: }&#xA;&#xA;Those are a lot of strings that we are allocating. And if we are reading a large file, that can very quickly turn into a major performance issue. If I was writing the same in C, for example, I would be re-using the allocated string multiple times, but here we&#x2019;ve to allocate and discard them pretty much continuously.&#xA;The really sad thing about it, it is incredibly easy to do this, usually without paying any attention. But even if you know what you are doing, you pretty much have to roll your own everything to get it to work. And that sucks quite badly.</p>
        </article>
        <div class="button flex justify-between">
            <a href="390.html"><span class="back arrow"></span></a>

            <a href="392.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>
</body>
</html>