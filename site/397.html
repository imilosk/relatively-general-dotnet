
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 397 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
    <!-- Google Analytics -->
    <script>
        // Only load GA if consent is given
        function loadGA() {
            const script = document.createElement('script');
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-MDFXJY3FCY';
            script.async = true;
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }

            gtag('js', new Date());
            gtag('config', 'G-MDFXJY3FCY');
        }

        // Check if consent was previously given
        if (localStorage.getItem('cookieConsent') === 'accepted') {
            loadGA();
        }
    </script>
    <!-- End Google Analytics -->
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-3961">
            <a href="https://ayende.com/blog/166017/ravendb-conference-status-update" target="_blank">
                <h2 class="title mb-6" id="article-3961">RavenDB Conference Status Update</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 18, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">As you probably know, we have the RavenDB Conference coming up in a few weeks. This is the very first conference that we are doing, and to say that we are excited would be a major understatement. We are going to have speakers talk about RavenDB from all angles. From the development team (including yours truly) to the operation guys behind RavenHQ as well as customers and consultants that can share their real world experience about how to best utilize RavenDB. The idea is to have an intimate gathering, and for the very first time, to actually have direct way to talk with all of our users, as well as share a lot of the stuff that happens behind the scenes. Not to mention, we crave feedback, and several key features of RavenDB were actually proposed by the community and then implemented by us. I was reviewing the registration numbers for the conference and it looks like we have made a&#x2026; miscalculation. The idea with the conference was to charge just enough to ensure a commitment to come, to avoid the plague of free conferences where many people sign up and most never come. We even offset things so you can pay 89$ for the conference and you get a 90$ coupon for RavenDB. On the side, since we are already there, we also setup an additional 3 days course for an in-depth look at RavenDB. But we had a lot more demand for the conference and the course than we thought we would have. We currently have just 2 places open for the course, and about 15 &#x2013; 20 places open for the conference.  Since the course is more expensive, that was a the kind of surprise that is actually kinda nice to have: &#x201C;Wait, you mean that they are giving us more money than we thought they would&#x2026;&#x201D;  At any rate, I find myself in the strange situation of encouraging people to go and buy the cheaper product, simply because we are really going to have no more room for the course soon. You can register here, I&#x2019;m looking forward to seeing you all.</p>
        </article>
        <article id="article-3962">
            <a href="https://www.meziantou.net/windows-data-protection-api-dpapi.htm" target="_blank">
                <h2 class="title mb-6" id="article-3962">Windows Data Protection API (DPAPI)</h2>
            </a>
            <p class="mb-2">by G&#xE9;rald Barr&#xE9;</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 18, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">J&#x27;ai &#xE9;crit un article sur un autre blog:Dans mon pr&#xE9;c&#xE9;dent article je vous ai pr&#xE9;sent&#xE9; les diff&#xE9;rentes fa&#xE7;ons de sauvegarder une information lorsque l&#x27;on n&#x27;a pas besoin de pouvoir retrouver l&#x27;information initiale. Cependant dans certains cas on souhaite prot&#xE9;ger une donn&#xE9;e afin que tout le monde ne</p>
        </article>
        <article id="article-3963">
            <a href="https://ayende.com/blog/165955/raft-as-the-raven-flies" target="_blank">
                <h2 class="title mb-6" id="article-3963">Raft, as the Raven flies</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 17, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The interesting thing about the etcd / go-raft review wasn&#x2019;t so much what they did, they did things quite beautifully, but the things that I wanted them to do that they didn&#x2019;t do. The actual implementation was fascinating, and for the purposes of what is required, more than adequate. I, however, have a very specific goal in mind, and that means that this is really not going to work with the given implementations. I&#x2019;ve better explain first. I&#x2019;m not sure if go-raft was written by the same people as etcd, but they do &#x201C;smell&#x201D; very much the same. It just occurred to me that yes, they are actually both on github, so I checked it appears that I was correct. xiangli-cmu, philips, benbjohnson and bcwaldon (among many others) have worked on both projects. The reason this is important is that this reinforce my feeling that go-raft was written mainly to serve the need of etcd. Anyway&#x2026; The reason that I think that is that the implementation is very much optimized at the level etcd needs it. What I mean is that there is a lot of work there to support multiple concurrent operations that would be batched to all the nodes in the cluster, then be applied in the in memory model. This work because etcd is a set of key/value pairs that are shared among many nodes, but they are usually very small values, and very small number of keys. I would be surprised if there were hundreds of thousands of keys in a single etcd installation. That just isn&#x2019;t the type of thing that it is meant to do. And that reflects throughout.  For example, there is an inherit assumption through the codebase, that the data set is small, the each value is small, etc. When sending a snapshot over the wire, there is the assumption that it can all fit in memory and that this is a good thing to do so. Even more to the point, the system where we only push entries to the nodes on heartbeats is great when you are trying to batch multiple changes together, with each change being independent of all the others (usually). However, that really doesn&#x2019;t work when what you actually need is something like the sort of things that we usually deal with. I want to emphasize that I&#x2019;m really evaluating the way etcd &amp; go-raft are built and find them wanting for my own purposes, I think that they are doing quite great for the kind of problem that they are meant to solve. Let us consider the kind of databases that we have. We usually have to deal with much larger values, typical documents are in the KB range, and are frequently hundreds of KB in size. We also tend to have quite a lot of them. Trying to put them all in memory (the etcd way) would be&#x2026; suboptimal. Now, one option would be to try and do just that, and have each operation in RavenDB (put/delete documents) as a state machine command in Raft. The problem is that this really gets complicated very quickly, leaving aside the fact that it isn&#x2019;t a general solution, and we really want to try to get to a general solution.  We don&#x2019;t want to solve this once for RavenDB, and then for RavenFS, and then for&#x2026; etc. And the reason that working at that level is tricky is that you need to push everything through the state machine, and everything in this case really does mean everything. That lead to a very different database design and implementation. It is also probably not really necessary. We can drop this a level or two down and instead of dealing at the database level, we can deal with that at the storage layer level. This is basically just an extension of the log shipping idea. Instead of using Raft for high level commands, just use Raft to create a consensus around the sequence of writes to the journal. That means that all the nodes will have the same journal, and thus have the same data in the storage. That in turn means that an &#x201C;entry&#x201D; can actually be pretty large (mutli MB range, sometimes). And because the journal is purely sequential, we need to issue that command to all the nodes as soon as it is submitted to the Raft state machine.  Now, the reason that the go-raft implementation waits for the heartbeat is that it batches things up nicely, and really speed up the general case. But we don&#x2019;t need to do that for what we are going to do. Or, to be rather more exact, we have already done just that. That is basically what Voron&#x2019;s transaction merging is all about. And since we can only handle writes as the leader, and since we will merge concurrent writes anyway, that is going to end up as a very similar behavior under load, and faster without load. At least that is what the initial thinking is saying. Snapshots, also something quite important for Raft, can be handle very simply by just doing a backup/restore over the network, by streaming all the data.  And the rest is just implementing Raft .</p>
        </article>
        <article id="article-3964">
            <a href="https://ayende.com/blog/165954/the-downsides-of-going-big" target="_blank">
                <h2 class="title mb-6" id="article-3964">The downsides of going big</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 14, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">One of the things that I found out is that as Hibernating Rhinos grows (and we currently have over a dozen people working full time), I&#x2019;m seeing two very interesting changes in my own behavior. The actual velocity is increasing by leaps &amp; bounds. We can do a lot more now, and we can do that faster and with a greater degree of parallelism. My personal development is growing less, as I am doing a lot more of business type things. One aspect of that is that I do a lot of reading of contracts, legalese, and other stuff that takes time from actual development work. I try to compensate by running the tests while I&#x2019;m reading contracts, and then I found the following in a contract I&#x2019;m reviewing:  Nice to know where that stand. And I emphasize.</p>
        </article>
        <article id="article-3965">
            <a href="https://ayende.com/blog/165985/ravendb-success-stories-codealike" target="_blank">
                <h2 class="title mb-6" id="article-3965">RavenDB Success Stories: Codealike</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 13, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I just run into the following case study from Microsoft:  We were amazed by how simple it was to embed RavenDB into our Windows Azure application. This gave us a huge advantage in getting our solution to market in just six weeks. Federico Andres LoisCo-Founder, Codealike</p>
        </article>
        <article id="article-3966">
            <a href="https://ayende.com/blog/165729/stack-overflow-yeah-right" target="_blank">
                <h2 class="title mb-6" id="article-3966">Stack overflow&#x2026; yeah, right!</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 12, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">My app crashed with stack overflow exception. That would be fine, except:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;&#xA0;&#xA;&#xA;&#x9;To be fair, that was under low memory conditions, since I was leaking virtual memory. So that make&#xA0;sense, still...</p>
        </article>
        <article id="article-3967">
            <a href="https://ayende.com/blog/165889/reviewing-go-raft-part-ii" target="_blank">
                <h2 class="title mb-6" id="article-3967">Reviewing go-raft, part II</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 11, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In my previous post, I started to go over the go-raft implementation, after being interrupted by the need to sleep, I decided to go on with this, but I wanted to expand a bit first about the issue we discussed earlier, not checking the number of bytes read in log_entry&#x2019;s Decode.  Let us assume that we actually hit that issue, what would happen?  The process goes like this, we try to read a value, but the Read method only return some of the information. We explicitly ignore that, and try to use the buffer anyway. Best case scenario, we are actually getting an error, so we bail early. At that point, we detect the error and truncate the file. Hello data loss, nice to see you. For fun, this is the best case scenario. It is worse if we marshal the partial data without an error. Then we have not the case of &#x201C;oh, we have a node that is somehow way behind&#x201D;, we have the case of &#x201C;this node actually applied different commands than anyone else&#x201D;. I reported this issue, and I&#x2019;m interested to know if my review is in any way correct. With that said, let us move on&#x2026; getEntriesAfter gives us all the in memory entries. That is quite similar to how RavenDB handled indexing, for that matter, so it is amusing. But this applies only to in memory stuff, and it is quite interesting to see how this will interact with other parts of the codebase. setCommitIndex is interesting. In my head, committing something means flushing them to disk. But in Raft&#x2019;s term. Committing something means applying the commands. But the reason it is interesting is that it has some interesting comments on edge cases. So far, I haven&#x2019;t see actually writing to disk, mind. And this one gives me a headache:  Basically, this mean that we need to write the commit index to the beginning of the file. It is also an extremely unsafe operation. What happens if you crash immediately after? Did you change go through, or not? For that matter, there is nothing that prevents the OS from first writing the changes you made to the beginning of the file then whatever else you wrote at the end. So a crash might actually leave you with the commit pointer pointing at corrupted data. Luckily, I don&#x2019;t see anything there actually calling this, though. The truncate method makes my head ache, mostly because it does things like delete data, which makes my itchy. This is called from the server code as part of normal processing of the append entries request. What this does, in effect, is to say something like: I want you to apply this log entry, make sure that your previous log entry is this, and if it isn&#x2019;t, revert it back to this entry.&#xA0; This is how Raft ensure that all the logs are the same across the cluster. Then we have this:     1:  // Appends a series of entries to the log.   2:  func (l *Log) appendEntries(entries []*protobuf.LogEntry) error {   3:      l.mutex.Lock()   4:      defer l.mutex.Unlock()   5:  &#xA0;   6:      startPosition, _ := l.file.Seek(0, os.SEEK_CUR)   7:  &#xA0;   8:      w := bufio.NewWriter(l.file)   9:  &#xA0;  10:      var size int64  11:      var err error  12:      // Append each entry but exit if we hit an error.  13:      for i := range entries {  14:          logEntry := &amp;LogEntry{  15:              log:      l,  16:              Position: startPosition,  17:              pb:       entries[i],  18:          }  19:  &#xA0;  20:          if size, err = l.writeEntry(logEntry, w); err != nil {  21:              return err  22:          }  23:  &#xA0;  24:          startPosition &#x2B;= size  25:      }  26:      w.Flush()  27:      err = l.sync()  28:  &#xA0;  29:      if err != nil {  30:          panic(err)  31:      }  32:  &#xA0;  33:      return nil  34:  }&#xA;&#xA;&#xA;This seems pretty easy to follow, all told. But note the call to sync() there in line 27. And the fact that this translate down to an fsync, which is horrible for performance.&#xA;There is also appendEntry, which appears to be doing the exact same thing as appendEntries and writeEntry. I&#x2019;m guessing that the difference is that appendEntries is called for a follower, and appendEntry is for a leader.&#xA;The last thing to go through in the log.go file is the compact function, which is&#x2026; interesting:&#xA;&#xA;   1:  // compact the log before index (including index)   2:  func (l *Log) compact(index uint64, term uint64) error {   3:      var entries []*LogEntry   4:  &#xA0;   5:      l.mutex.Lock()   6:      defer l.mutex.Unlock()   7:  &#xA0;   8:      if index == 0 {   9:          return nil  10:      }  11:      // nothing to compaction  12:      // the index may be greater than the current index if  13:      // we just recovery from on snapshot  14:      if index &gt;= l.internalCurrentIndex() {  15:          entries = make([]*LogEntry, 0)  16:      } else {  17:          // get all log entries after index  18:          entries = l.entries[index-l.startIndex:]  19:      }  20:  &#xA0;  21:      // create a new log file and add all the entries  22:      new_file_path := l.path &#x2B; &quot;.new&quot;  23:      file, err := os.OpenFile(new_file_path, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0600)  24:      if err != nil {  25:          return err  26:      }  27:      for _, entry := range entries {  28:          position, _ := l.file.Seek(0, os.SEEK_CUR)  29:          entry.Position = position  30:  &#xA0;  31:          if _, err = entry.Encode(file); err != nil {  32:              file.Close()  33:              os.Remove(new_file_path)  34:              return err  35:          }  36:      }  37:      file.Sync()  38:  &#xA0;  39:      old_file := l.file  40:  &#xA0;  41:      // rename the new log file  42:      err = os.Rename(new_file_path, l.path)  43:      if err != nil {  44:          file.Close()  45:          os.Remove(new_file_path)  46:          return err  47:      }  48:      l.file = file  49:  &#xA0;  50:      // close the old log file  51:      old_file.Close()  52:  &#xA0;  53:      // compaction the in memory log  54:      l.entries = entries  55:      l.startIndex = index  56:      l.startTerm = term  57:      return nil  58:  }&#xA;&#xA;&#xA;This code can&#x2019;t actually run on Windows. Which is interesting. The issue here is that it is trying to rename a file that is open on top of another file which is open. Windows does not allow it.&#xA;But the interesting thing here is what this does. We have the log file, which is the persisted state of the in memory entries collection. Every now and then, we compact it by creating a snapshot, and then we create a new file, with only the entries after the newly created snapshot position.&#xA;So far, so good, and that gives me a pretty good feeling regarding how the whole thing is structured. Next in line, the peer.go file. This represent a node&#x2019;s idea about what is going on in the another node in the cluster. I find the heartbeat code really interesting:&#xA;// Starts the peer heartbeat.&#xA;func (p *Peer) startHeartbeat() {&#xA;    p.stopChan = make(chan bool)&#xA;    c := make(chan bool)&#xA;    go p.heartbeat(c)&#xA;    &lt;-c&#xA;}&#xA;&#xA;// Stops the peer heartbeat.&#xA;func (p *Peer) stopHeartbeat(flush bool) {&#xA;    p.stopChan &lt;- flush&#xA;}&#xA;&#xA;// Listens to the heartbeat timeout and flushes an AppendEntries RPC.&#xA;func (p *Peer) heartbeat(c chan bool) {&#xA;    stopChan := p.stopChan&#xA;&#xA;    c &lt;- true&#xA;&#xA;    ticker := time.Tick(p.heartbeatInterval)&#xA;&#xA;    debugln(&quot;peer.heartbeat: &quot;, p.Name, p.heartbeatInterval)&#xA;&#xA;    for {&#xA;        select {&#xA;        case flush := &lt;-stopChan:&#xA;            if flush {&#xA;                // before we can safely remove a node&#xA;                // we must flush the remove command to the node first&#xA;                p.flush()&#xA;                debugln(&quot;peer.heartbeat.stop.with.flush: &quot;, p.Name)&#xA;                return&#xA;            } else {&#xA;                debugln(&quot;peer.heartbeat.stop: &quot;, p.Name)&#xA;                return&#xA;            }&#xA;&#xA;        case &lt;-ticker:&#xA;            start := time.Now()&#xA;            p.flush()&#xA;            duration := time.Now().Sub(start)&#xA;            p.server.DispatchEvent(newEvent(HeartbeatEventType, duration, nil))&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;Start heartbeat starts a new heartbeat, and then wait under the heartbeat function notify it that it has started running. &#xA;What is confusing is the reference to the peer&#x2019;s server. Peer is defined as:&#xA;// A peer is a reference to another server involved in the consensus protocol.&#xA;type Peer struct {&#xA;    server            *server&#xA;    Name              string `json:&quot;name&quot;`&#xA;    ConnectionString  string `json:&quot;connectionString&quot;`&#xA;    prevLogIndex      uint64&#xA;    mutex             sync.RWMutex&#xA;    stopChan          chan bool&#xA;    heartbeatInterval time.Duration&#xA;}&#xA;&#xA;&#xA;&#xA;And it seems logical to think that this is a remote peer&#x2019;s server, but this is actually the local server reference, not the remote one. Note that it is actually the flush method that does the remote call.&#xA;Flush is defined as:&#xA;func (p *Peer) flush() {&#xA;    debugln(&quot;peer.heartbeat.flush: &quot;, p.Name)&#xA;    prevLogIndex := p.getPrevLogIndex()&#xA;    term := p.server.currentTerm&#xA;&#xA;    entries, prevLogTerm := p.server.log.getEntriesAfter(prevLogIndex, p.server.maxLogEntriesPerRequest)&#xA;&#xA;    if entries != nil {&#xA;        p.sendAppendEntriesRequest(newAppendEntriesRequest(term, prevLogIndex, prevLogTerm, p.server.log.CommitIndex(), p.server.name, entries))&#xA;    } else {&#xA;        p.sendSnapshotRequest(newSnapshotRequest(p.server.name, p.server.snapshot))&#xA;    }&#xA;}&#xA;&#xA;&#xA;The interesting thing here is that the entries collection might be empty (in which case this serve as just a heartbeat). Another thing that pops to mind is that this has an explicitly leader instructing follower to generate snapshots. The Raft paper suggested that this is something that would happen locally on each server on an independent basis.&#xA;There is a lot of interesting behavior in sendAppendEntriesRequest(), not so much in what it does, as in how it handles replies. There is a lot of state going on there. It&#x2019;s very well commented, so I&#x2019;ll let you read it, there isn&#x2019;t anything that is actually going on that is complex.&#xA;What is fascinating is that while the transport layer for go-raft is HTTP, which is inherently request/response. It actually handles this in an interesting fashion:&#xA;&#xA;Requests are synchronous&#xA;On reply, the in memory state of the peer is updated immediately&#xA;The response from the peer is queued to be handled by the server event loop&#xA;The end result is that a lot of the handling is centralized into a really pretty state machine. The rest of what is going on there is not very interesting, except for snapshots, but those are covered elsewhere.&#xA;And now, we are ready to actually go and look at the server code, but&#x2026; not yet. It is over thousand lines of code, so I think that I&#x2019;ll go over other stuff first. In particular, snapshotting looks interesting.&#xA;&#xA;This is actually quite depressing. Note the State properties here. There is an implicit assumption that it is possible / advisable to go with the entire in memory state like that. I know that I am sensitive to such things, but that seems like an aweful lot of waste when talking about large systems.&#xA;Here is one such issue:&#xA;&#xA;Let us assume that our state is big, hundreds of MB or maybe a few GB in size.&#xA;We currently hold it in memory inside the Snaphsot.STate, then we marshal that to json. Now, I actually had to go and check, but Go&#x2019;s json package actually does the usual thing and encode a byte array as a base 64 formatted string. What that means, in turn, is that you have an overhead of about 25% that you have to deal with, and this is all allocated in main memory. And then you write it to a file. &#xA;This is&#x2026;. quite insane, to be frank.&#xA;Assuming that I have a state that is 100 MB in size, I&#x2019;m going to hold all of that in memory, then allocate another 125MB just to hold the json state, then write it to a file. Why not write it to a file directly in the first place? (You could do CRC along the way).&#xA;The whole thing appear to be assuming small sizes of data. Throughout the entire codebase, actually.&#xA;And now, I have no other ways to avoid it, we are going into the server.go itself&#x2026;&#xA;There is a lot of boilerplate stuff there, but the first interesting thing happens when we look at how to apply the log:&#xA;&#xA;&#xA;This says, when we need to apply it, execute the command method on my state. A lot of the other methods are some variant of:&#xA;&#xA;Nothing to see here at all.&#xA;And we finally get to the key part, the event loop:&#xA;&#xA;Let us look in detail on the followerLoop. Inside that function, we have a loop that waits for:&#xA;&#xA;Stop signal, which would lead to us shutting down&#x2026;&#xA;We got an event on our queue&#x2026;&#xA;The timeout for an event has expired&#x2026;&#xA;There is one part there that puzzles me:&#xA;&#xA;promotable will return true if the log has any entries at all. I&#x2019;m not really sure why that is the case, to be honest. In particular, what about the case when we start with an empty server. I&#x2019;m going to go on reading the code, and we&#x2019;ll see where it leads us. And it leads us to:&#xA;&#xA;So next we need to figure out what is this self join stuff. I am not sure if that is something comes from Raft or from an external source. I found this issue that discusses this, but it isn&#x2019;t very helpful in terms of understanding who issue the self join command. I tried looking at the etcd codebase, but I didn&#x2019;t find anything so far. I&#x2019;ll leave it for now.&#xA;The rest of the operations are basically just forwarding the calls to the appropriate methods if they are in the allowed state.&#xA;The caniddateLoop method isn&#x2019;t anything special, it follows the Raft paper pretty nicely, although I have to admit the &#x201C;candidate becomes follower upon Append Entries command&#x201D; is buried deep. The same is true for the other behaviors. The appropriate state based responses sometimes are hard to figure out, because you have the state loop, then you have the same apparent behavior everywhere. For example, we need to become follower if we get an Append Entries request. That happens in processAppendEntriesRequest(), but it would actually be easier to see this if we had code duplication. This is a case where getting familiar with the codebase would help understanding it, and I don&#x2019;t think that this would be a change worth doing, anyway.&#xA;Probably the most interesting behavior is in the leadershipLoop when we process a command. A command is added to the server queue using a Do(Command) method. It is then processed in processCommand.&#xA;The problem here is that commands are actually appended to the log, and then sent to peers using the heartbeat interval. By default, that stand at 50 ms.&#xA;This is great and all, but it does mean that the latency for requests is going to suffer. This doesn&#x2019;t matter that much for something like etcd. The assumption here is that the requests are all going to be on different things, so we can queue a lot of commands and get pretty good speed overall. It is a problem if in our system, we have to process sequential operations. In that mode, we can&#x2019;t wait until the heartbeat, and we want to process this right away. I&#x2019;ll discuss this later,I think. It is a very important property of this implementation (but not for Raft in general).&#xA;Looking at the snapshot state, this happens when a follower get this a SnapshotRequest, but I don&#x2019;t see anywhere that send it. Maybe it is another caller originated thing?&#xA;I just looked at the etcd source, and I think that I confirmed that both behaviors are there in the etcd source. So I think that that explains it.&#xA;And this is it, basically. I have some thoughts about the implementation of this and of etcd, but I think that this is enough for now&#x2026; I&#x2019;ll post them in my next post.</p>
        </article>
        <article id="article-3968">
            <a href="https://ayende.com/blog/165953/getting-ready-for-ravendb-conf-behind-the-scenes" target="_blank">
                <h2 class="title mb-6" id="article-3968">Getting ready for RavenDB Conf&#x2013;Behind the scenes</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 11, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Get a look behind the scenes for what we are doing for RavenDB Conference.   http://conference.ravendb.net</p>
        </article>
        <article id="article-3969">
            <a href="https://ayende.com/blog/165858/reviewing-go-raft-part-i" target="_blank">
                <h2 class="title mb-6" id="article-3969">Reviewing go-raft, part I</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 10, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">After going over the etcd codebase, I decided that the raft portion of this is deserving a much stronger look. The project is here, and I am reviewing commit: 30f261bfe873561c2c75b6206ba1f62a42dbc8d6 Again, I strong recommend reading the Raft paper. It is quite good. At any rate, assuming that you understand Raft, let us get cracking. This time, I&#x2019;m reading this in Sublime Text. As usual, I&#x2019;m reading in lexicographical order, and I&#x2019;m starting from append_entires.go AppendEntries is at the very heart of Raft, so I was pleased to see it here: // The request sent to a server to append entries to the log.&#xA;type AppendEntriesRequest struct {&#xA;    Term         uint64&#xA;    PrevLogIndex uint64&#xA;    PrevLogTerm  uint64&#xA;    CommitIndex  uint64&#xA;    LeaderName   string&#xA;    Entries      []*protobuf.LogEntry&#xA;}&#xA;&#xA;&#xA;// The response returned from a server appending entries to the log.&#xA;type AppendEntriesResponse struct {&#xA;    pb     *protobuf.AppendEntriesResponse&#xA;    peer   string&#xA;    append bool&#xA;}&#xA;&#xA;&#xA;However, I didn&#x2019;t really understand this code. It seemed circular, at least until I realized that we also have a whole lot of generated files. See:&#xA;&#xA;The actual protobuf semantics are (excluding a lot of stuff, of course):&#xA;message LogEntry {&#xA;    required uint64 Index=1;&#xA;    required uint64 Term=2;&#xA;    required string CommandName=3;&#xA;    optional bytes Command=4; // for nop-command&#xA;}&#xA;&#xA;message AppendEntriesRequest {&#xA;    required uint64 Term=1;&#xA;    required uint64 PrevLogIndex=2;&#xA;    required uint64 PrevLogTerm=3;&#xA;    required uint64 CommitIndex=4;&#xA;    required string LeaderName=5;&#xA;    repeated LogEntry Entries=6;&#xA;}&#xA;&#xA;message AppendEntriesResponse {&#xA;    required uint64 Term=1;&#xA;    required uint64 Index=2;&#xA;    required uint64 CommitIndex=3;&#xA;    required bool   Success=4;&#xA;}&#xA;&#xA;&#xA;So, goraft (which I always read as graft) is using protocol buffers as its wire format. Note in particular that the LogEntry contain the full content of a command. That AppendEntriesRequest has an array of them, and that the AppendEntriesResponse is setup separately. That means that it is very natural to use a one way channel for communication. Even though we do request response, there is a high degree of separation between the request &amp; reply. Indeed, from reading the code in etcd, I thought that was the case. &#xA;There is something that really bothers me, though. I noticed that in etcd&#x2019;s codebase as well. This is things like this:&#xA;// Encodes the AppendEntriesRequest to a buffer. Returns the number of bytes&#xA;// written and any error that may have occurred.&#xA;func (req *AppendEntriesRequest) Encode(w io.Writer) (int, error) {&#xA;    pb := &amp;protobuf.AppendEntriesRequest{&#xA;        Term:         proto.Uint64(req.Term),&#xA;        PrevLogIndex: proto.Uint64(req.PrevLogIndex),&#xA;        PrevLogTerm:  proto.Uint64(req.PrevLogTerm),&#xA;        CommitIndex:  proto.Uint64(req.CommitIndex),&#xA;        LeaderName:   proto.String(req.LeaderName),&#xA;        Entries:      req.Entries,&#xA;    }&#xA;&#xA;    p, err := proto.Marshal(pb)&#xA;    if err != nil {&#xA;        return -1, err&#xA;    }&#xA;&#xA;    return w.Write(p)&#xA;}&#xA;&#xA;&#xA;I&#x2019;m not sure about the actual semantics of memory allocations in Go, but let us assume that we had a single ,log entry with 1KB for the command data. This means that we would have the command data:&#xA;&#xA;Once in the LogEntry inside the AppendEntriesRequest&#xA;Once in the protocol buffers byte array returned from Marshal&#xA;There doesn&#x2019;t appear to be any way to directly stream things. Maybe it is usually dealing with small amounts of data, maybe they didn&#x2019;t notice, or maybe something in Go make this very efficient, but I doubt it.&#xA;The next interesting part is Command handling. Raft is all about reaching a consensus on the order of executing a set of commands in a cluster. So it is really interesting to see it being handled with Go&#x2019;s interfaces.&#xA;// Command represents an action to be taken on the replicated state machine.&#xA;type Command interface {&#xA;    CommandName() string&#xA;}&#xA;&#xA;// CommandApply represents the interface to apply a command to the server.&#xA;type CommandApply interface {&#xA;    Apply(Context) (interface{}, error)&#xA;}&#xA;&#xA;type CommandEncoder interface {&#xA;    Encode(w io.Writer) error&#xA;    Decode(r io.Reader) error&#xA;}&#xA;&#xA;&#xA;We have some additional things about serializing commands and reading them back, but nothing beyond this. The Commands.go file, however, is of a little bit more interest. Let us look at the join command:&#xA;// Join command interface&#xA;type JoinCommand interface {&#xA;    Command&#xA;    NodeName() string&#xA;}&#xA;&#xA;// Join command&#xA;type DefaultJoinCommand struct {&#xA;    Name             string `json:&quot;name&quot;`&#xA;    ConnectionString string `json:&quot;connectionString&quot;`&#xA;}&#xA;&#xA;&#xA;// The name of the Join command in the log&#xA;func (c *DefaultJoinCommand) CommandName() string {&#xA;    return &quot;raft:join&quot;&#xA;}&#xA;&#xA;func (c *DefaultJoinCommand) Apply(server Server) (interface{}, error) {&#xA;    err := server.AddPeer(c.Name, c.ConnectionString)&#xA;&#xA;    return []byte(&quot;join&quot;), err&#xA;}&#xA;&#xA;func (c *DefaultJoinCommand) NodeName() string {&#xA;    return c.Name&#xA;}&#xA;&#xA;&#xA;&#xA;I&#x2019;m not sure when we have an interface for JoinCommand, then a default implementation like that. I saw that elsewhere in etcd, it might be a Go pattern. Note that the JoinCommand is an interface that embeds another interface (Command, in this case, obviously).&#xA;Note that you have the Apply function to actually handle the real work, in this case, add a peer.&#xA0; There is nothing interesting in config.go, debug.go or context.go but event.go is puzzling. To be fair, I am really at a loss to explain this style:&#xA;// Event represents an action that occurred within the Raft library.&#xA;// Listeners can subscribe to event types by using the Server.AddEventListener() function.&#xA;type Event interface {&#xA;    Type() string&#xA;    Source() interface{}&#xA;    Value() interface{}&#xA;    PrevValue() interface{}&#xA;}&#xA;&#xA;// event is the concrete implementation of the Event interface.&#xA;type event struct {&#xA;    typ       string&#xA;    source    interface{}&#xA;    value     interface{}&#xA;    prevValue interface{}&#xA;}&#xA;&#xA;// newEvent creates a new event.&#xA;func newEvent(typ string, value interface{}, prevValue interface{}) *event {&#xA;    return &amp;event{&#xA;        typ:       typ,&#xA;        value:     value,&#xA;        prevValue: prevValue,&#xA;    }&#xA;}&#xA;&#xA;// Type returns the type of event that occurred.&#xA;func (e *event) Type() string {&#xA;    return e.typ&#xA;}&#xA;&#xA;// Source returns the object that dispatched the event.&#xA;func (e *event) Source() interface{} {&#xA;    return e.source&#xA;}&#xA;&#xA;// Value returns the current value associated with the event, if applicable.&#xA;func (e *event) Value() interface{} {&#xA;    return e.value&#xA;}&#xA;&#xA;// PrevValue returns the previous value associated with the event, if applicable.&#xA;func (e *event) PrevValue() interface{} {&#xA;    return e.prevValue&#xA;}&#xA;&#xA;&#xA;&#xA;Why go to all this trouble to define things this way? It seems like a lot of boiler plate code. It would be easier to just expose a struct directly. I am assuming that this is done so you can send other things than the event struct, with additional information as well. In C# you&#x2019;ll do that by subsclassing the event, but you cannot do that in Go. A better alternative might have been to just have a tag / state field in the struct and let it go that way, though.&#xA;event_dispatcher.go is just an implementation of a dictionary of string to events, nothing much beyond that. A lot of boiler plate code, too.&#xA;http_transporter.go is next, and is a blow to my hope that this will do a one way messaging system. I&#x2019;m thinking about doing Raft over ZeroMQ or NanoMSG. Here is the actual process of sending data over the wire:&#xA;// Sends an AppendEntries RPC to a peer.&#xA;func (t *HTTPTransporter) SendAppendEntriesRequest(server Server, peer *Peer, req *AppendEntriesRequest) *AppendEntriesResponse {&#xA;    var b bytes.Buffer&#xA;    if _, err := req.Encode(&amp;b); err != nil {&#xA;        traceln(&quot;transporter.ae.encoding.error:&quot;, err)&#xA;        return nil&#xA;    }&#xA;&#xA;    url := joinPath(peer.ConnectionString, t.AppendEntriesPath())&#xA;    traceln(server.Name(), &quot;POST&quot;, url)&#xA;&#xA;    t.Transport.ResponseHeaderTimeout = server.ElectionTimeout()&#xA;    httpResp, err := t.httpClient.Post(url, &quot;application/protobuf&quot;, &amp;b)&#xA;    if httpResp == nil || err != nil {&#xA;        traceln(&quot;transporter.ae.response.error:&quot;, err)&#xA;        return nil&#xA;    }&#xA;    defer httpResp.Body.Close()&#xA;&#xA;    resp := &amp;AppendEntriesResponse{}&#xA;    if _, err = resp.Decode(httpResp.Body); err != nil &amp;&amp; err != io.EOF {&#xA;        traceln(&quot;transporter.ae.decoding.error:&quot;, err)&#xA;        return nil&#xA;    }&#xA;&#xA;    return resp&#xA;}&#xA;&#xA;&#xA;This is very familiar territory for me, I have to say . Although, again, there is a lot of wasted memory here by encoding the data multiple times, instead of streaming it directly.&#xA;And here is how it receives information:&#xA;// Handles incoming AppendEntries requests.&#xA;func (t *HTTPTransporter) appendEntriesHandler(server Server) http.HandlerFunc {&#xA;    return func(w http.ResponseWriter, r *http.Request) {&#xA;        traceln(server.Name(), &quot;RECV /appendEntries&quot;)&#xA;&#xA;        req := &amp;AppendEntriesRequest{}&#xA;        if _, err := req.Decode(r.Body); err != nil {&#xA;            http.Error(w, &quot;&quot;, http.StatusBadRequest)&#xA;            return&#xA;        }&#xA;&#xA;        resp := server.AppendEntries(req)&#xA;        if _, err := resp.Encode(w); err != nil {&#xA;            http.Error(w, &quot;&quot;, http.StatusInternalServerError)&#xA;            return&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;Really there is nothing much to write home about, to be frank. All of the operations are like that, just encoding/decoding and forwarding the code to the right function. I&#x2019;m skipping log.go in favor of going to log_entry.go for a moment. The log is really important in Raft, so I want to focus on small chewables first.&#xA;If the user don&#x2019;t provide an encoder for a command, it will be converted using json, then serialized to a writer using protocol buffers format.&#xA;One thing that I did notice that was interesting was a bug in decoding from a ptorocol buffer stream:&#xA;// Decodes the log entry from a buffer. Returns the number of bytes read and&#xA;// any error that occurs.&#xA;func (e *LogEntry) Decode(r io.Reader) (int, error) {&#xA;&#xA;    var length int&#xA;    _, err := fmt.Fscanf(r, &quot;%8x\n&quot;, &amp;length)&#xA;    if err != nil {&#xA;        return -1, err&#xA;    }&#xA;&#xA;    data := make([]byte, length)&#xA;    _, err = r.Read(data)&#xA;&#xA;    if err != nil {&#xA;        return -1, err&#xA;    }&#xA;&#xA;    if err = proto.Unmarshal(data, e.pb); err != nil {&#xA;        return -1, err&#xA;    }&#xA;&#xA;    return length &#x2B; 8 &#x2B; 1, nil&#xA;}&#xA;&#xA;&#xA;&#xA;Do you see the bug?&#xA;It is in the reading of the data from the reader. A reader may decide to read less than the data that was requested. In this case, I&#x2019;m assuming that it is always sending fully materialized readers to the Decode method, not surprising given how often it will create in memory buffers for the entire dataset. Still.. that isn&#x2019;t nice to do, and it can create the most subtle and hard to understand bugs.&#xA;And now, into the Log!&#xA;// A log is a collection of log entries that are persisted to durable storage.&#xA;type Log struct {&#xA;    ApplyFunc   func(*LogEntry, Command) (interface{}, error)&#xA;    file        *os.File&#xA;    path        string&#xA;    entries     []*LogEntry&#xA;    commitIndex uint64&#xA;    mutex       sync.RWMutex&#xA;    startIndex  uint64 // the index before the first entry in the Log entries&#xA;    startTerm   uint64&#xA;}&#xA;&#xA;// The results of the applying a log entry.&#xA;type logResult struct {&#xA;    returnValue interface{}&#xA;    err         error&#xA;}&#xA;&#xA;&#xA;There are a few things that we can notice right now. First, ApplyFunc is how we control the application of stuff to the in memory state, I am assuming. Given that applying the log can only happen after we have a consensus and probably fsynced to disk, it makes sense to invoke it from here.&#xA;Then, we also have a file, so that is where we are actually doing a lot of the interesting stuff, like actual storage IO and things like that. The in memory events array is also interesting, mostly because I wonder just how big it is, and when it is getting truncated. I think that the way it works, we have the log properties, which likely represent the flushed to disk state, and the entries represent the yet to be flushed state.&#xA;Things get interesting in the open method, which is called to create new log or recover an existing one. The interesting parts (recovery) is here:&#xA;// Read the file and decode entries.&#xA;for {&#xA;    // Instantiate log entry and decode into it.&#xA;    entry, _ := newLogEntry(l, nil, 0, 0, nil)&#xA;    entry.Position, _ = l.file.Seek(0, os.SEEK_CUR)&#xA;&#xA;    n, err := entry.Decode(l.file)&#xA;    if err != nil {&#xA;        if err == io.EOF {&#xA;            debugln(&quot;open.log.append: finish &quot;)&#xA;        } else {&#xA;            if err = os.Truncate(path, readBytes); err != nil {&#xA;                return fmt.Errorf(&quot;raft.Log: Unable to recover: %v&quot;, err)&#xA;            }&#xA;        }&#xA;        break&#xA;    }&#xA;    if entry.Index() &gt; l.startIndex {&#xA;        // Append entry.&#xA;        l.entries = append(l.entries, entry)&#xA;        if entry.Index() &lt;= l.commitIndex {&#xA;            command, err := newCommand(entry.CommandName(), entry.Command())&#xA;            if err != nil {&#xA;                continue&#xA;            }&#xA;            l.ApplyFunc(entry, command)&#xA;        }&#xA;        debugln(&quot;open.log.append log index &quot;, entry.Index())&#xA;    }&#xA;&#xA;    readBytes &#x2B;= int64(n)&#xA;}&#xA;&#xA;&#xA;This is really interesting, because it is actually sending the raw file to the Decode function, unlike what I expected. The reason this is surprising is that there&#xA0;is a strong likelihood that the OS&#xA0; will actually return less data than requested. As it turns out, on Windows, this will never be the case, but it does appear (at least from the contract of the API it ends up calling) that at least on Linux, that is possible. Now, I ended up going all the way to the sys call interface in linux, so I&#x2019;m pretty sure that this can&#x2019;t happen there either, but still&#x2026;&#xA;At any rate, the code appear to be pretty clear. We read the log entry, decode it, (truncating the file if there are any issues) and if need be, we apply it.&#xA;And I think that this is enough for now&#x2026; it is close to 9 PM, and I need to do other things as well. I&#x2019;ll get back to this in my next post.</p>
        </article>
        <article id="article-3970">
            <a href="https://ayende.com/blog/165857/reviewing-etcd" target="_blank">
                <h2 class="title mb-6" id="article-3970">Reviewing etcd</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: March 07, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The etcd project is a project that I stumbled upon that looks interesting. It is a a highly-available key value store for shared configuration and service discovery. It is written in Go and is implemented using Raft. I&#x2019;m reviewing commit&#xA0; 46d817f91b2edf4141081abff7d92a4f71d39248. I don&#x2019;t know Go, and I think that this would be a great way to learn both about Raft (which I am very interested about) and about Go (which I peeked at occasionally, but never really studied). Like some of my other posts, this is likely to be a very long and rambling one. For reading the code, I am using LiteIDE, at least for now. This is what this looks like.  I usually like to do a lexicographical read through the codebase, at least at first. That means that in this case, I have to go through the docs first. Probably not a totally bad idea, but a divergence from my usual approach. Discovery &#x2013; it looks like etcd handled the problem of initial peers selection by&#x2026; going to another etcd cluster, that handle membership information. There is a SaaS offering, it appears (discovery.etcd.io). I like the recursive nature of that, and obviously you can set it up with a static list of peers to start with. The first real code file I saw was this one, bench.go:      1: package main   2:&#xA0;    3: import (   4:     &quot;flag&quot;   5:     &quot;log&quot;   6:     &quot;strconv&quot;   7:&#xA0;    8:     &quot;github.com/coreos/etcd/third_party/github.com/coreos/go-etcd/etcd&quot;   9: )  10:&#xA0;   11: func write(endpoint string, requests int, end chan int) {  12:     client := etcd.NewClient([]string{endpoint})  13:&#xA0;   14:     for i := 0; i &lt; requests; i&#x2B;&#x2B; {  15:         key := strconv.Itoa(i)  16:         _, err := client.Set(key, key, 0)  17:         if err != nil {  18:             println(err.Error())  19:         }  20:     }  21:     end &lt;- 1  22: }  23:&#xA0;   24: func watch(endpoint string, key string) {  25:     client := etcd.NewClient([]string{endpoint})  26:&#xA0;   27:     receiver := make(chan *etcd.Response)  28:     go client.Watch(key, 0, true, receiver, nil)  29:&#xA0;   30:     log.Printf(&quot;watching: %s&quot;, key)  31:&#xA0;   32:     received := 0  33:     for {  34:         &lt;-receiver  35:         received&#x2B;&#x2B;  36:     }  37: }  38:&#xA0;   39: func main() {  40:     endpoint := flag.String(&quot;endpoint&quot;, &quot;http://127.0.0.1:4001&quot;, &quot;etcd HTTP endpoint&quot;)  41:&#xA0;   42:     rWrites := flag.Int(&quot;write-requests&quot;, 50000, &quot;number of writes&quot;)  43:     cWrites := flag.Int(&quot;concurrent-writes&quot;, 500, &quot;number of concurrent writes&quot;)  44:&#xA0;   45:     watches := flag.Int(&quot;watches&quot;, 500, &quot;number of writes&quot;)  46:&#xA0;   47:     flag.Parse()  48:&#xA0;   49:     for i := 0; i &lt; *watches; i&#x2B;&#x2B; {  50:         key := strconv.Itoa(i)  51:         go watch(*endpoint, key)  52:     }  53:&#xA0;   54:     wChan := make(chan int, *cWrites)  55:     for i := 0; i &lt; *cWrites; i&#x2B;&#x2B; {  56:         go write(*endpoint, (*rWrites / *cWrites), wChan)  57:     }  58:&#xA0;   59:     for i := 0; i &lt; *cWrites; i&#x2B;&#x2B; {  60:         &lt;-wChan  61:         log.Printf(&quot;Completed %d writes&quot;, (*rWrites / *cWrites))  62:     }  63: }&#xA;I include the entire file here because it is short, and really quite interesting. This is my first time really reading Go code, so I had to go and read some docs. The first interesting thing is in line 11, when when have &#x201C;end chan int&#x201D;, which defines a channel of integers. This allows cross goroutine (for .NET guys, think tasks / TPL, that isn&#x2019;t actually accurate, but it is close enough) communication, including &#x201C;waiting&#x201D; for results.&#xA;The write func will write the specified number of requests, then push a number to the channel, signifying that it completed its work. That is really quite nice pattern for doing work, considering that there isn&#x2019;t a way to await a goroutine.&#xA;The watch func is a little hard for me to get. Mostly because as far as I understand, it is setting up a watch for a particular key, then just accumulate the number of changes to it in a local variable, and not doing anything else with it.&#xA;The main function is really funny to read. The flag package is fascinating way to handle parameter parsing, and it shows how carefully Go was meant to be a server side language, where command line parsing is really common. The flag package is both powerful and really simple. I think that I&#x2019;ll probably make use of this approach for configuration in RavenDB.&#xA;I love that you define the flag, and then you get a pointer to where that value will be, once you called flag.Parse();&#xA;Note that calls to go [expr] are equivalent for Task.Factory.StartNew([expr]) in .NET (not really, but close enough). The syntax &lt;-wChan, for example, means &#x201C;wait until there is a new value in the channel&#x201D;. Presumably it also translate to something like &#x201C;await channel.DequeueAsync()&#x201D; in C#.&#xA;Next was the config package, where etcd is initializing itself. It was interesting to learn that you can have non global flags using the flag package, so you can use the same code for parsing arguments to a method. But that was about it. Nothing exciting there.&#xA;I&#x2019;m skipping the contrib directory because there is no Go code there, and it doesn&#x2019;t seems relevant for now. I&#x2019;ll note that there is a mix of shell scripts, Python and json code in there, so I&#x2019;m feeling good about ignoring that for now.&#xA;One thing that I really like in Go is that it is very easy to define &#x201C;extension methods&#x201D;, in fact, you usually appear to define structs (data holders), and then you just define a function that takes this as the base argument, and you can call it using method syntax. That makes some things very natural and nice. And it also give you really nice separation between data &amp; behavior.&#xA;I also like the multiple return values option, which gives us a good pattern for reporting errors without getting either crazy syntax or throwing. It also make it clear when we want to ignore errors. Look at this:&#xA;&#xA;&#xA;   1: func (d *Discoverer) findPeers() (peers []string, err error) {   2:     resp, err := d.client.Get(path.Join(d.prefix), false, true)   3:     if err != nil {   4:         return nil, err   5:     }   6:&#xA0;    7:     node := resp.Node   8:&#xA0;    9:     if node == nil {  10:         return nil, fmt.Errorf(&quot;%s key doesn&#x27;t exist.&quot;, d.prefix)  11:     }&#xA;Trying to do this in C, for example, would lead to an explosion of arrow head return values, or the complexities of &#x201C;return zero for error, then get the actual issue from GetLatsError()&#x201D;. Multiple return values results in a much nicer code than that.&#xA;The discovery protocol itself is defined in the docs ,but the code implementing it is really nice. Being able to piggy back on etcd itself to implement discovery is really nice.&#xA;The fixtures directory seems to be filled with certs files, I am not sure what for, but I&#x2019;ll go directly to the http directory and see what is going on there. And there doesn&#x2019;t appear to be anything much, so I&#x2019;m moving on to the next thing that is actually meaningful.&#xA;The metrics section is interesting, mostly because we have been doing the same thing in RavenDB currently. But it all depends on an external package, so I&#x2019;ll skip this for now. The next interesting thing is in the mod folder, where we have the dashboard (html5 app, not interested for me) module, and the leader &amp; lock modules.&#xA;I&#x2019;ll start with the leader module. Where we actually have interesting things. The leader module is actually very literally just proxying stuff to the lock module. It is getting a request, translating that request to a lock module http request, and execute that. Personally, I wouldn&#x2019;t bother with doing this server side, and handle this entirely client side, or by calling the lock module methods directly, instead of proxying the request to the lock module. I am not sure why this approach was choosen:&#xA;&#xA;&#xA;   1: // getHandler retrieves the current leader.   2: func (h *handler) getHandler(w http.ResponseWriter, req *http.Request) error {   3:     vars := mux.Vars(req)   4:&#xA0;    5:     // Proxy the request to the lock service.   6:     url := fmt.Sprintf(&quot;%s/mod/v2/lock/%s?field=value&quot;, h.addr, vars[&quot;key&quot;])   7:     resp, err := h.client.Get(url)   8:     if err != nil {   9:         return err  10:     }  11:     defer resp.Body.Close()  12:&#xA0;   13:     w.WriteHeader(resp.StatusCode)  14:     io.Copy(w, resp.Body)  15:     return nil  16: }&#xA;The lock module is where real stuff is happening. And at the same time, I am not sure at what level exactly this is happening. What appears to be happening is that the lock module, too, is built directly on top of the etcd client, rather than using it directly. This is strange to me, because that isn&#x2019;t the way I would architect it, but I am guessing that this make it easier to work with things, having only a single real external API. On the other hand, having a server make http requests to itself seems very strange to me.&#xA;One thing that really confused me was a lot of references to things that are actually defined in another repository, the client side of etcd in go. Another interesting thing is the way Go implements interfaces. Instead of using explicit interfaces, if a type has all the methods for an interface, it is implementing that interface.&#xA;At this point I decided that I wanted a better IDE and spent some time getting IntelliJ to work with Go. It supports this, and you even get some reference tracking. I couldn&#x2019;t get all of it to work, in particular, external reference weren&#x2019;t tracked, and I didn&#x2019;t really care to see why, so I just left it:&#xA;&#xA;&#xA;At any rate, I was reading the lock module code. In particular, I am not tracking the acquire_handler.go file. It has a major function (acquireHandler)* that actually handle the process of acquiring the lock.&#xA;&#xA;* Sidenote, I like the structure of the code so far, in most files, we have one function, and some supporting functions to help it do some work. It is nice, simple and quite easy to follow.&#xA;The first thing that is done is syncing the cluster information. This is done by going to any of the machines that we already know about and asking them about the current state of the cluster. We take the first response, and presumably, since we are running server side, the first response would always be from us (assuming that the requests end up going to the leader). So there isn&#x2019;t another machine boundary request, but it is still very strange to read it going through so much client operations.&#xA;This code is really interesting:&#xA;&#xA;&#xA;   1:&#xA0;    2:     // Setup connection watcher.   3:     closeNotifier, _ := w.(http.CloseNotifier)   4:     closeChan := closeNotifier.CloseNotify()   5:     stopChan := make(chan bool)&#xA;In C#, that would be setting up a cancellation token for the request being abandoned by the client or we completing some work.&#xA;&#xA;&#xA;   1: // If node exists then just watch it. Otherwise create the node and watch it.              2: node, index, pos := h.findExistingNode(keypath, value)                                     3: if index &gt; 0 {                                                                             4:     if pos == 0 {                                                                             5:         // If lock is already acquired then update the TTL.                                      6:         h.client.Update(node.Key, node.Value, uint64(ttl))                                       7:     } else {                                                                                  8:         // Otherwise watch until it becomes acquired (or errors).                                9:         err = h.watch(keypath, index, nil)                                                      10:     }                                                                                        11: } else {                                                                                  12:     index, err = h.createNode(keypath, value, ttl, closeChan, stopChan)                      13: }                                                                                       &#xA;This is interesting, I am not really able to follow what is going on in the happen case (index &gt; 0) yet. Let us lock at what happens with createNode&#x2026;&#xA;&#xA;&#xA;   1: // createNode creates a new lock node and watches it until it is acquired or acquisition fails.   2: func (h *handler) createNode(keypath string, value string, ttl int, closeChan &lt;-chan bool, stopChan chan bool) (int, error) {   3:     // Default the value to &quot;-&quot; if it is blank.   4:     if len(value) == 0 {   5:         value = &quot;-&quot;   6:     }   7:&#xA0;    8:     // Create an incrementing id for the lock.   9:     resp, err := h.client.AddChild(keypath, value, uint64(ttl))  10:     if err != nil {  11:         return 0, err  12:     }  13:     indexpath := resp.Node.Key  14:     index, _ := strconv.Atoi(path.Base(indexpath))  15:&#xA0;   16:     // Keep updating TTL to make sure lock request is not expired before acquisition.  17:     go h.ttlKeepAlive(indexpath, value, ttl, stopChan)  18:&#xA0;   19:     // Watch until we acquire or fail.  20:     err = h.watch(keypath, index, closeChan)  21:&#xA0;   22:     // Check for connection disconnect before we write the lock index.  23:     if err != nil {  24:         select {  25:         case &lt;-closeChan:  26:             err = errors.New(&quot;user interrupted&quot;)  27:         default:  28:         }  29:     }  30:&#xA0;   31:     // Update TTL one last time if acquired. Otherwise delete.  32:     if err == nil {  33:         h.client.Update(indexpath, value, uint64(ttl))  34:     } else {  35:         h.client.Delete(indexpath, false)  36:     }  37:&#xA0;   38:     return index, err  39: }&#xA;In line 9, we create a child of the key path. Assuming that the key path is foo, this will create an item with foo/1, foo/2, etc. Effectively an auto incrementing number (with no guarantees on the size of the step, mind).&#xA;In line 17 we make sure that we keep this alive, the ttlKeepAlive function is really fun to read:&#xA;&#xA;&#xA;   1: // ttlKeepAlive continues to update a key&#x27;s TTL until the stop channel is closed.   2: func (h *handler) ttlKeepAlive(k string, value string, ttl int, stopChan chan bool) {   3:     for {   4:         select {   5:         case &lt;-time.After(time.Duration(ttl/2) * time.Second):   6:             h.client.Update(k, value, uint64(ttl))   7:         case &lt;-stopChan:   8:             return   9:         }  10:     }  11: }&#xA;The C# translation for this would be:&#xA;&#xA;&#xA;   1: public async Task TtlKeepAlive(string k, string value, int ttl, CancelationToken t)   2: {   3:     while(true)   4:     {   5:         await Task.Delay(ttl, t);   6:         if(t.IsCancelled)   7:           return;   8:         client.Update(k,value, ttl);   9:&#xA0;   10:     }  11: }&#xA;But I really like this Go select syntax. It is very much like Erlang&#x2019;s pattern matching on receive. At any rate, it seems that the magic happens in the watch method. &#xA;&#xA;&#xA;   1: // watch continuously waits for a given lock index to be acquired or until lock fails.   2: // Returns a boolean indicating success.   3: func (h *handler) watch(keypath string, index int, closeChan &lt;-chan bool) error {   4:     // Wrap close chan so we can pass it to Client.Watch().   5:     stopWatchChan := make(chan bool)   6:     stopWrapChan := make(chan bool)   7:     go func() {   8:         select {   9:         case &lt;-closeChan:  10:             stopWatchChan &lt;- true  11:         case &lt;- stopWrapChan:  12:             stopWatchChan &lt;- true  13:         case &lt;- stopWatchChan:  14:         }  15:     }()  16:     defer close(stopWrapChan)  17:&#xA0;   18:     for {  19:         // Read all nodes for the lock.  20:         resp, err := h.client.Get(keypath, true, true)  21:         if err != nil {  22:             return fmt.Errorf(&quot;lock watch lookup error: %s&quot;, err.Error())  23:         }  24:         nodes := lockNodes{resp.Node.Nodes}  25:         prevIndex := nodes.PrevIndex(index)  26:&#xA0;   27:         // If there is no previous index then we have the lock.  28:         if prevIndex == 0 {  29:             return nil  30:         }  31:&#xA0;   32:         // Watch previous index until it&#x27;s gone.  33:         waitIndex := resp.Node.ModifiedIndex  34:&#xA0;   35:         // Since event store has only 1000 histories we should use first node&#x27;s CreatedIndex if available  36:         if firstNode := nodes.First(); firstNode != nil {  37:             waitIndex = firstNode.CreatedIndex  38:         }  39:&#xA0;   40:         _, err = h.client.Watch(path.Join(keypath, strconv.Itoa(prevIndex)), waitIndex, false, nil, stopWatchChan)  41:         if err == etcd.ErrWatchStoppedByUser {  42:             return fmt.Errorf(&quot;lock watch closed&quot;)  43:         } else if err != nil {  44:             return fmt.Errorf(&quot;lock watch error: %s&quot;, err.Error())  45:         }  46:     }  47: }&#xA;I&#x2019;ve to admit, this makes my head hurt, just a little bit.&#xA;But first, the defer syntax Go has is really nice. It is very similar to C#&#x2019;s using statements, but it isn&#x2019;t limited to just a specific interface, and it doesn&#x2019;t introduce a nesting block.&#xA;To go routine in line 7 is interesting. It will wait for a notification from the close channel, the stop watch channel or the wrap channel. And it will forward all of those to the stop watch channel. I&#x2019;m really not sure why this is the case, but let&#x2019;s go with this for now.&#xA;The real interesting work happens in the for loop. We get all the keys in the specified key path. Note that we assume that we only have numeric keys in that &#x201C;directory&#x201D;. And we basically try to find if there is any value that is before our value.&#xA;The easiest way to think about it is in the same way you do when you wait in line in any government queue. You take a number, and you&#x2019;re the first is there is no one with an earlier number than you.&#xA;The interesting bit is how Watch is handled. It is basically going to do a long poll request from the server, and the stopWatchChan is used to notify the Watch method when the user cancelled the request, so we don&#x2019;t need this any longer. I&#x2019;m really not sure why there is a need for stopWrapChan, but&#x2026; at least now I understand what is going on here. We use the numbering system to effectively join a queue. Then we wait until we are at the head of the queue. &#xA;Let us go back to the actual acuireHandler routine, more specifically to the findExistingNode() behavior. If we specified a value, we try to find an existing entry in the path that already have this value. If there isn&#x2019;t a value, we go back to the &#x201C;take a number, wait&#x201D; approach. If there is a value, however, I don&#x2019;t following the logic. The findExistingNode() has three return values. The relevant node with the value, the index (the queue #, effectively), and the position of the specified node in the queue.&#xA;My problem is that I don&#x2019;t understand the logic here. We find a node with the same value as we want, then we check that it is the first in the queue? What happens when we have two clients issuing the same request at the same time? I understand what happens, I don&#x2019;t understand what the intention is.&#xA;As an aside, I think that I understand why a lot of the internal works in the lock module is done over the HTTP layer. The idea here is to only handle the distribution once. And if you route everything through the http interface, that would be it. This way, you don&#x2019;t have to worry about how to handle consistencies, or stuff like that. And the idea is that you have a simple HTTP interface for a complex system like locking. My own preference would be to do this entirely client side, with no server side behavior, but that puts a lot of the onus on the clients, and it is easier to implement server side if you have a lot of clients for many environments.&#xA;Anyway, I think that I found the two pieces that really interests me:&#xA;&#xA;&#xA0;&#xA;Store is probably the on disk storage, something that is very near &amp; dear to my heart. While server is the pieces that I&#x2019;ll probably learn the most from&#x2026;&#xA;I&#x2019;ll start with going over the storage stuff, since that is probably the most familiar to me. Here is the interface for the store:&#xA;&#xA;&#xA;   1: type Store interface {   2:     Version() int   3:     CommandFactory() CommandFactory   4:     Index() uint64   5:&#xA0;    6:     Get(nodePath string, recursive, sorted bool) (*Event, error)   7:     Set(nodePath string, dir bool, value string, expireTime time.Time) (*Event, error)   8:     Update(nodePath string, newValue string, expireTime time.Time) (*Event, error)   9:     Create(nodePath string, dir bool, value string, unique bool,  10:         expireTime time.Time) (*Event, error)  11:     CompareAndSwap(nodePath string, prevValue string, prevIndex uint64,  12:         value string, expireTime time.Time) (*Event, error)  13:     Delete(nodePath string, recursive, dir bool) (*Event, error)  14:     CompareAndDelete(nodePath string, prevValue string, prevIndex uint64) (*Event, error)  15:&#xA0;   16:     Watch(prefix string, recursive, stream bool, sinceIndex uint64) (*Watcher, error)  17:&#xA0;   18:     Save() ([]byte, error)  19:     Recovery(state []byte) error  20:&#xA0;   21:     TotalTransactions() uint64  22:     JsonStats() []byte  23:     DeleteExpiredKeys(cutoff time.Time)  24: }&#xA;This is really interesting, because from the interface alone you can see some really interesting things. For example, The Save() method. That doesn&#x2019;t match any transactional store interface that I can think of. To be fair, it looks to be more in the sense that this is used for snapshots than anything else, but still..&#xA;Those appear to be the core elements of the store:&#xA;&#xA;&#xA;   1: type store struct {                                                        2:     Root           *node                                                      3:     WatcherHub     *watcherHub                                                4:     CurrentIndex   uint64                                                     5:     Stats          *Stats                                                     6:     CurrentVersion int                                                        7:     ttlKeyHeap     *ttlKeyHeap  // need to recovery manually                  8:     worldLock      sync.RWMutex // stop the world lock                        9: }                                                                         10:&#xA0;   11:&#xA0;   12: // node is the basic element in the store system.  13: // A key-value pair will have a string value  14: // A directory will have a children map  15: type node struct {  16:     Path string  17:&#xA0;   18:     CreatedIndex  uint64  19:     ModifiedIndex uint64  20:&#xA0;   21:     Parent *node `json:&quot;-&quot;` // should not encode this field! avoid circular dependency.  22:&#xA0;   23:     ExpireTime time.Time  24:     ACL        string  25:     Value      string           // for key-value pair  26:     Children   map[string]*node // for directory  27:&#xA0;   28:     // A reference to the store this node is attached to.  29:     store *store  30: }&#xA;Again, the ability to return multiple values is really nice, see methods such as:&#xA;&#xA;&#xA;   1: // Read function gets the value of the node.   2: // If the receiver node is not a key-value pair, a &quot;Not A File&quot; error will be returned.   3: func (n *node) Read() (string, *etcdErr.Error) {   4:     if n.IsDir() {   5:         return &quot;&quot;, etcdErr.NewError(etcdErr.EcodeNotFile, &quot;&quot;, n.store.Index())   6:     }   7:&#xA0;    8:     return n.Value, nil   9: }&#xA;This is quite lovely way to handle things. &#xA;However, looking at the Store directory, I am seeing a lot of stuff about modifying the in memory state, but nothing about persistence. I think that this is all handled via Raft. So I&#x2019;ll just move away into reading the server side code now.&#xA;This is the Server interface:&#xA;&#xA;&#xA;   1: type Server interface {   2:     State() string   3:     Leader() string   4:     CommitIndex() uint64   5:     Term() uint64   6:     PeerURL(string) (string, bool)   7:     ClientURL(string) (string, bool)   8:     Store() store.Store   9:     Dispatch(raft.Command, http.ResponseWriter, *http.Request) error  10: }&#xA;And then we have actually handling requests. I choose to look at the simplest thing, just looking at how we process a read request:&#xA;&#xA;&#xA;   1: func GetHandler(w http.ResponseWriter, req *http.Request, s Server) error {   2:     vars := mux.Vars(req)   3:     key := &quot;/&quot; &#x2B; vars[&quot;key&quot;]   4:&#xA0;    5:     // Help client to redirect the request to the current leader   6:     if req.FormValue(&quot;consistent&quot;) == &quot;true&quot; &amp;&amp; s.State() != raft.Leader {   7:         leader := s.Leader()   8:         hostname, _ := s.ClientURL(leader)   9:&#xA0;   10:         url, err := url.Parse(hostname)  11:         if err != nil {  12:             log.Warn(&quot;Redirect cannot parse hostName &quot;, hostname)  13:             return err  14:         }  15:         url.RawQuery = req.URL.RawQuery  16:         url.Path = req.URL.Path  17:&#xA0;   18:         log.Debugf(&quot;Redirect consistent get to %s&quot;, url.String())  19:         http.Redirect(w, req, url.String(), http.StatusTemporaryRedirect)  20:         return nil  21:     }  22:&#xA0;   23:     recursive := (req.FormValue(&quot;recursive&quot;) == &quot;true&quot;)  24:     sort := (req.FormValue(&quot;sorted&quot;) == &quot;true&quot;)  25:     waitIndex := req.FormValue(&quot;waitIndex&quot;)  26:     stream := (req.FormValue(&quot;stream&quot;) == &quot;true&quot;)  27:&#xA0;   28:     if req.FormValue(&quot;wait&quot;) == &quot;true&quot; {  29:         return handleWatch(key, recursive, stream, waitIndex, w, s)  30:     }  31:&#xA0;   32:     return handleGet(key, recursive, sort, w, s)  33: }&#xA;If we are requiring consistency, and we aren&#x2019;t the leader, we&#x2019;ll forward to the leader. Otherwise, we&#x2019;ll process the request. Let us assume for now that we are doing a simple get, not a watch, this gives us:&#xA;&#xA;&#xA;   1: func handleGet(key string, recursive, sort bool, w http.ResponseWriter, s Server) error {   2:     event, err := s.Store().Get(key, recursive, sort)   3:     if err != nil {   4:         return err   5:     }   6:&#xA0;    7:     writeHeaders(w, s)   8:     b, _ := json.Marshal(event)   9:     w.Write(b)  10:     return nil  11: }  12:&#xA0;   13: func writeHeaders(w http.ResponseWriter, s Server) {  14:     w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)  15:     w.Header().Add(&quot;X-Etcd-Index&quot;, fmt.Sprint(s.Store().Index()))  16:     w.Header().Add(&quot;X-Raft-Index&quot;, fmt.Sprint(s.CommitIndex()))  17:     w.Header().Add(&quot;X-Raft-Term&quot;, fmt.Sprint(s.Term()))  18:     w.WriteHeader(http.StatusOK)  19: }&#xA;As you can see, we are basically just getting the current state from the in memory store, and handle that. It would be more interesting to look at how we handle waiting for a value to change, however:&#xA;&#xA;&#xA;   1: func handleWatch(key string, recursive, stream bool, waitIndex string, w http.ResponseWriter, s Server) error {   2:     // Create a command to watch from a given index (default 0).   3:     var sinceIndex uint64 = 0   4:     var err error   5:&#xA0;    6:     if waitIndex != &quot;&quot; {   7:         sinceIndex, err = strconv.ParseUint(waitIndex, 10, 64)   8:         if err != nil {   9:             return etcdErr.NewError(etcdErr.EcodeIndexNaN, &quot;Watch From Index&quot;, s.Store().Index())  10:         }  11:     }  12:&#xA0;   13:     watcher, err := s.Store().Watch(key, recursive, stream, sinceIndex)  14:     if err != nil {  15:         return err  16:     }  17:&#xA0;   18:     cn, _ := w.(http.CloseNotifier)  19:     closeChan := cn.CloseNotify()  20:&#xA0;   21:     writeHeaders(w, s)  22:&#xA0;   23:     if stream {  24:         // watcher hub will not help to remove stream watcher  25:         // so we need to remove here  26:         defer watcher.Remove()  27:         for {  28:             select {  29:             case &lt;-closeChan:  30:                 return nil  31:             case event, ok := &lt;-watcher.EventChan:  32:                 if !ok {  33:                     // If the channel is closed this may be an indication of  34:                     // that notifications are much more than we are able to  35:                     // send to the client in time. Then we simply end streaming.  36:                     return nil  37:                 }  38:&#xA0;   39:                 b, _ := json.Marshal(event)  40:                 _, err := w.Write(b)  41:                 if err != nil {  42:                     return nil  43:                 }  44:                 w.(http.Flusher).Flush()  45:             }  46:         }  47:     }  48:&#xA0;   49:     select {  50:     case &lt;-closeChan:  51:         watcher.Remove()  52:     case event := &lt;-watcher.EventChan:  53:         b, _ := json.Marshal(event)  54:         w.Write(b)  55:     }  56:     return nil  57: }&#xA;The store&#x2019;s Watch() method is actually interesting, because it exposes some interesting Go concepts (handling full channels, channels for communications, etc). But the important thing is that this will simply wait for a change to happen in the in memory state, and when such a thing happens, it will put a value in the wathcer.EventChan channel. So the logic here goes like this:&#xA;&#xA;Setup a watch on the in memory state. &#xA;Wait for a: &#xA;&#xA;Change in the items we watch &#xA;Or user abandoning the request&#xA;There is some interesting stuff here regarding one time watch, or streaming watch, but that appears to be quite easy to figure out and follow what is going on.&#xA;One thing that I can tell you, from my own experience, is that I would actually expect this to have serious issues in productions. In particular, web servers can decide that this request takes too long, and just abort it (for example IIS behaves in this manner), or that it timed out. That obviously depends on the server side implementation, and I&#x2019;m willing to assume that this isn&#x2019;t the case for whatever http stack etcd uses. However, clients do not. Most clients would give you the benefit of the doubt, but they would abort the request after a while, usually 15 seconds. That might be okay for some purposes, but especially if you want to handling streaming, that isn&#x2019;t really going to cut it.&#xA;More to the point, for long requests, this can cause issues for proxies, firewalls, etc. They&#x2019;ll decide that the request is closed, and shut it down even if you handled it on both ends properly. With RavenDB, we have a remarkably similar system, but our streaming notifications also incorporate the idea of heartbeat messages. Those are sent every now and then strictly in order to make sure that you&#x2019;ll get something client side, and that will make all the infrastructure, client side code, etc much much happier.&#xA;Enough with the small stuff, let us look at how we handle more complex things. I now intend to take a look at the POST handler. POST operations in etcd has the following format:&#xA;&#xA;curl http://127.0.0.1:4001/v2/keys/queue -XPOST -d value=Job1 &#xA;The idea is that this will create an automatically named key such as queue/15, queue/853, etc. The POST handler is interesting, because here it is in its entirety.&#xA;&#xA;&#xA;   1:&#xA0;    2: func PostHandler(w http.ResponseWriter, req *http.Request, s Server) error {   3:     vars := mux.Vars(req)   4:     key := &quot;/&quot; &#x2B; vars[&quot;key&quot;]   5:&#xA0;    6:     value := req.FormValue(&quot;value&quot;)   7:     dir := (req.FormValue(&quot;dir&quot;) == &quot;true&quot;)   8:     expireTime, err := store.TTL(req.FormValue(&quot;ttl&quot;))   9:     if err != nil {  10:         return etcdErr.NewError(etcdErr.EcodeTTLNaN, &quot;Create&quot;, s.Store().Index())  11:     }  12:&#xA0;   13:     c := s.Store().CommandFactory().CreateCreateCommand(key, dir, value, expireTime, true)  14:     return s.Dispatch(c, w, req)  15: }&#xA;The CreateCreateCommand just create a data object that holds the parameters, and then we dispatch it. I&#x2019;m thinking that we can learn quite a lot from how that works.&#xA;Dispatch merely send the command to the leader. This is the relevant code if we are not the leader:&#xA;&#xA;&#xA;   1: leader := ps.raftServer.Leader()                                            2:                                                                             3: // No leader available.                                                     4: if leader == &quot;&quot; {                                                           5:     return etcdErr.NewError(300, &quot;&quot;, s.Store().Index())                        6: }                                                                           7:                                                                             8: var url string                                                              9: switch c.(type) {                                                          10: case *JoinCommand, *RemoveCommand:                                         11:     url, _ = ps.registry.PeerURL(leader)                                      12: default:                                                                   13:     url, _ = ps.registry.ClientURL(leader)                                    14: }                                                                          15: uhttp.Redirect(url, w, req)                                                16:                                                                            17: return nil                                                               &#xA;So basically, if there isn&#x2019;t a leader, we error. That can happen if we have a network split and we are in the minority portion, for example. But usually we&#x2019;ll just redirect you to the right server to use. But here is the interesting part, where we are the leader, and get to do stuff:&#xA;&#xA;&#xA;   1: result, err := ps.raftServer.Do(c)   2: if err != nil {   3:     return err   4: }   5:&#xA0;    6: if result == nil {   7:     return etcdErr.NewError(300, &quot;Empty result from raft&quot;, s.Store().Index())   8: }   9:&#xA0;   10: // response for raft related commands[join/remove]  11: if b, ok := result.([]byte); ok {  12:     w.WriteHeader(http.StatusOK)  13:     w.Write(b)  14:     return nil  15: }  16:&#xA0;   17: var b []byte  18: if strings.HasPrefix(req.URL.Path, &quot;/v1&quot;) {  19:     b, _ = json.Marshal(result.(*store.Event).Response(0))  20:     w.WriteHeader(http.StatusOK)  21: } else {  22:     e, _ := result.(*store.Event)  23:     b, _ = json.Marshal(e)  24:&#xA0;   25:     w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)  26:     // etcd index should be the same as the event index  27:     // which is also the last modified index of the node  28:     w.Header().Add(&quot;X-Etcd-Index&quot;, fmt.Sprint(e.Index()))  29:     w.Header().Add(&quot;X-Raft-Index&quot;, fmt.Sprint(s.CommitIndex()))  30:     w.Header().Add(&quot;X-Raft-Term&quot;, fmt.Sprint(s.Term()))  31:&#xA0;   32:     if e.IsCreated() {  33:         w.WriteHeader(http.StatusCreated)  34:     } else {  35:         w.WriteHeader(http.StatusOK)  36:     }  37: }  38:&#xA0;   39: w.Write(b)  40:&#xA0;   41: return nil&#xA;The ps variable is something called a PeerServer, and I haven&#x2019;t check it yet. But all of this code is basically doing is: &#x201C;send this to raft to Do something about it, then reply to the caller&#x201D;. So let us look at what we are actually doing there. The Do method merely call the send() method, which looks like this:&#xA;&#xA;&#xA;   1: // Sends an event to the event loop to be processed. The function will wait   2: // until the event is actually processed before returning.   3: func (s *server) send(value interface{}) (interface{}, error) {   4:     event := &amp;ev{target: value, c: make(chan error, 1)}   5:     s.c &lt;- event   6:     err := &lt;-event.c   7:     return event.returnValue, err   8: }&#xA;Personally, I think that this is very interesting, and again, very much like the way you would structure an Erlang system. Of particular interest is the idea of event loop. That would be the s.c channel, and I assume that this is meant for a separate goroutine that is processing work on top of that. We ended up with transaction merging in Voron using pretty much the same system.&#xA;The s.c channel is a channel of ev pointers. And ev is defined as:&#xA;&#xA;&#xA;   1:&#xA0;    2: // An internal event to be processed by the server&#x27;s event loop.   3: type ev struct {   4:     target      interface{}   5:     returnValue interface{}   6:     c           chan error   7: }&#xA;The interface{} definition it Go&#x2019;s System.Object, basically. And the error channel is there to mark when we are done processing the event, I assume. I would structure it so we can send a null error as completion, and I bet that this is how this is done.&#xA;I&#x2019;m currently assuming that this is being read from the loop() method. And while I usually don&#x2019;t just comment on comments, this one is really nice:&#xA;&#xA;&#xA;   1:&#xA0;    2: //--------------------------------------   3: // Event Loop   4: //--------------------------------------   5:&#xA0;    6: //               ________   7: //            --|Snapshot|                 timeout   8: //            |  --------                  ______   9: // recover    |       ^                   |      |  10: // snapshot / |       |snapshot           |      |  11: // higher     |       |                   v      |     recv majority votes  12: // term       |    --------    timeout    -----------                        -----------  13: //            |-&gt; |Follower| ----------&gt; | Candidate |--------------------&gt; |  Leader   |  14: //                 --------               -----------                        -----------  15: //                    ^          higher term/ |                         higher term |  16: //                    |            new leader |                                     |  17: //                    |_______________________|____________________________________ |&#xA;This comment promises an interesting function to read&#x2026;&#xA;&#xA;&#xA;   1:&#xA0;    2: func (s *server) loop() {   3:     defer s.debugln(&quot;server.loop.end&quot;)   4:&#xA0;    5:     for {   6:         state := s.State()   7:&#xA0;    8:         s.debugln(&quot;server.loop.run &quot;, state)   9:         switch state {  10:         case Follower:  11:             s.followerLoop()  12:&#xA0;   13:         case Candidate:  14:             s.candidateLoop()  15:&#xA0;   16:         case Leader:  17:             s.leaderLoop()  18:&#xA0;   19:         case Snapshotting:  20:             s.snapshotLoop()  21:&#xA0;   22:         case Stopped:  23:             s.stopped &lt;- true  24:             return  25:         }  26:     }  27: }&#xA;Let us start by looking at the leaderLoop behavior:&#xA;&#xA;&#xA;   1: func (s *server) leaderLoop() {   2:     s.setState(Leader)   3:     logIndex, _ := s.log.lastInfo()   4:&#xA0;    5:     // Update the peers prevLogIndex to leader&#x27;s lastLogIndex and start heartbeat.   6:     s.debugln(&quot;leaderLoop.set.PrevIndex to &quot;, logIndex)   7:     for _, peer := range s.peers {   8:         peer.setPrevLogIndex(logIndex)   9:         peer.startHeartbeat()  10:     }  11:&#xA0;   12:     // Commit a NOP after the server becomes leader. From the Raft paper:  13:     // &quot;Upon election: send initial empty AppendEntries RPCs (heartbeat) to  14:     // each server; repeat during idle periods to prevent election timeouts  15:     // (&#xA7;5.2)&quot;. The heartbeats started above do the &quot;idle&quot; period work.  16:     go s.Do(NOPCommand{})  17:&#xA0;   18:     // Begin to collect response from followers  19:     for s.State() == Leader {  20:         var err error  21:         select {  22:         case e := &lt;-s.c:  23:             if e.target == &amp;stopValue {  24:                 // Stop all peers before stop  25:                 for _, peer := range s.peers {  26:                     peer.stopHeartbeat(false)  27:                 }  28:                 s.setState(Stopped)  29:             } else {  30:                 switch req := e.target.(type) {  31:                 case Command:  32:                     s.processCommand(req, e)  33:                     continue  34:                 case *AppendEntriesRequest:  35:                     e.returnValue, _ = s.processAppendEntriesRequest(req)  36:                 case *AppendEntriesResponse:  37:                     s.processAppendEntriesResponse(req)  38:                 case *RequestVoteRequest:  39:                     e.returnValue, _ = s.processRequestVoteRequest(req)  40:                 }  41:             }  42:&#xA0;   43:             // Callback to event.  44:             e.c &lt;- err  45:         }  46:     }  47:&#xA0;   48:     s.syncedPeer = nil  49: }&#xA;To be perfectly frank, this is really code code. I am loving the structure here. It is really fun to go through and figure out. And the code follows really closely the Raft paper. And&#x2026; it appears that at some point I actually moved off the etcd code and into the go-raft codebase. I think that I&#x2019;ll skip doing the Raft stuff for this blog post. It is long enough already, and just focus on the etcd stuff for now.&#xA;The part that we really care for this blog post about is the processCommand call:&#xA;&#xA;&#xA;   1: // Processes a command.   2: func (s *server) processCommand(command Command, e *ev) {   3:     s.debugln(&quot;server.command.process&quot;)   4:&#xA0;    5:     // Create an entry for the command in the log.   6:     entry, err := s.log.createEntry(s.currentTerm, command, e)   7:&#xA0;    8:     if err != nil {   9:         s.debugln(&quot;server.command.log.entry.error:&quot;, err)  10:         e.c &lt;- err  11:         return  12:     }  13:&#xA0;   14:     if err := s.log.appendEntry(entry); err != nil {  15:         s.debugln(&quot;server.command.log.error:&quot;, err)  16:         e.c &lt;- err  17:         return  18:     }  19:&#xA0;   20:     s.syncedPeer[s.Name()] = true  21:     if len(s.peers) == 0 {  22:         commitIndex := s.log.currentIndex()  23:         s.log.setCommitIndex(commitIndex)  24:         s.debugln(&quot;commit index &quot;, commitIndex)  25:     }  26: }&#xA;In createEntry, we create effectively serialize the command into JSON, and appenEntry writes it to a file. (I finally found the serialize format, it is JSON for the commands, wrapped in a protobuf envelop). As an aside, if this was a C# code, I would be very worried about the cost of all those allocations. The data is first moved to a JSON buffer, then into a protocol buffer entry, where it is marshaled into another buffer, and only then is it written to the actual file. That is pretty prevalent in the codebase, to be honest. But again, this is Raft stuff that is going on, not etcd stuff. So we&#x2019;ll ignore this for now and try to see where we actually get to apply the command against our own internal state.&#xA;I had to go through some hoops to figure it out. In particular, commands are applied during recovery, or when we are actually committing the state following a quorum, and this is happening in the Log.ApplyFunc, which is setup externally, and&#x2026; Anyway, what we actually do is this:&#xA;&#xA;&#xA;   1: // Apply command to the state machine.                                    2: switch c := c.(type) {                                                    3: case CommandApply:                                                        4:     return c.Apply(&amp;context{                                                 5:         server:       s,                                                        6:         currentTerm:  s.currentTerm,                                            7:         currentIndex: s.log.internalCurrentIndex(),                             8:         commitIndex:  s.log.commitIndex,                                        9:     })                                                                      10: case deprecatedCommandApply:                                             11:     return c.Apply(s)                                                       12: default:                                                                 13:     return nil, fmt.Errorf(&quot;Command does not implement Apply()&quot;)            14: }                                                                      &#xA;And that goes all the way back to the CreateCommand&#x2019;s Apply function, which does:&#xA;&#xA;&#xA;   1: // Create node                                                                                         2: func (c *CreateCommand) Apply(context raft.Context) (interface{}, error) {                             3:     s, _ := context.Server().StateMachine().(store.Store)                                                 4:                                                                                                        5:     e, err := s.Create(c.Key, c.Dir, c.Value, c.Unique, c.ExpireTime)                                     6:                                                                                                        7:     if err != nil {                                                                                       8:         log.Debug(err)                                                                                       9:         return nil, err                                                                                     10:     }                                                                                                    11:                                                                                                       12:     return e, nil                                                                                        13: }                                                                                                     14:                                                                                                     &#xA;So, basically, we have Raft that does the hard work of getting a Quorum, persistence, etc.&#xA0; The etcd server is responsible for the in memory state, defining commands, etc.&#xA;The really interesting part from my perspective is that we need to process erroneous entries as well, in the same manner. For example, let us say that I want to create a new entry, but only if it isn&#x2019;t already there. The way it works, even though I know that this would be an error, I have to run this through Raft, get a consensus that we can apply this command, and then we apply the command, see that it is wrong, and return an error. That error leaves no state changes, but it still had to go through the Raft process, it is going to be in the log forever, etc. I&#x2019;m guessing that the percentage of erroneous commands is low, to be able to tolerate that. &#xA;And, at any rate. That pretty much conclude my review of etcd. It comes to about 20 pages or so, according to my math, and that is quite enough. On the other hand, it might have been 7 posts, instead. I would really like to get some feedback on which option you like more, dear reader.&#xA;Next, I&#x2019;m going to go over go-raft, I have some thoughts about this, but I&#x2019;ll keep them for my next post.&#xA;As a side note. I am not, by any means, an experience Go developer. I haven&#x2019;t even read Go code beyond Hello World before starting reading the etcd codebase. But I can tell you that this is a very nice codebase to look at. It is clear, nicely laid out, it is possible to go through everything and understand what is going on easily.</p>
        </article>
        <div class="button flex justify-between">
            <a href="396.html"><span class="back arrow"></span></a>

            <a href="398.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>

<!-- Cookie Consent Banner -->
<div class="cookie-consent" id="cookieConsent">
    <div>
        <p class="text-sm">We use cookies to analyze our website traffic and provide a better browsing experience. By
            continuing to use our site, you agree to our use of cookies.</p>
    </div>
    <div class="cookie-consent-buttons">
        <button class="cookie-consent-decline" onclick="declineCookies()">Decline</button>
        <button class="cookie-consent-accept" onclick="acceptCookies()">Accept</button>
    </div>
</div>

<script>
    // Cookie consent management
    function showCookieConsent() {
        const consent = localStorage.getItem('cookieConsent');
        if (!consent) {
            document.getElementById('cookieConsent').classList.add('show');
        }
    }

    function acceptCookies() {
        localStorage.setItem('cookieConsent', 'accepted');
        document.getElementById('cookieConsent').classList.remove('show');
        loadGA(); // Load Google Analytics after consent
    }

    function declineCookies() {
        localStorage.setItem('cookieConsent', 'declined');
        document.getElementById('cookieConsent').classList.remove('show');
    }

    // Show the consent banner only for EU visitors (you can add more country codes as needed)
    fetch('https://ipapi.co/json/')
            .then(response => response.json())
            .then(data => {
                const euCountries = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE'];
                if (euCountries.includes(data.country_code)) {
                    showCookieConsent();
                } else {
                    // For non-EU visitors, automatically load GA
                    if (!localStorage.getItem('cookieConsent')) {
                        localStorage.setItem('cookieConsent', 'accepted');
                        loadGA();
                    }
                }
            })
            .catch(() => {
                // If we can't determine location, show the consent banner to be safe
                showCookieConsent();
            });
</script>
</body>
</html>