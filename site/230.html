
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Home â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<script>
    const lightModePref = window.matchMedia("(prefers-color-scheme: light)");

    function getUserPref() {
        const storedTheme = typeof localStorage !== "undefined" && localStorage.getItem("theme");
        return storedTheme || (lightModePref.matches ? "light" : "dark");
    }

    function setTheme(newTheme) {
        if (newTheme !== "light" && newTheme !== "dark") {
            return console.warn(
                `Invalid theme value '${newTheme}' received. Expected 'light' or 'dark'.`,
            );
        }

        const root = document.documentElement;

        // root already set to newTheme, exit early
        if (newTheme === root.getAttribute("data-theme")) {
            return;
        }

        root.setAttribute("data-theme", newTheme);

        const colorThemeMetaTag = document.querySelector("meta[name='theme-color']");
        const bgColour = getComputedStyle(document.body).getPropertyValue("--theme-bg");
        colorThemeMetaTag.setAttribute("content", `hsl(${bgColour})`);
        if (typeof localStorage !== "undefined") {
            localStorage.setItem("theme", newTheme);
        }
    }

    // initial setup
    setTheme(getUserPref());

    document.addEventListener("DOMContentLoaded", function () {
        document.getElementById("theme-toggle").addEventListener("click", () => {
            const theme = localStorage.getItem("theme");

            if (theme === "dark") {
                setTheme("light");
            } else {
                setTheme("dark");
            }
        });

        document.getElementById("toggle-navigation-menu").addEventListener("click", (e) => {
            const button = e.target;
            const ariaExpanded = button.getAttribute("aria-expanded");
            const header = document.getElementById("main-header");

            if (ariaExpanded === "true") {
                button.setAttribute("aria-expanded", "false");
                header.classList.remove("menu-open");
            } else {
                button.setAttribute("aria-expanded", "true");
                header.classList.add("menu-open");
            }
        });
    });
</script>

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <theme-toggle class="ms-auto">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main">
    <section aria-label="Blog post list">
        <a href="https://ayende.com/blog/171875/production-postmortem-the-case-of-the-memory-eater-and-high-load" target="_blank"><h1 class="title mb-6">Production postmortem</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 31, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This is a recent case. One of our customers complained that every now and then they started to see very high memory utilization, escalating quickly until the system would bog down and die. They were able to deploy a mitigation strategy of a sort, when they detected this behavioral pattern, they would force RavenDB to reject client requests for a short while, which would fix this issue. This went on for&#xA0; a while, because the behavior was utterly random. It didn&#x2019;t seem to relate to load, peek usage time on the system didn&#x2019;t correlate to this in any way. Eventually the customer raised another issue, that a certain spatial query was behaving very slowly in the logs. We tested that, and we found that the customer was correct. More properly, the query executed just fine when run independently. But when we run this query tens or hundreds of times concurrently, we will see very high response times (and getting worse), and we would see the server memory just blowing up very quickly. So we have a memory leak, we figured out, let us see what is going on&#x2026; We dumped the data, and tried to figure out what it was exactly that we were leaking. But there wasn&#x2019;t anything there! In fact, looking at the problem, it became even curiouser.&#xA0; Take a look at what we saw during one of the test runs:  Note that this is all running with no other work, just a lot of queries hitting the server. Somehow, we had a lot of data going into the Gen2 heap. But when we checked the Gen2, it was pretty much empty. In fact, we had a 100% fragmentation. Something was very strange here. We enabled memory allocation tracking and started to look into what was going on. We found this very suspicious (note that this is from a different run from the one above):  So FileStream.Read is allocating GBs over GBs of memory? What is going on?! It took a while to figure out what was going on. The underlying issue was within Lucene. Actually, an intersection of a few things inside Lucene. Here is how Lucene reads from a file on disk:  What you&#x2019;ll notice is that Lucene is holding a lock on the file, and then issuing I/O. In other words, it is going to hold that lock for a while. This is a very strange thing to do, why is Lucene doing it? It does this because of a strange decision on how to do concurrent I/O.  Basically, whenever Lucene needs to do concurrent I/O, it will clone the relevant input object, and then use it concurrently. The idea, I gather, is that Lucene didn&#x2019;t want to have a separate file handle for each multi threaded operation, instead it created one file handle, and used it concurrently. Since concurrent I/O takes careful usage, they slapped a lock on it and call it a day. I&#x2019;m being unfair, I know, this is explicitly called out in the docs:  And in the Java version, there is an NIOFSDirectory that is presumably much better. Such doesn&#x2019;t exist in the Lucene.Net version we are using. In fact, I was curious and I checked the upcoming version, they do have a NIOFSDirectory implementation, which had the following code in it:  This is a single global lock for everything. Thank you, I&#x2019;ll take the lock per file. Now, to be fair again, work in progress, etc. We noticed this issue a long while ago, and we solved it by using multiple FileStreams. It used more resources, but it meant that we were far more concurrent. Note that all of this actually happened years ago, and we had no problems in this area. Note that Linux program typically worry a lot more about the number of open file handles than Windows programs do. The problem was definitely related to the use of multiple FileStream. But it didn&#x2019;t have anything to do with holding multiple handles to the same file. Instead, the issue was in the usage pattern that the query exhibited. In particular, and I&#x2019;m going to get deep into Lucene here, the problem was inside the SegmentReader.Terms() method:  This seem innocuous, right? Here is how this is implemented:  And all the way down until we gets to the input.Clone() method. Now, in a standard Lucene system, using concurrent queries, this would result in a fair amount of locking. In RavenDB, this just meant that we were creating new FileStream objects. The problem was that this particular query had a list of terms that it needed to check, and it called the Terms() method many times. How much is many times? 12,000 times! Still not a problem, except that it called FileStream.Read on each and every one of those. And FileStream.Read does the following:  And the _bufferSize is set to the default of 4KB. In other words, processing a single instance of this particular query will result in the system allocating about 48MB of memory! And when we have concurrent queries of this type? Each of them is allocating 48 MB of memory, and because they allocate so much, we have GC runs, which cause the memory (which is still in use) to be sent to Gen 1, and eventually park in Gen 2. There is languish (because it is temporary memory, but we don&#x2019;t clear Gen 2 very often). We changed the implementation to use overlapped I/O and tested that, and the memory consumption dropped by a significant number. But we still saw more allocations than we liked. We ended up tracking that down the this call (in BufferedIndexInput&#xA0; in the Lucene codebase):  The buffer size in this case is 1KB. So allocation for this query was actually 60 MB(!), and we only managed to drop it by 48MB. After fighting with this for a long while, we ended scratch the whole buffered index input idea. It is just not sustainable in terms of allocations. Instead, we created a memory map input class, that map the input data once, and doesn&#x2019;t use a buffer (so no allocations). With that option, our cost to process this query was drastically lower. We profile the change, to see whatever there are additional issues, and we found that the newly optimized code was much better, but still had an issue. The memory map code used the UnmanagedMemoryStream class to expose the file to the rest of the application. Unfortunately, this class appears to be intended for concurrent usage, which is a rarity for Streams. Here is ReadByte method from that class: As you can see, this method is doing quite a lot. And it showed up as a hot spot in our profiling. The rest of the class is pretty complex as well, and does significantly more than what we actually need it to do. We replaced this with a MmapStream class, and here is the comparable implementation.  You can safely assume that this is much faster . We have tested this using 5000 concurrent requests, without caching. Memory consumption is steady, and doesn&#x2019;t increase. We show marked improvement across the board, in memory utilization, CPU usage and I/O rates. Note that while this issue was caused by a particular query whose pattern of operation caused tremendous number of allocations, this change has wider reaching implications. We now allocate less memory for all queries, and previous experience has shown us that reducing a single 4Kb allocation in query processing can improve overall performance but 30%. We haven&#x2019;t run those tests yet, but I&#x2019;ll be surprised if we&#x2019;ll see negative results.</p>
        <a href="https://ayende.com/blog/171874/concurrent-max-value" target="_blank"><h1 class="title mb-6">Concurrent max value</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 28, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">For a feature in RavenDB, I need to figure out the maximum number of outputs per document an index has. Now, indexing runs in multiple threads at the same time, so we ended up with the following code:  var actualIndexOutput = maxActualIndexOutput;&#xA;if (actualIndexOutput &gt; numberOfAlreadyProducedOutputs)&#xA;{&#xA;    // okay, now let verify that this is indeed the case, in thread safe manner,&#xA;    // this way, most of the time we don&#x27;t need volatile reads, and other sync operations&#xA;    // in the code ensure we don&#x27;t have too stale a view on the data (beside, stale view have&#xA;    // to mean a smaller number, which we then verify).&#xA;    actualIndexOutput = Thread.VolatileRead(ref maxActualIndexOutput);&#xA;    while (actualIndexOutput &gt; numberOfAlreadyProducedOutputs)&#xA;    {&#xA;        // if it changed, we don&#x27;t care, it is just another max, and another thread probably&#xA;        // set it for us, so we only retry if this is still smaller&#xA;        actualIndexOutput = Interlocked.CompareExchange(&#xA;            ref maxActualIndexOutput, &#xA;            numberOfAlreadyProducedOutputs,&#xA;            actualIndexOutput);&#xA;    }&#xA;}&#xA;&#xA;&#xA;The basic idea is that this code path is hit a lot, once per document indexed per index. And it also needs to be thread safe, so we first do an unsafe operation, then a thread safe operations.&#xA;The idea is that we&#x2019;ll quickly arrive at the actual max number of index inputs,&#xA0; but we don&#x2019;t have to pay the price of volatile reads or thread synchronization.</p>
        <a href="https://ayende.com/blog/171873/technical-observations-from-my-wife-performance" target="_blank"><h1 class="title mb-6">Technical observations from my wife</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 27, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I was telling my wife about my day at work, and the conversation went something like that:&#xA;&#xA;Me: So we spent all day trying to optimize this really expensive query.&#xA;Wife: What made it so expensive?&#xA;Me: We weren&#x2019;t sure, but it run for 300 &#x2013; 400 ms!&#xA;Wife: You are so impatient.</p>
        <a href="https://enterprisecraftsmanship.com/posts/database-versioning-tools/" target="_blank"><h1 class="title mb-6">Database versioning tools</h1></a>
        <p class="mb-2">by Vladimir Khorikov</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 26, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The topic described in this article is a part of my Database Delivery Best Practices Pluralsight course&#xA; In the previous two articles, we looked at the theory behind the notion of database versioning. Today, I want to dive into practice and discuss the database versioning tools available at our disposal.&#xA; Database versioning tools classes The tools on the market can be divided into two classes: those which follow the state-based approach and those that&#xA0;adhere to&#xA0;the migration-based principles.</p>
        <a href="https://ayende.com/blog/171842/optimizing-i-o-throughput" target="_blank"><h1 class="title mb-6">Optimizing I/O throughput</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 26, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">We got a customer request about performance issues they were seeing on startup on a particular set of machines. Those machine run in a cloud environment, and they have&#x2026; peculiar, one might say deviant, I/O characteristics. In particular, the I/O pipeline on those machines is wide, but very slow. What do I mean by that? I meant that any particular I/O operation on those is likely to be slow, but the idea is that you can get much better performance if you issue concurrent I/O. The system is supposed to be able to handle that much better, and overall you&#x2019;ll see the same relative performance as elsewhere. This is pretty big issue for us, because for many things, we really do care about serial I/O performance. For example, if we are committing a transaction, we really have no other way to handle it except to wait until the I/O is fully completed. That said, the particular scenario where we had the problem was startup. If the database was under heavy load at the time it shut down, the recovery logs would be full, and the database would need to replay the recent actions that happened. Note that shutdown performance is important, because it many cases we are running in an environment where shutdown comes with a ticking clock (in IIS or as a Windows Service). At startup, we usually have more time, and it is expected that we&#x2019;ll take a while to get up to speed. If nothing else, just bringing enough of the database to memory is going to take time, so on large databases, startup time is expected to be non trivial. That said, the startup time on those set of machines was utterly atrocious. To figure out what is going on, I pulled out Process Monitor and looked at the File I/O. We go this:  We are reading from a journal, and that is pretty serial I/O (in the image, I&#x2019;m running of a remote network drive, to simulate slow responses). Note that we need to read the log in a serial fashion, and the way the OS reads things, we read 32Kb at a time. Remember, we are reading things in a serial fashion, and that means that we have a lot of page faults, and we have a slow I/O system, and we execute them serially.  Yes, that is a killer for perf. By the way, when I&#x2019;m talking about slow I/O system, I&#x2019;m talking about &gt; 0.5 MS per disk read for most requests (ideally, we would have latency of 0.05 &#x2013; 0.15). And we have quite a few of those, as you can imagine.  Since I know that we are going to be reading the whole journal, I used the PrefetchVirtualMemory() method and passed it the entire file (it is a maximum of 64MB, and we are going to need to read it all anyway). This let the OS have the maximum amount of freedom when reading the data, and it generate big, concurrent I/O. Here is how this looks like:  This also give the wide I/O bandwidth a chance to play. We load the I/O subsystem with a lot of stuff that it can try to do in an optimized fashion.   The next part that was expensive was that we need to apply the data from the journal files to the data file, and sync it.  The performance of syncing a file is related to the size of the file, unfortunately. And the file in question was large, over 45GB. Especially on such a system, we saw a lot of latency here, as in multiple minutes. One obvious optimization was to not sync per journal file, but sync once per the whole recovery process. That helped, but it was still too expensive.  Next, we tried pretty much everything we could think about.  Switching to WriteFile (from using mmap and then calling FlushViewOfFile) Using async I/O (WriteFileEx) Using scatter / gather I/O with no buffering (saves the need to do sync in the end) Completion ports Asking a 4 months old baby girl what she think about it (she threw up on the keyboard, which is what I wanted to do at the time, then she cried, and I joined her) Nothing seems to have worked. The major issue was that in this workload, we have a large file (45GB, as I said) and we are writing 4KB pages into it in effectively random places. In the workload we were trying to work with, there were roughly 256,000 individual 4KB writes (most of them weren&#x2019;t consecutive, so we couldn&#x2019;t get the benefit of that). That is about 1 GB of writing to do. And nothing we could do would get us beyond 3MB/sec or so. Saturating the I/O subsystem with hundreds of thousands of small writes wouldn&#x2019;t work, and we were at a loss. Note that a small test we made, just copying data around manually has resulted in roughly 10MS/sec peek performance on those machines. This is a very lame number, so there isn&#x2019;t much that we can do.  Then I thought to ask, why are we seeing this only during startup? Surely this happens also on a regular basis. Why didn&#x2019;t we notice? The reason for that is pretty simple, we didn&#x2019;t notice because we amortize the cost. Only on startup did we had to actually sit and wait for it to complete. So we dropped that requirement. We used to read all the journals, apply them to the data file, sync the data files and then delete the journals. Now we read the journals, apply them (via a memory map) to the data file, and only remember what is the last journal file we applied in memory.  There is a background process running that will take care of syncing the data file (and deleting the old journals). If we crash again, we&#x2019;ll just have to replay the logs that we aren&#x2019;t sure were synced before. This saves even more time.  But we still have another issue. Writing to memory mapped file require the OS to page the relevant pages into memory. And again, we are on slow I/O, and the OS will only page the stuff that we touch, so this is again a serial process that this time require us to load to memory about 1GB of data at 3MB/sec. That is&#x2026; not a good place to be at. So the next step was to figure out all the addresses we&#x2019;ll be writing to, and letting the OS know that we&#x2019;ll be fetching them. We do some work to make sure that we load those values (and neighboring pages) to memory, then we can write to them without paging for each page individually. A nice side effect of this is that because this is running on the latest changes in the system, this has the effect of preloading to memory the pages that are likely to be in used after the database has started. That is a lot of work, but to be perfectly frank, this is mostly optimizing in a bad environment. The customer can&#x2019;t walk away form their current machine easily, but the I/O rates those machines have would make any database sit in a corner and cry.</p>
        <a href="https://ayende.com/blog/171841/unsafe-operations-are-required-in-the-real-world" target="_blank"><h1 class="title mb-6">Unsafe operations are required in the real world</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 25, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">There is a pretty interesting discussion in the Raft mailing list, about clarifying some aspects of the Raft protocol. This led to some in depth discussion on the difference between algorithms in their raw state and the actual practice that you need in the real world. In case you aren&#x2019;t aware, Raft is a distributed consensus protocol. It allows a group of machines to reach a decision together (a gross over simplification, but good enough for this). In a recent post, I spoke about dedicated operations bypasses. This discussion surfaced another one. One of the things that make Raft much simpler to work with is that it explicitly handles topology changes (adding / removing nodes). Since that is part of the same distributed consensus algorithm, it means that it is safe to add or remove a node at runtime.  Usually when you build a consensus algorithm, you are very much focused on safety. So you make sure that all your operations are actually safe (otherwise, why bother?). Except that you must, in your design, explicitly allow the administrator to make inherently unsafe operations. Why? Consider the case of a three node cluster, that has been running along for a while now. A disaster strikes, and two of the nodes die horriblyh. This puts our cluster in a situation where it cannot get a majority, and nothing happen until at least one machine is back online. But those machines aren&#x2019;t coming back. So our plucky admin wants to remove the two dead servers from the cluster, so it will have one node only, and resume normal operations (then the admin can add additional nodes at leisure). However, the remaining node will refuse to remove any node from the cluster. It can&#x2019;t, it doesn&#x2019;t have a majority. If sounds surprisingly silly, but you actually have to build into the system the ability to make those changes with explicit admin consent as unsafe operations. Otherwise, you might end up with a perfectly correct system, that breaks down horribly in failure conditions. Not because it buggy, but because it didn&#x2019;t take into account that the real world sometimes requires you to break the rules.</p>
        <a href="https://ayende.com/blog/171811/the-you-broke-the-build-game" target="_blank"><h1 class="title mb-6">The &#x201C;you broke the build!&#x201D; game</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 24, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Recently I pulled some code from a colleague, and tried to test it. It worked, which was fine, so I let it run the tests, and went out to lunch. When I came back, I was surprised to discover that the build has failed, not because of some test failing, but because it couldn&#x2019;t compile. To be rather more exact, we go the following error:  [optimized-build] Using type script compiler: C:\Program Files (x86)\Microsoft SDKs\TypeScript\1.4\tsc.exe&#xA; [optimized-build]&#xA; [optimized-build] System.ComponentModel.Win32Exception thrown:&#xA; [optimized-build] --------------------------&#xA; [optimized-build] The filename or extension is too long&#xA; [optimized-build] --------------------------&#xA;&#xA;&#xA;&#xA;That was strange. I checked several times, and we had no such thing. No one had a veryVeryLongFileNameThatNeededToBeVeryExplicitAboutWhatItWasDoingAndDidNotCareAboutLength.ts.&#xA;And the tsc.exe location was in its normal place. This is from a part in our build process that gather all the TypeScript files and merge them into a single optimized bundle. And it suddenly failed. Now, on the colleague machine, it worked. The previous commit before I merged it, it worked. The merge was a clean one, and very obvious that nothing was going on there.&#xA;It took me a while, but I finally figured out that the error occurred because my colleague has added a new TypeScript file. &#xA;How can adding a file break the build?&#xA;As it turns out, the code we were calling did something like this:&#xA;&#xA;tsc.exe file1.ts file2.ts file3.ts&#xA;And at some point, the size of the command line we were passing to the process has exceeded 32KB. And that is when everything broke loose.&#xA;Luckily, we were able to write those things to a file and ask the compiler to load them directly, instead of passing them via the command line:&#xA;&#xA;tsc.exe @arguments.txt&#xA;And everything was okay again&#x2026;</p>
        <a href="https://ayende.com/blog/171810/dedicated-operations-road-bypasses" target="_blank"><h1 class="title mb-6">Dedicated operations road bypasses</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 21, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">We care very deeply about the operations side of RavenDB. Support calls are almost never about &#x201C;where are you? I want to send you some wine &amp; roses&#x201D;, and they tend to come at unpleasant timing. One of the things that we had learnt was that when stuff breaks, it tend to do so in ways that are&#x2026; interesting. Let me tell you a story&#x2026;  A long time ago, a customer was using an index definition that relied on the presence of a custom assembly to enrich the API available for indexing. During the upgrade process from one major version of RavenDB to the next, they didn&#x2019;t take into account that they need to also update the customer assembly. When they tried to start RavenDB, it failed because of the version mismatch, since they weren&#x2019;t actually using that index anyway. The customer then removed the assembly, and started RavenDB again. At this point, the following sequence of events happened:  The database started, saw that it is using an old version of the storage format, and converted to the current version of the storage format. The database started to load the indexes, but the index definition was invalid without the customer assembly, so it failed. (Index definitions are validated at save time, so the code didn&#x2019;t double check that at the time). The customer was now stuck, the database format was already converted, so in order to rollback, they would need to restore from backup. They could also not remove the index from the database, because the database wouldn&#x2019;t start to let them do so. Catch 22. At this point, the admin went into the IndexDefinitions directory, and deleted the BadIndex.index-definition file, and restarted RavenDB again. The database then recognized that the index definition is missing, but the index exists, deleted the index from the server, and run happily ever after. Operations road bypass is our terminology for giving administrators a path to changing internal state in our system using standard tools, without requiring the system to be up and functioning. The example with the index definition is a good one, because the sole reason we keep the index definition on disk is to allow administrators the ability to touch them without needing RavenDB in a healthy state. What do you do in your system to make it possible for the admin to recover from impossible situations?</p>
        <a href="https://ayende.com/blog/171809/repeatable-random-tests" target="_blank"><h1 class="title mb-6">Repeatable random tests</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 20, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Testing our software is something that we take very serious. And in some cases, we want to go beyond testing stuff that we know. We want to test random stuff. For example, if we add 10,000 documents, then remove every 17th, what happens? Is there any differences in behavior, performance, etc? It is easy to do random stuff, of course. But that leads to an interesting case. As long as the tests are passing, you can pat yourself on the back: &#x201C;We have done good, and everything works as it should&#x201D;. But when something fails&#x2026; well, the only thing that you know is that something did fail. You don&#x2019;t have a way to reproduce this. Because the test is&#x2026; random. In order to handle that, we wrote the following code:  [AttributeUsage(AttributeTargets.Method, AllowMultiple = true)]&#xA; public class InlineDataWithRandomSeed : DataAttribute&#xA; {&#xA; &#xA;     public InlineDataWithRandomSeed(params object[] dataValues)&#xA;     {&#xA;         this.DataValues = dataValues ?? new object[] {null};&#xA;     }&#xA; &#xA;     public object[] DataValues { get; set; }&#xA;&#xA;     public override IEnumerable&lt;object[]&gt; GetData(MethodInfo methodUnderTest, Type[] parameterTypes)&#xA;     {&#xA;         var objects = new object[DataValues.Length&#x2B;1];&#xA;         Array.Copy(DataValues,0,objects,0, DataValues.Length);&#xA;         objects[DataValues.Length] = Environment.TickCount;&#xA;         yield return objects;&#xA;         &#xA;     }&#xA; }&#xA;&#xA;&#xA;This is using XUnit, which gives us the ability to add a seed to the test. Let us see how the test looks:&#xA;&#xA;&#xA;And this is what this looks like when it runs:&#xA;&#xA;When we have a failure, we know what the seed is, and we can run the test with that seed, and see what exactly happened there.</p>
        <a href="https://ayende.com/blog/171777/presenting-highly-available-scalable-solutions-at-goto-copenhagen" target="_blank"><h1 class="title mb-6">Presenting, Highly Available &amp; Scalable Solutions at GOTO Copenhagen</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: August 19, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I&#x2019;ll be presenting at the GOTO Copenhagen conference in Oct 7 &#x2013; 8 this year. The full session summary is:  Presentation: Highly Available &amp; Scalable Solutions with RavenDB Track: Solutions Track 1 / Time: Monday 13:20 - 14:10 / Location: Rosenborg RavenDB is a 2nd generation document database, with built-in load distribution, seamless replication, disaster recovery and data-driven sharding. In this session, we are going to explore how RavenDB deals with scaling under load and remain highly available even under failure conditions. We&#x27;ll see how RavenDB&#x27;s data-driven sharding allows to increase the amount of the data in our cluster without giving up the benefits of data locality. We are are going to execute complex distributed map-reduce queries on a sharded cluster, giving you lightning-fast responses over very large data volumes. Hibernating Rhinos will also be presenting at a booth, and we&#x2019;ll have a few members of the core team there to talk about RavenDB and the cool things that you can do with it.</p>
        <div class="button flex justify-between">
            <a href="229.html"><span class="back arrow"></span></a>

            <a href="231.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2024<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
</body>
</html>