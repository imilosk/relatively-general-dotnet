
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 544 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-5431">
            <a href="https://ayende.com/blog/4348/why-all-the-performance-posts" target="_blank">
                <h2 class="title mb-6" id="article-5431">Why all the performance posts?</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 03, 2010
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">For the last week or so I have been posting just about performance. Can you figure out why? Yes, I just finish doing a heavy optimization for the profiler, but why so many posts?  The answer is quite simple, but I want to see what conspiracies you are going to put out.</p>
        </article>
        <article id="article-5432">
            <a href="https://ayende.com/blog/4347/patterns-for-reducing-memory-usage" target="_blank">
                <h2 class="title mb-6" id="article-5432">Patterns for reducing memory usage</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 02, 2010
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Memory problems happen when you application use more memory that you would like. It isn&#x2019;t necessarily paging or causing OutOfMemory, but it is using enough memory to generate complaints. The most common cases for memory issues are:     Memory leaks    Garbage spewers    In memory nuts    Framework bugs   Let me take each of them in turn.  Memory leaks in a managed language are almost always related to dangling references, such as in a cache with no expiration or events where you never unsubscribe. Those are usually nasty to figure out, because tracking down what is holding the memory can be unpleasant. But, by the same token, it is also fairly straightforward to do so.  Garbage spewers are pieces of code that allocate a lot of memory that will have to be freed soon afterward. A common case of that is:     public string Concat(string[] items)&#xA;{&#xA;   string result = &quot;&quot;;&#xA;   foreach(var item in items)&#xA;      results &#x2B;= item;&#xA; &#xA;   return result;&#xA;}&#xA;  &#xA;&#xA;This is going to allocate a lot of memory, which will have to be freed soon after. This will get cleaned up eventually, but it will put a lot of pressure on the GC first, will cause the application to consume more memory and in general won&#x2019;t play nice with others. While the code above is the simplest way to explain this, it is fairly common in ways that are harder to detect, a common case would be to load a DTO from the database, convert that to an entity and convert that to a view model. Along the way, you are going to consume a lot of memory for doing pretty much the same thing.&#xA;&#xA;Now the caveat here is that most objects are actually small, so you don&#x2019;t really notice that, but if you are working with large objects, or a lot of them, this is something that is going to hit you.&#xA;&#xA;In memory nuts refer to a common problem, you simply put your entire dataset in memory, and commonly refer to it by direct model traversal. When your dataset becomes too big, however&#x2026; well, that is the point where the pain is really going to hit you. Usually, fixing this is a costly process, because your code assumes that the entire thing is in memory. Even if you can easily save it to persistent storage, fixing all the places where the code assumes that everything is just a pointer reference away is a big problem. &#xA;&#xA;Framework bugs are my least favorite, it is when you run into cases where the framework just won&#x2019;t release memory. Most often, this is because you are doing something wrong, but occasionally you will hit the real framework bug, and tracking that down is a pure PITA.&#xA;&#xA;In all cases, you need to set up some goals, what is acceptable memory usage, in what scenarios, over what time frame, etc. Then build test scenarios that are repeatable and try each of your improvements out. Do not try to implement too much upfront, that way lies the road to madness.</p>
        </article>
        <article id="article-5433">
            <a href="https://ayende.com/blog/4346/micro-optimization-decision-process" target="_blank">
                <h2 class="title mb-6" id="article-5433">Micro optimization decision process</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 01, 2010
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">There are some parts of our codebase that are simply going to have to be called a large number of times. Those are the ones that we want to optimize, but at the same time, unless they are ridiculously inefficient, there isn&#x2019;t that much room for improvement.  Let us look at this for a second:     The numbers are pretty hard to read in this manner, so I generally translate it to the following table:              Method name        Cost per 1,000 invocations                  StringEqualsToBuffer        7 ms                  get_Item        0.2 ms                  get_Length        0.2 ms                  GetHashCode        4 ms                  Equals        1 ms          It is important to note that what I am trying to check here is relative cost of calling a method. I use the thousands invocation just to give us back a number that we can actually understand easily, instead of dealing with nanoseconds.  As you can see, all of the methods in this piece of code are actually pretty fast, the slowest will complete in under ten nanoseconds. The problem is that they are called a lot. StringEqualsToBuffer cost me 90 seconds in this test run. This means that to improve its performance, we need to get it to drop to even fewer nanoseconds, or reduce the number of times it is called. Both of which are going to be hard.  You can look at how I dealt with this particular case in this post, but right now I want to talk about the decision process, not just the action that I took.  Usually, in such situations, I find the most costly function (StringEqualsToBuffer in this case) and then find any functions that it called, in this case, we can see that get_Item and get_Length are both costly functions called from StringEqualsToBuffer. Stupid micro optimization tactics, like referencing a field directly instead of through a property have enormous consequences in this type of scenario.  Next, we have things like GetHashCode, which looks to be very slow (it takes 4 nanoseconds to complete, I have hard time calling it slow :-)). This function is slow not because we are doing something that can be optimized, but simply because of what it does. Since we can&#x2019;t optimize the code itself, we want to do the next best thing, and see if we can optimize the number of times that this code is called. In other words, apply caching to the issue. Applying caching means that we need to handle invalidation, so we need to consider whatever we will gain something from that, mind you. Often, the cost of managing the cache can be higher than the cost of calculating the value from scratch when we are talking about this kind of latencies.  Another issue to consider is the common memory vs. time argument, it is easy to err into one side of them when you are focused on micro benchmarks. You get a routine that completes in 1 nanosecond in the common case but uses up 10 Mb of cache. Sometimes you want that, sometimes it is a very bad tradeoff.  I generally start with simple performance tuning, finding out hotspots and figuring out how to fix them. Usually, it is some sort of big O problem, either in the function itself or what it is called on. Those tend to be easy to fix and produce a lot of benefit. Afterward, you get to true algorithmic fixes (find a better algo for this problem). Next, I run tests for memory usage, seeing if under the most extreme likely conditions, I am hitting my specified limits.  I&#x2019;ll talk about reducing memory usage in a separate post, but once you run through that, another run to verified that you haven&#x2019;t traded off in the other direction (reduced memory at the expense of running time) would complete the process.</p>
        </article>
        <article id="article-5434">
            <a href="https://ayende.com/blog/4345/memory-obesity-and-the-curse-of-the-string" target="_blank">
                <h2 class="title mb-6" id="article-5434">Memory obesity and the curse of the string</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 31, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I believe that I have mentioned that my major problem with the memory usage in the profiler is with strings. The profiler is doing a lot with strings, queries, stack traces, log messages, etc are all creating quite a lot of strings that the profiler needs to inspect, analyze and finally produce the final output.  Internally, the process looks like this:    On my previous post, I talked about the two major changes that I made so far to reduce memory usage, you can see them below. I introduced string interning in the parsing stage and serialized the model to disk so we wouldn&#x2019;t have to keep it all in memory, which resulted in the following structure:     However, while those measures helped tremendously, there is still more that I can do. The major problem with string interning is that you first have to have the string in order to check it in the interned table. That means that while you save on memory in the long run, in the short run, you are still allocating a lot of strings. My next move is to handle interning directly from buffered input, skipping the need to allocate memory for a string to use as the key for interning.  Doing that has been a bit hard, mostly because I had to go deep into the serialization engine that I use (Protocol Buffers) and add that capability. It is also fairly complex to handle something like this without having to allocating a search key in the strings table. But, once I did that, I noticed three things.  First, while memory increased during operation, there weren&#x2019;t any jumps &amp; drops, that is, we couldn&#x2019;t see any periods in which the GC kicked in and released a lot of garbage. Second, memory consumption was relatively low through the operation. Before optimizing the memory usage, we are talking about 4 GB for processing and 1.5 GB for final result, after the previous optimization it was 1.9 GB for processing and 1.3 for final result. But after this optimization, we have a fairly simple upward spike up to 1.3 GB. You can see the memory consumption during processing in the following chart, memory used in in GB on the Y axis.     As you can probably tell, I am much happier with the green line than the other. Not only just because it takes less memory in general, but because it is much more predictable, it means that the application&#x2019;s behavior is going to be easier to reason about.   But this optimization brings to mind the question, since I just introduced interning at the serialization level, do I really need to have interning at the streaming level? On the face of it, it looks like an unnecessary duplication. Indeed, removing the string interning that we did in the streaming level reduce overall memory usage from 1.3GB to 1.15GB.  Overall, I think this is a nice piece of work.</p>
        </article>
        <article id="article-5435">
            <a href="https://ayende.com/blog/4344/when-mini-benchmarks-are-important" target="_blank">
                <h2 class="title mb-6" id="article-5435">When mini benchmarks are important</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 30, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">&quot;We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil&quot; - Donald Knuth    I have expressed my dislike for micro benchmarks in the past, and in general, I still have this attitude, but sometimes, you really care.      A small note, while a lot of namespaces you are going to see are Google.ProtocolBuffers, this represent my private fork of this library that was customized to fit UberProf&#x2019;s needs. Some of those things aren&#x2019;t generally applicable (like string interning at the serialization level), so please don&#x2019;t try to project from the content of this post to the library itself.    Let me show you what I mean:       The following is profiling this piece of code:     private static bool StringEqaulsToBuffer(ByteString byteString, ByteBuffer byteBuffer)&#xA;{&#xA;    if(byteString.Length != byteBuffer.Length)&#xA;        return false;&#xA;    for (int i = 0; i &lt; byteString.Length; i&#x2B;&#x2B;)&#xA;    {&#xA;        if(byteString[i] != byteBuffer.Buffer[byteBuffer.Offset&#x2B;i])&#xA;            return false;&#xA;    }&#xA;    return true;&#xA;}&#xA;  &#xA;&#xA;This looks pretty simple right?&#xA;&#xA;Now, it is important to understand that this isn&#x2019;t some fake benchmark that I contrived, this is the profile results from testing a real world scenario. In general, methods such as Equals or GetHashCode, or anything that they call, is likely to be called a lot of times, so paying attention to its performance is something that you should think about.&#xA;&#xA;This are a couple of very easy things that I can do to make this easier, remove the call to the ByteString indexer (which show up as get_Item in the profiler results) to a direct array access and consolidate the calls to the ByteString.Length property.&#xA;&#xA;After applying those two optimizations, we get the following code:&#xA;&#xA;&#xA;  private static bool StringEqaulsToBuffer(ByteString byteString, ByteBuffer byteBuffer)&#xA;{&#xA;    var strLen = byteString.Length;&#xA;    if(strLen != byteBuffer.Length)&#xA;        return false;&#xA;    for (int i = 0; i &lt; strLen; i&#x2B;&#x2B;)&#xA;    {&#xA;        if(byteString.bytes[i] != byteBuffer.Buffer[byteBuffer.Offset&#x2B;i])&#xA;            return false;&#xA;    }&#xA;    return true;&#xA;}&#xA;  &#xA;&#xA;And this profiler result:&#xA;&#xA; &#xA;&#xA;You can see that the this simple change resulted in drastic improvement to the StringEqualsToBuffer mehtod. As it stands now, I don&#x2019;t really see a good way to optimize this any further, so I am going to look at the other stuff that showed up. Let us take a look at ByteBuffer.GetHashCode() now:&#xA;&#xA;&#xA;  public override int GetHashCode()&#xA;{&#xA;    var ret = 23;&#xA;    for (var i = Offset; i &lt; Offset&#x2B;Length; i&#x2B;&#x2B;)&#xA;    {&#xA;        ret = (ret &lt;&lt; 8) | Buffer[i];&#xA;    }&#xA;    return ret;&#xA;}&#xA;&#xA;&#xA;&#xA;The problem is that I don&#x2019;t really see a way to optimize that, instead, I am going to cache that in a field. There is some problem here with the fact that ByteBuffer is mutable, but I can handle that by forcing all call sites that change it to call a method that will force hash recalculation. Note how different this decision is from the usual encapsulation that I would generally want. Placing additional burdens on call sites is a Bad Thing, but by doing so, I think that I can save quite significantly on the hash code calculation overhead.&#xA;&#xA;Next, let us look at the DoCleanupIfNeeded method and see why it is taking so much time.&#xA;&#xA;&#xA;  private void DoCleanupIfNeeded()&#xA;{&#xA;    if (strings.Count &lt;= limit)&#xA;        return;&#xA;&#xA;    // to avoid frequent thrashing, we will remove the bottom 10% of the current pool in one go&#xA;    // that means that we will hit the limit fairly infrequently&#xA;    var list = new List&lt;KeyValuePair&lt;ByteStringOrByteBuffer, Data&gt;&gt;(strings);&#xA;    list.Sort((x, y) =&gt; x.Value.Timestamp - y.Value.Timestamp);&#xA;&#xA;    for (int i = 0; i &lt; limit/10; i&#x2B;&#x2B;)&#xA;    {&#xA;        strings.Remove(list[i].Key);                &#xA;    }&#xA;}&#xA;  &#xA;&#xA;From the profiler output, we can see that it is an anonymous method that is causing the holdup, that is pretty interesting, since this anonymous method is the sort lambda. I decided to see if the BCL can do better, and changed that to:&#xA;&#xA;&#xA;  private void DoCleanupIfNeeded()&#xA;{&#xA;    if (strings.Count &lt;= limit)&#xA;        return;&#xA;&#xA;    // to avoid frequent thrashing, we will remove the bottom 10% of the current pool in one go&#xA;    // that means that we will hit the limit fairly infrequently&#xA;    var toRemove = strings.OrderBy(x=&gt;x.Value.Timestamp).Take(limit/10).ToArray();&#xA;&#xA;    foreach (var valuePair in toRemove)&#xA;    {&#xA;        strings.Remove(valuePair.Key);                &#xA;    }&#xA;}&#xA;  &#xA;&#xA;This isn&#x2019;t really what I want, since I can&#x2019;t take a dependency on v3.5 on this code base, but it is a good perf test scenario. Let us see what the profiler output is after those two changes:&#xA;&#xA; &#xA;&#xA;This is much more interesting, isn&#x2019;t it?&#xA;&#xA;First, we can see that the call to ByteBuffer.GetHashCode went away, but we have a new one, ByteBuffer.ResetHash. Note, however, that ResetHash only took half as much time as the previous appearance of GetHashCode and that it is called only half as many times. I consider this a net win.&#xA;&#xA;Now, let us consider the second change that we made, where previously we spend 11.1 seconds on sorting, we can see that we now spend 18 seconds, even if the number of calls is so much lower. That is a net lose, so we will revert that.&#xA;&#xA;And now, it is the time for the only test that really matters, is it fast enough? I am doing that by simply running the test scenario outside of the profiler and checking to see if its performance is satisfactory. And so far, I think that it does meet my performance expectation, therefore, I am going to finish with my micro optimizations and move on to more interesting things.</p>
        </article>
        <article id="article-5436">
            <a href="https://ardalis.com/hide-windows-language-updates-in-windows-7/" target="_blank">
                <h2 class="title mb-6" id="article-5436">Hide Windows Language Updates in Windows 7</h2>
            </a>
            <p class="mb-2">by Ardalis</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 29, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Setting up a new machine and going through the Windows Update Dance as I install the various updates that are available now (Windows 7 has&#x2026;Keep Reading &#x2192;</p>
        </article>
        <article id="article-5437">
            <a href="https://ayende.com/blog/4343/fighting-the-profiler-memory-obesity" target="_blank">
                <h2 class="title mb-6" id="article-5437">Fighting the profiler memory obesity</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 29, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">When I started looking into persisting profiler objects to disk, I had several factors that I had to take into account:     Speed in serializing / deserializing.     Ability to intervene in the serialization process at a deep level.     Size (also effect speed).    The first two are pretty obvious, but the third requires some explanation. The issue is, quite simply, that I can apply some strategies to significantly reduce both speed &amp; size of serialization by making sure that the serialization pipeline knows exactly what is going on (string tables &amp; flyweight objects).  I started looking into the standard .NET serialization pipeline, but that was quickly ruled out. There are several reasons for that, first, you literally cannot hook deep enough into the serialization pipeline to do the sort of things that I wanted to do (you cannot override how System.String get persisted), and it is far too slow for my usages.  My test data started as a ~900Mb of messages, which I loaded into the profiler (resulting in a 4 GB footprint during processing and a 1.5GB footprint when processing is done). Persisting the in memory objects using BinaryFormatter resulted in a file whose size is 454Mb and whose deserialization I started before I started writing this post and at this point in time has not completed yet. Currently the application (simple cmd line test app that only does deserialization, takes 1.4 GB).  So that was utterly out. So I set out to write my own serialization format. Since I wanted it to be fast, I couldn&#x2019;t use reflection, (BF app currently takes 1.6 GB) but by the same token, writing serialization by hand is labor intensive, error prone method. That lives aside the question of handling changes in the objects down the road, that is not something that I would like to do.  Having come to that conclusion, I decided to make use of CodeDOM to generate a serialization assembly on the fly. That would give me the benefits of no reflection, handle addition of new members to the serialized objects and would allow me to incrementally improve how (BF app now takes 2.2 GB, and I am getting ready to kill it). My first attempt in doing so, applying absolutely not optimization techniques, result in a 381 Mb file and an 8 seconds parsing time.  That is pretty good, but I wanted to do a bit more.   Now, note that this is an implementation specific for a single use. After applying a simple string table optimization, the results of the serialization are two files, the string table is 10Mb in length and the actual saved data is 215Mb and de-serialization takes ~10 seconds. Taking a look at what actually happened, it looked like the cost of maintaining string table is quite high. Since I care more about responsiveness than file size, and since the code for maintaining the string table is complex, I dropped that in favor of in memory only MRU string interning.  Initial testing shows that this should be quite efficient in reducing memory usage. In fact, in my test scenario, memory consumption during processing dropped down 4 GB to just 1.8 &#x2013; 1.9 GB and 1.2 GB when processing is completed. And just using the application shows that the user level performance is pretty good, even if I say so myself.  There are additional options that I intend to take, but I&#x2019;ll talk about them in a later post.</p>
        </article>
        <article id="article-5438">
            <a href="https://ayende.com/blog/4342/a-persistence-problem-irony-your-name-is" target="_blank">
                <h2 class="title mb-6" id="article-5438">A persistence problem, irony, your name is&#x2026;</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 28, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The major goal that I had in mind for the profiler was online development usage. That is, do something, check the profiler, clear it, do something else, etc. One of the things that I am finding out is that people use it a lot more as a dumping ground. They push a lot of information into it, and then want to sift through that and look at how the application behave, not just a single scenario.  Surprisingly, it works quite well, especially with the recently implemented performance profiling sessions that we just run through. One scenario, however, remains stubbornly outside what the profiler can currently do. When people talk to me about it, they call it load tests profiling, or integration tests profiling. This is when you pour literally gigabytes of information into the profiler. And it works, provided you have enough memory, that is.  If you don&#x2019;t have enough memory, however, you get to say hello to OutOfMemoryException.  When I dove into this problem I was sure that I would simply find that there is something stupid that I am doing wrong, and that as soon as I&#x2019;ll figure it out, it will be all right. I actually did find a few places where I could optimize memory usage (reducing lambda usage in favor of cached delegates to named methods, for example), but that only shaved a few percentage points. Trying out string interning actually resulted in a huge saving in memory, but I feel that this is just a stop gag measure. I have to persist the data to disk, rather than keep it in memory.  That lead me to a very interesting problem. What I need is basically a key value store. Interestingly enough, I already wrote one. The problem is that while this would work great right now, I have future plans which means depending on Esent is an&#x2026; unwise choice. Basically, I would like to be able to run on Mono and/or Silverlight and that rules out using a Windows only / full trust native dll. As they say, a bummer. That requirement also rules out using the various embedded databases as well.  I considered ignoring this requirement and handling it when the times come, but I decided that since this is going to majorly effect how I am going to use it, I can&#x2019;t really afford to delay that decision. With that in mind, I set out to figure out what I needed:     A fast way to store / retrieve a session information along with its associated data (stack trace, alerts, statistics, etc).    Ability to store, at a minimum, tens of thousands of items of variable size.    A single file (or at least, very few files) &#x2013; cannot afford to have one item per file (it usually kills the FS).    Support updates without re-writing the entire file.    Usable from Mono &amp; Silverlight, or easily portable to them.   With that in mind, I decided to take a look at what is already out there.     C#-Sqlite looked like it might be the ticker. It is a C# port of the Sqlite database. Unfortunately, I took a look at the code base and it is a port to C#, the code gave me the willies. I don&#x2019;t feel that I can trust it, and at any rate, it would require me to write a lot of data access code, that is a thing that I am trying to avoid :-). (And no, you can&#x2019;t use NHibernate with that version, you would have to port the ADO.Net driver as well, and then you wouldn&#x2019;t be able to use it in Silverlight anyway.)    Caching Application Block &#x2013; because it looked like it had a persistent solution already. That persistent solution is based on several files per item, which is not acceptable. I already tried that route in the past, it is a good way to kill your file system.    SilverDB &#x2013; this is an interesting code base, and a good solution for the problem it is meant to (saving relatively small amount of information to disk). However, I need to save large amounts of information, and I need to handle a lot of updates. SilverDB re-write the entire file whenever it is saving. That has too high a perf cost for my needs.    TheCache &#x2013; I took only a brief look here, but it looks that it is too heavily focused on being a cache to be useful for my purposes.   In fact, given my requirements, it might be interesting to see what I don&#x2019;t need.     Not reliable.    Not thread safe.    Saving is just a way to free memory.   Given that, I decided to go with the following method:     Custom serialization format, allowing me to save space &amp; time using file &amp; memory based string interning.    No persistent file index, that can be kept directly in memory.    Persisted string interning file.   As you can see, this is a very tailored solution, not something that would be generally useful, but I have great hopes for this.</p>
        </article>
        <article id="article-5439">
            <a href="https://ayende.com/blog/4341/string-interning-the-garbage-collectible-way" target="_blank">
                <h2 class="title mb-6" id="article-5439">String Interning: The Garbage Collectible way</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 27, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Since I know people will want the actual implementation, here is a simple way of handling string interning in a way that will allow you to GC the results at some point. The issue is simple, I want to intern strings (so a string value is only held once through my entire app), but I don&#x2019;t want to be stuck with them if the profiler state has been clear, for example.      public class GarbageCollectibleStringInterning&#xA;{&#xA;    private static IDictionary&lt;string,string&gt; strings = new Dictionary&lt;string,string&gt;();&#xA;&#xA;    private static ReaderWriterLockSlim locker = new ReaderWriterLockSlim();&#xA;    &#xA;    public static void Clear()&#xA;    {&#xA;        locker.EnterWriteLock();&#xA;        try&#xA;        {&#xA;            strings.Clear();&#xA;        }&#xA;        finally&#xA;        {&#xA;            locker.ExitWriteLock();&#xA;        }&#xA;    }&#xA;    &#xA;    public static string Intern(string str)&#xA;    {&#xA;        string val;&#xA;        &#xA;        locker.EnterReadLock();&#xA;        try&#xA;        {&#xA;            if(strings.TryGetValue(str, out val))&#xA;                return val;&#xA;        }&#xA;        finally&#xA;        {&#xA;            locker.ExitReadLock();&#xA;        }&#xA;        &#xA;        locker.EnterWriteLock();&#xA;        try&#xA;        {&#xA;            if(strings.TryGetValue(str, out val))&#xA;                return val;&#xA;                &#xA;            strings.Add(str,str);&#xA;            return str;&#xA;        }&#xA;        finally&#xA;        {&#xA;            locker.ExitWriteLock();&#xA;        }&#xA;    }&#xA;}&#xA;  &#xA;&#xA;This is a fairly simple implementation, a more complex one may try to dynamically respond to GC notification, but I think that this would be useful enough on its own.&#xA;&#xA;Using this approach, I was able to reduce used memory in the profiler by over 50%. I gave up on that approach, however, because while it may reduce the memory footprint, it doesn&#x27;t actually solve the problem, only delay it.</p>
        </article>
        <article id="article-5440">
            <a href="https://ayende.com/blog/4340/the-operation-was-successful-but-the-patient-is-still-dead-deferring-the-obvious-doesnt-work" target="_blank">
                <h2 class="title mb-6" id="article-5440">The operation was successful, but the patient is still dead&#x2026; deferring the obvious doesn&#x2019;t work</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 26, 2009
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">So, I have a problem with the profiler. At the root of things, the profiler is managing a bunch of strings (SQL statements, stack traces, alerts, etc). When you start pouring large amount of information into the profiler, the number of strings that it is going to keep in memory is going to increase, until you get to say hello to OutOfMemoryException.  During my attempt to resolve this issue, I figured out that string interning was likely to be the most efficient way to resolve my problem. After all, most of the strings that I have to display are repetitive. String interning has one problem, it exists forever. I spent a few minutes creating a garbage collectible method of doing string interning. In my first test, which was focused on just interning stack traces, I was able to reduce memory consumption by 50% (about 800Mb, post GC) and it is fully garbage collectible, so it won&#x2019;t hung around forever.  Sounds good, right?  Well, not really. While it is an interesting thought experiment, using interning is a great way of handling things, but it only mask the problem, and that only for a short amount of time. The problem is still an open ended set of data that I need to deal with, and while there are a whole bunch of stuff that I can do to delay the inevitable, defeat is pretty much ensured. The proper way of doing that is not trying to use hacks to reduce memory usage, but to deal with the root cause, keeping everything in memory.</p>
        </article>
        <div class="button flex justify-between">
            <a href="543.html"><span class="back arrow"></span></a>

            <a href="545.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2024<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>
</body>
</html>