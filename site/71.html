
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 71 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
    <!-- Google Analytics -->
    <script>
        // Only load GA if consent is given
        function loadGA() {
            const script = document.createElement('script');
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-MDFXJY3FCY';
            script.async = true;
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }

            gtag('js', new Date());
            gtag('config', 'G-MDFXJY3FCY');
        }

        // Check if consent was previously given
        if (localStorage.getItem('cookieConsent') === 'accepted') {
            loadGA();
        }
    </script>
    <!-- End Google Analytics -->
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-701">
            <a href="https://ayende.com/blog/198049-A/re-how-discord-supercharges-network-disks-for-extreme-low-latency" target="_blank">
                <h2 class="title mb-6" id="article-701">re</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 16, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I read this blog post from Discord, which presents a really interesting approach to a problem that they ran into. Basically, in the cloud you have the choice between fast and ephemeral disks and persistent (and much slower) disks.&#xA;Technically speaking you can try to get really fast persistent disks, but those are freaking expensive. Ultra disks on Azure and io2 disks on AWS and Extreme persistent disks for GCP. The cost for a single 1TB disk with 25K IOPS would be around 1,800 USD / month, for example. That is just for the disk!&#xA;To give some context, an r6gd.16xlarge instance with 64 cores and 512 GB (!) of RAM as well as 3.8 TB of NVMe drive will cost you less than that. That machine can also do 80K IOPS, for context.&#xA;At Discord scale, they ran into the limitations of I/O in the cloud with their database and had to come up with a solution for that.&#xA;My approach would be to&#x2026; not do anything, to be honest. They are using a database (ScyllaDB) that is meant to run on commodity hardware. That&#xA0;means that losing a node is an expected scenario. The rest of the nodes in the cluster will be able to pitch in and recover the data when the node comes back or is replaced. That looks like the perfect scenario for running with fast ephemeral disks, no?&#xA;There are two problems with ephemeral disks. First, they are ephemeral , wich means that a hardware problem can make the whole disk go poof. Not an issue, that is why you are using a replicated database, no? We&#x2019;ll get to that.&#xA;Another issue that is raised by Discord is that they rely on disk snapshots for backups and other important workflows. The nice thing about snapshotting a cloud disk is that it is typically fast and cheap to do. Otherwise you need to deal with higher level backup systems at the database layer. The issue is that you probably do want that, because restoring a system from a set of disk snapshots that were taken at different times and at various states is likely to be&#x2026; challenging.&#xA;Discord&#x27;s solution to this is to create a set of ephemeral disks that are mirrored into persistent disks. Reads are going to the fast disks and writes are spread around. A failure on the ephemeral disks will lead to a recovery of the data from the network disk.&#xA;Their post has the gory details and a lot more explanation aside. I wanted to write this post for a simple reason. As a database guy, this system scares me to pieces.&#xA;The issue is that I don&#x2019;t know what kind of data consistency we can expect in such an environment. Do I get any guarantees about the equivalence of data between the fast disks and the network disk? Can they diverge from one another? What happens when you have partial errors?&#xA;Consider a transaction that modifies three different pages that end up going to three different fast disks &#x2B; the network disk. If one of the fast disks has an error during write, what is written to the persistent disk?&#xA;Can I get an out-of-date read from this system if we read from the network disk for some reason? That may mean that two pages that were written in one transaction are coming back as different versions. That will likely violate assumptions and invariants and can lead to all sorts of&#x2026; interesting problems.&#xA;Given that this system is meant to handle the failure modes, it sounds really scary because it is an additional layer of complexity (and one that the database is unaware of) to deal with.&#xA;Aside from the snapshots, I assume that the reason for this behavior is to avoid the cost of rebuilding a node when there is a failure. I don&#x2019;t have enough information to say what is the failure rate and the impact on the overall system, but the solution provided is elegant, beautiful, and quite frankly, pretty scary to me.&#xA;There have been quite a few unknowns that we had to deal with in the realm of storage. But this adds a whole new layer of things that can break.</p>
        </article>
        <article id="article-702">
            <a href="https://ayende.com/blog/198017-A/importing-the-stack-overflow-dataset-into-ravendb" target="_blank">
                <h2 class="title mb-6" id="article-702">Importing the Stack Overflow dataset into RavenDB</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 15, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Around 2017 we needed to test RavenDB with realistic datasets. That was the time that we were working hard on the 4.0 release, and we wanted to have some common dataset that was production quality (for all the benefits and complications that this brings) to play with.&#xA;A serious issue was that we needed that dataset to also be public, because we wanted to discuss its details. The default dataset people usually talk about in such a scenario is the Enron emails, but that is around half a million documents and quite small, all things considered.&#xA;Luckily for us, Stack Overflow has made their dataset publicly available in a machine readable format. That means that we could take that, adapt that to RavenDB and use that to test various aspects of our behaviors with realistic data.&#xA;The data is distributed as a set of XML files, so I quickly wrote something that would convert the data to a JSON format and adapt the model to a more relational one. The end result was a dataset with 18 million documents and with a hefty size of 52 GB. I remember that at the time, working with this data was a lengthy process. Importing the data took a long time and indexing even longer.&#xA;A few years later, this is still our go-to dataset for anything involving non-trivial amount of data, but we have gotten to the point where the full process of working with it has shrunk significantly. It used to take 45&#x2B; minutes to import the data, now it takes less than 10, for example. Basically, we made RavenDB good enough that it wasn&#x2019;t that much of a challenge.&#xA;Of course&#x2026; Stack Overflow continues to publish their dataset&#x2026; so I decided it was time to update their data again. I no longer have the code that I used to do the initial import, but the entire process was fairly simple.&#xA;You can look at the code that is used to do the import here. This is meant to be quick &amp; dirty code, mind you. It is about 500 lines of code and handles a surprisingly large number of edge cases.&#xA;You can find the actual data dump here.&#xA;And the explanation about the schema is here.&#xA;There is also a database diagram here.&#xA;In case you missed the point, the idea is that I want to remember how I did it for the next time I&#x27;ll want to refresh our dataset.&#xA;So far, I imported a bunch of Stack Exchange communities:&#xA;&#xA;World Building &#x2013; Just over 100K documents and 1 GB in size. Small enough to play with seamlessly.&#xA;Super User &#x2013; 1.85 million documents and weighing 4 GB in size. I think we&#x2019;ll use that as the default database for showing things off on the Raspberry Pi edition.&#xA;Stack Overflow &#x2013; 40.5 million documents and exceeding 150 GB in size. This is a great scenario for working with a significant amount of data. That is likely to be our new default benchmarking database.&#xA;&#xA;The other advantage is that everyone is familiar with Stack Overflow. It makes for a great demo when we can pull up realistic data on the fly.&#xA;It already gave me some interesting details to explore. For example, enabling documents compression mode for the Super User community reduced the disk utilization to under 2 GB. That is a great space-saving, and it means that we can easily fit the entire database on a small SD card and have a &#x201C;RavenDB Server &#x2B; Database in a box&#x201D; as a Raspberry Pi.&#xA;The Stackoverflow dataset is 150GB without compression, with documents compression, it dropped to just 57GB, which is all kinds of amazing.&#xA;They make for great demos .</p>
        </article>
        <article id="article-703">
            <a href="https://www.meziantou.net/generate-pinvoke-code-for-win32-apis-using-a-source-generator.htm" target="_blank">
                <h2 class="title mb-6" id="article-703">Generating PInvoke code for Win32 apis using a Source Generator</h2>
            </a>
            <p class="mb-2">by G&#xE9;rald Barr&#xE9;</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 15, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Writing PInvoke code is not trivial. Most of the time you need to find the method signature from the documentation or the header files. This takes time and is error-prone. Also, you can&#x27;t find a NuGet package that wraps all Win32 methods because the number of methods, constants and structures is hu</p>
        </article>
        <article id="article-704">
            <a href="https://ayende.com/blog/197761-C/architectural-optimizations-vs-the-profiler" target="_blank">
                <h2 class="title mb-6" id="article-704">Architectural optimizations vs the profiler</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 12, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">For the past couple of years, we had a stealth project going on inside of RavenDB. That project is meant to re-architect the internals of how RavenDB handles queries. The goal is to have a major performance improvement for RavenDB indexing and queries.&#xA;We spent a lot of time thinking about architecting this. Design discussions for this feature goes back to 2015, to give you some context. The codename for this project is: Corax.&#xA;Recently we finished wiring the new engine into RavenDB and for the first time in a long while, we could actually do a comparative benchmark between the two implementations. For this post, I&#x2019;m going to focus solely on indexing performance, by the way.&#xA;Here is a couple of (very simple) indexes working on indexing a 497 million documents.&#xA;&#xA;You can see that the numbers are pretty good, but we just started. Here is what the numbers look like after about 7 million documents being indexed:&#xA;&#xA;You can see that Corax already opened up quite a gap between the two engines.&#xA;As a reminder, we have been optimizing our indexing process with Lucene for literally over a decade. We have done a lot to make things fast. Corax is still beating Lucene quite handily.&#xA;However, let&#x2019;s take a look here, so far we indexed ~16 million documents and we can see that we are slowing down a bit:&#xA;&#xA;That actually makes sense, we are doing quite a lot of work around here. It is hard to maintain the same speed when you aren&#x2019;t working on a blank slate.&#xA;However, Corax was architected for speed, so while we weren&#x2019;t surprised by the overall performance, we wanted more. We started analyzing what is going on. Quite quickly we figured out a truly stupendous issue in Corax.&#xA;One of the biggest problems when competing with Lucene is that it is a great library. It has certain design tradeoffs that I don&#x2019;t like, but the key issue is that you can&#x2019;t just build your own solution. You need to match or exceed whatever Lucene is doing.&#xA;One of the design decisions that has a major impact on how Lucene operates is that it is using an LSM model (log structured merge). This means that it writes data to immutable files (segments) and merge them occasionally. That means that handling deletes in Lucene is naturally handled during those merges. It means that Lucene can get away with tracking a lot less data about the entries that it indexed. That reduces the overall disk space it requires.&#xA;Corax takes a different approach, we don&#x2019;t do compaction, because that lead to occasional spikes in computes and I/O needs. Instead, Corax uses a steady progress model. That means that it needs to track more data than Lucene.&#xA;Our first Corax indexes took about 5 &#x2013; 10 times more disk space than Lucene. That isn&#x2019;t a percentage, that is five to ten times bigger. One of the ways we handle this is to use an adaptive compression algorithm. We look at the entries that are being indexed and compress them. We don&#x2019;t do that blindly, we generate a dictionary to match the actual entries at hand and are able to achieve some spectacular compression rate. Corax still uses more disk space than Lucene, but now the difference is in percentages, rather than in multiples.&#xA;On a regular basis, we&#x2019;ll also check if the type of data that is being indexed has changed and we need to re-compute the dictionary. It turns out that we did that using a random sampling of the entries in the index. The number of samples range from 1 in 10 to 1 in 100, depending on the size of the index.&#xA;Then we threw a half billion index entries at Corax, and merely checking whether the dictionary could be better would result in us computing a dictionary with over 5 million entries. That was easily fixed, thankfully. We need to limit the scan not just in proportion to the size of the index but also globally. We can rely on the random nature of the sampling to give us a better dictionary next time, if needed. And it won&#x2019;t stall the indexing process.&#xA;After jumping over the most obvious hurdles, the next stage is to pull the profiler and see what kind of bottlenecks we have in the system. Here is the first thing that popped out to me:&#xA;&#xA;Over 10% of the indexing time is spent on adding an item to CollectionOfBloomFilters, what is that?&#xA;Well, remember how I said that Lucene optimized its file structure to handle deletes better? One of the consequences of that is that deletes can be really expensive. If you are indexing a new document (which doesn&#x2019;t need to delete), you can have a significant time saving by skipping that. This is the rule of the bloom filter here. Yes, even with that cost, for Lucene it is worth it.&#xA;For Corax&#x2026; however, that isn&#x2019;t the case. We can just skip that cost entirely.&#xA;&#xA;10.75% performance boost&#xA;&#xA;Next&#x2026; we have this dude:&#xA;&#xA;That call is meant to update the number of records that Corax is holding in the index. We are updating a persistent value once for each entry that is indexed. But we can do that once for the entire batch!&#xA;&#xA;2.81% performance boost&#xA;&#xA;Those are easy, no? What is next?&#xA;&#xA;For each term that we run, we rent and return a buffer. For each term! That alone takes 1% of the indexing time. Utterly ridiculous. We can use a single buffer for the entire indexing operation, after all.&#xA;As for the IsAnalayzed property? That does some (trivial) computation, but we know that the value is immutable. Make that once in the constructor and turn that property into a field.&#xA;&#xA;1.33% performance boost&#xA;&#xA;Those are literally just the things we noticed in the first few minutes. After applying those changes, I reset the indexing and looked at the results after it ran for a while. And now that, I&#x2019;ll admit, is far more gratifying.&#xA;&#xA;It is really interesting to see the impact of seemingly minor changes like those. Especially because the architecture holds up quite well.&#xA;Corax is proceeding quite well and we have really great hopes for it. We need to hammer on it a bit more, but it is showing a lot of promise.&#xA;The really interesting thing is that all those changes (which ended up pretty much doubling the effective indexing speed) are all relatively minor and easily fixed. That is despite the fact that we wrote Corax to be optimized, you always find surprises when you run the profiler, and sometimes they are very pleasant ones.</p>
        </article>
        <article id="article-705">
            <a href="https://ayende.com/blog/197698-B/my-new-interview-task-stop-the-flow" target="_blank">
                <h2 class="title mb-6" id="article-705">My new interview task: Stop the flow</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 11, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">We run into an interesting scenario at work that I thought would make for a pretty good interview task. Consider a server that needs to proxy a request from the outside world to an internal service, something like this:That isn&#x2019;t that interesting. The interesting bit is that the network between the internal server and the proxy is running at 10Gb/sec and the external network is limited to 512Kb/sec. Furthermore, the internal server expects the other side to just&#x2026; take the load. It will blast the other side with as much data as it can, and if you can&#x2019;t handle that, will cut the connection. What this means is that for small requests, the proxy can successfully pass the data to the external server, but for larger ones, it is unable to read the data quickly enough to do so and the internal server will disconnect from it.It is the responsibility of the proxy to manage that scenario.&#xA0; That is the background for this task, practically speaking, this means that you have the following code, which works if the size is 8MB but fails if it is 64MB. We have the SlowClientStream and the FastServerStream &#x2013; which means that we are able to focus completely on the task at hand (ignoring networks, etc).The requirement is to pass a 64 MB of data between those two streams (which have conflicting requirements)The FastServerStream requires that you&#x2019;ll read from it in a rate of about 31Kb / sec.The SlowClientStream, on the other hand, will accept data at a maximum rate of about 30Kb/sec (but is variable across time). You may not change the implementation of either stream (but may add behavior in separate classes). You may not read the entire response from the server before sending to the client.There is a memory limit of 32 MB on the maximum amount of memory you may use in the program.How would you go about solving this?The challenge skeleton is here.</p>
        </article>
        <article id="article-706">
            <a href="https://andrewlock.net/handling-concurrent-merges-to-master-in-multi-stage-azure-devops-pipelines/" target="_blank">
                <h2 class="title mb-6" id="article-706">Handling concurrent merges to master in multi-stage Azure DevOps pipelines</h2>
            </a>
            <p class="mb-2">by Andrew Lock</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 09, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In this post I describe a problem we were seeing in our large Azure DevOps pipeline, where a merge to master would cause PR builds to break mid-run.&#x2026;</p>
        </article>
        <article id="article-707">
            <a href="https://ayende.com/blog/197985-A/tracking-down-ravendb-i-o-usage-in-linux" target="_blank">
                <h2 class="title mb-6" id="article-707">Tracking down RavenDB I/O usage in Linux</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 08, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Today I had to look into the a customer whose RavenDB instance was burning through a lot of I/O. The process is somewhat ingrained in me by this point, but I thought that it would make for a good blog post so I&#x2019;ll recall that next time.Here is what this looks like from the point of view of the disk:We are seeing a lot of reads in terms of MB/sec and a lot of write operations (but far less in terms of bandwidth). That is the external details, can we figure out more? Of course.We start our investigation by running:sudo iotop -aoThis command gives us the accumulative time for threads that do I/O. One of the important things that RavenDB is to tag its threads with the tasks that they are assigned. Here is a sample output:  TID  PRIO  USER     DISK READ DISK WRITE&gt;  SWAPIN      IO    COMMAND&#xA; 2012 be/4 ravendb    1748.00 K    143.81 M  0.00 %  0.96 % Raven.Server -c /ravendb/config/settings.json [Follower thread]&#xA; 9533 be/4 ravendb     189.92 M     86.07 M  0.00 %  0.60 % Raven.Server -c /ravendb/config/settings.json [Indexing of Use]&#xA; 1905 be/4 ravendb     162.73 M     72.23 M  0.00 %  0.39 % Raven.Server -c /ravendb/config/settings.json [Indexing of Use]&#xA; 1986 be/4 ravendb     154.52 M     71.71 M  0.00 %  0.38 % Raven.Server -c /ravendb/config/settings.json [Indexing of Use]&#xA; 9687 be/4 ravendb     185.57 M     70.34 M  0.00 %  0.59 % Raven.Server -c /ravendb/config/settings.json [Indexing of Car]&#xA; 1827 be/4 ravendb     172.60 M     65.25 M  0.00 %  0.69 % Raven.Server -c /ravendb/config/settings.json [&#x27;Southsand&#x27;]In this case, we see the top 6 threads in terms of I/O (for writes). We can see that we have a lot of of indexing and documents writes. That said, thread names in Linux are limited to 14 characters, so we probably need to give better names to them.That is part of the task, let&#x2019;s look at the cost in terms of reads:  TID  PRIO  USER    DISK READ&gt;  DISK WRITE  SWAPIN      IO    COMMAND&#xA;11191 be/4 ravendb       2.09 G     31.75 M  0.00 %  7.58 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11494 be/4 ravendb    1353.39 M     14.54 M  0.00 % 19.62 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11496 be/4 ravendb    1265.96 M      4.97 M  0.00 % 16.56 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11211 be/4 ravendb    1120.19 M     42.66 M  0.00 %  2.83 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11371 be/4 ravendb    1114.50 M     35.25 M  0.00 %  5.00 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11001 be/4 ravendb    1102.55 M     43.35 M  0.00 %  3.12 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]&#xA;11340 be/4 ravendb     825.43 M     26.77 M  0.00 %  4.85 % Raven.Server -c /ravendb/config/settings.json [.NET ThreadPool]That is a lot more complicated, however. Now we don&#x2019;t know what task this is running, only that something is reading a lot of data.We have the thread id, so we can make use of that to see what it is doing:sudo strace -p 11191 -cThis command will track the statistics on the systems calls that are issued by the specified thread. I&#x2019;ll typically let it run for 10 &#x2013; 30 seconds and then hit Ctrl&#x2B;C, giving me:% time     seconds  usecs/call     calls    errors syscall&#xA;------ ----------- ----------- --------- --------- ----------------&#xA; 90.90    3.868694         681      5681        82 futex&#xA;  8.28    0.352247           9     41035           sched_yield&#xA;  0.79    0.033589        1292        26           pwrite64&#xA;  0.03    0.001246          52        24         1 recvfrom&#xA;  0.01    0.000285         285         1           restart_syscall&#xA;  0.00    0.000000           0         2           madvise&#xA;  0.00    0.000000           0         2           sendmsg&#xA;------ ----------- ----------- --------- --------- ----------------&#xA;100.00    4.256061                 46771        83 totalI&#x2019;m mostly interested in the pwrite64 system call. RavenDB uses mmap() for most of its data access, so that is harder to read, but we can get a lot of information from the output. Now I&#x2019;m going to run the following command:sudo strace -p 11191 -e trace=pwrite64This will give us a trace of all the pwrite64() system calls from that thread, looking like this:pwrite64(315, &quot;\365\275&quot;..., 4113, 51080761896) = 4113&#xA;pwrite64(315, &quot;\344\371&quot;..., 4113, 51080893512) = 4113There is an strace option (-y) that can be used to show the file paths for system calls, but I forgot to use it, no worries, I can do:sudo ls -lh /proc/11191/fd/315Which will give me the details on this file:lrwx------ 1 root root 64 Aug  7 09:21 /proc/11783/fd/315 -&gt; /ravendb/data/Databases/Southsand/PeriodicBackupTemp/2022-08-07-03-30-00.ravendb-encrypted-full-backup.in-progressAnd that tells me everything that I need to know. The reason we have high I/O is that we are generating a backup file. That explains why we are seeing a lot of reads (since we need to read in order to generate the backup).The entire process is mostly about figuring out exactly what is going on, and RavenDB is very careful about leaving as many breadcrumbs as possible to make it easy to follow.</p>
        </article>
        <article id="article-708">
            <a href="https://www.meziantou.net/using-a-custom-build-pipeline-with-azure-static-web-apps.htm" target="_blank">
                <h2 class="title mb-6" id="article-708">Using a custom build pipeline with Azure Static Web Apps</h2>
            </a>
            <p class="mb-2">by G&#xE9;rald Barr&#xE9;</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 08, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Azure Static Web Apps allows to host static web sites and their API. They also provide a GitHub action to build and deploy your application. The GitHub action automatically detects the kind of project from the sources and builds it. It currently supports many JavaScript frameworks and static site g</p>
        </article>
        <article id="article-709">
            <a href="https://ayende.com/blog/197953-A/production-postmortem-the-allocating-query" target="_blank">
                <h2 class="title mb-6" id="article-709">Production postmortem</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 05, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">A customer was experiencing large memory spikes in some cases, and we were looking into the allocation patterns of some of the queries that were involved. One of the things that popped up was a query that allocated just under 30GB of managed memory during its processing.&#xA;Let me repeat that, because it bears repeating. That query allocated 30(!) GB(!) during its execution. Now, that doesn&#x2019;t mean that it was consuming 30 GB, it was just the allocations involved. Most of that memory was immediately discarded during the operation. But 30 GB of garbage to cleanup puts a lot of pressure on the system. We took a closer look at the offensive query. It looked something like this:&#xA;&#xA;from index &#x201C;Notifications/RoutingAndPriority&#x201D; where startsWith(Route, $routeKeyPrefix) order by Priority desc&#xA;&#xA;That does not seem like a query that should be all that expensive. But details matter, so we dove into this. For this particular query, the routes are hierarchical structures that are unique for each message. Something like:&#xA;&#xA;notifications/traffic/new-york-city/67a81019-941b-4d04-a0db-0559ed45343c&#xA;notifications/emergency/las-vegas/0a8e18fb-563b-4b6a-8e93-e10e08239656&#xA;&#xA;And the queries that were generated were using the city &amp; topic to filter the information that they were interested in.&#xA;The customer in question had a lot of notifications going on at all times. And each one of their Routes was unique. Internally, RavenDB uses Lucene (currently  ) to handle searches, and Lucene is using an inverse index to execute queries.&#xA;The usual way to think about is like this:&#xA;&#xA;We have a list of terms (Brown, Green &amp; Purple) and each of them has a list of the matching documents that contain the particular term.&#xA;The process of issuing a prefix query then is easy, scan all entries that match the prefix and return their results. This is indeed what Lucene is doing. However&#x2026; while it is doing that, it will do something like this:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          var termsEnum = GetTermsEnum();&#xA;        &#xA;        &#xA;          &#xA;          foreach(string term in termsEnum.Prefix(&quot;notifications/traffic/new-york-city/&quot;))&#xA;        &#xA;        &#xA;          &#xA;          {&#xA;        &#xA;        &#xA;          &#xA;              foreach(int match in docsEnum.ForTerm(term))&#xA;        &#xA;        &#xA;          &#xA;              {&#xA;        &#xA;        &#xA;          &#xA;                   yield return match;&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          prefix.cs&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;Pay close attention to what is actually happening here. There are two enumerators that we work with. One for the terms for the field and one for the documents for a specific term.&#xA;All of this is perfectly reasonable, but there is an issue. What happens when you have a lot of unique values? Well, then Lucene will have a lot of iterations of the loop. In this case, each term has just a single match, and Lucene is pretty good at optimizing search by specific term.&#xA;The actual problem is that Lucene allocates a string instance for each term. If we have 30 million notifications for New York&#x2019;s traffic, that means that we&#x2019;ll allocate 30 million strings during the processing of the query. We aren&#x2019;t retaining these strings, mind. They&#x2019;ll be cleaned up by the GC quickly enough, but that is an additional cost that we don&#x2019;t actually want.&#xA;Luckily, in this case, there is a much simple solution. Given that the pattern of the route is known, we can skip the unique portion of the route. That means that in our index, we&#x2019;ll do something similar to:&#xA;&#xA;Route = doc.Route.Substring(0, doc.Route.LastIndexOf(&#x27;/&#x27;) &#x2B; 1)&#xA;&#xA;Once that is done, the number of unique matches there would be negligible. There would be no more allocations galore to observe and overall system performance is much improved.&#xA;We looked into whether&#xA0;there is something that we can do with Lucene to avoid this allocations issue, but it is endemic to the way the API works. The longer term plan is to fix that completely, of course. We are making great strides there already .&#xA;In short, if you are doing startsWith() queries or similar, pay attention to the number of unique terms that you have to go through. A simple optimization on the index like the one above can bring quite a bit of dividends.</p>
        </article>
        <article id="article-710">
            <a href="https://ardalis.com/unsupported-audio-format-set-audio-output-pcm/" target="_blank">
                <h2 class="title mb-6" id="article-710">Solved: Unsupported audio format set the audio output to pulse code modulation PCM</h2>
            </a>
            <p class="mb-2">by Ardalis</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 02, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Solved! My dell monitor had started showing an annoying error every 30 seconds or so saying &#x27;Unsupported audio format. Set the audio output&#x2026;Keep Reading &#x2192;</p>
        </article>
        <div class="button flex justify-between">
            <a href="70.html"><span class="back arrow"></span></a>

            <a href="72.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>

<!-- Cookie Consent Banner -->
<div class="cookie-consent" id="cookieConsent">
    <div>
        <p class="text-sm">We use cookies to analyze our website traffic and provide a better browsing experience. By
            continuing to use our site, you agree to our use of cookies.</p>
    </div>
    <div class="cookie-consent-buttons">
        <button class="cookie-consent-decline" onclick="declineCookies()">Decline</button>
        <button class="cookie-consent-accept" onclick="acceptCookies()">Accept</button>
    </div>
</div>

<script>
    // Cookie consent management
    function showCookieConsent() {
        const consent = localStorage.getItem('cookieConsent');
        if (!consent) {
            document.getElementById('cookieConsent').classList.add('show');
        }
    }

    function acceptCookies() {
        localStorage.setItem('cookieConsent', 'accepted');
        document.getElementById('cookieConsent').classList.remove('show');
        loadGA(); // Load Google Analytics after consent
    }

    function declineCookies() {
        localStorage.setItem('cookieConsent', 'declined');
        document.getElementById('cookieConsent').classList.remove('show');
    }

    // Show the consent banner only for EU visitors (you can add more country codes as needed)
    fetch('https://ipapi.co/json/')
            .then(response => response.json())
            .then(data => {
                const euCountries = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE'];
                if (euCountries.includes(data.country_code)) {
                    showCookieConsent();
                } else {
                    // For non-EU visitors, automatically load GA
                    if (!localStorage.getItem('cookieConsent')) {
                        localStorage.setItem('cookieConsent', 'accepted');
                        loadGA();
                    }
                }
            })
            .catch(() => {
                // If we can't determine location, show the consent banner to be safe
                showCookieConsent();
            });
</script>
</body>
</html>