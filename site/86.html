
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 86 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-851">
            <a href="https://ayende.com/blog/195937-A/production-postmortem-an-error-on-the-first-act-will-lead-to-data-corruption-on-the-second-act" target="_blank">
                <h2 class="title mb-6" id="article-851">Production postmortem</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: January 03, 2022
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The topic of this post is a bug in RavenDB, a pretty serious one. The end result is that a user reported that they got an error from RavenDB that they are unable to read a stored document. In some cases, RavenDB needs to read a document on startup, which means that it wasn&#x2019;t able to start up if that document had this behavior.&#xA;As you can imagine, this is one of those issues that gets our full and immediate attention. The error itself gave us a lot of information:&#xA;&#xA; Dictionary mismatch on Dic #375&#xA;   at Voron.Data.Tables.ZstdLib.AssertSuccess(UIntPtr v, CompressionDictionary dictionary)&#xA;&#xA;This is related to RavenDB&#x2019;s document compression behavior. In order to get a great compression ratio from our documents, we train RavenDB on the recent documents that you have and generate a compression dictionary. The problem at hand is that the compression dictionary we have and the compression dictionary that was actually used are different. As you can see from the error, we are using zstd as the compression algorithm. When zstd generates a dictionary it will (by default) generate an id from that document that is mostly based on the xxhash64 of its content, rounded to 32 bits. You can see the relevant part here. This is pretty nice, since it means that there is a good chance that we&#x2019;ll detect the wrong dictionary.&#xA;So now we know what is going on, but we don&#x2019;t understand why.&#xA;When we wrote this feature, we were quite aware that we&#x2019;ll not be able to make any sort of sense from the documents if we don&#x2019;t have the right dictionary. For that reason, we store the dictionaries three times. Once inside of RavenDB itself and twice in ancillary files, which we can use during recovery. This sort of error should be utterly impossible. And yet, we had run into that in production, so we have to dig deeper still.&#xA;The primary suspect was the dictionary training portion. One of the things that RavenDB does on a continuous basis is measure the compression ratio of the documents, if we aren&#x2019;t able to hit a good compression ratio, RavenDB will try to generate a new dictionary from the most recent documents and see if that new dictionary can do better. This can be very helpful in maintaining good compression rates. As your documents change, RavenDB will detect that and realize that it can do better, retrain on the recent data and compress even further. The problem is that this code path is also quite tricky, we first compress the document using the current dictionary, then we try generating a new dictionary and see if compressing with the new dictionary is better. If that is the case, we can install the new dictionary for future operations, otherwise, we need to discard it.&#xA;I suspected that the issue was somewhere around that area, we might not be handling the rejection of the new dictionary properly. So I went into the code and started digging, but I found absolutely nothing. The entire process is covered in tests and has been in production for close to 18 months, so this isn&#x2019;t something that obvious.&#xA;After spending quite a bit of time on the issue, I decided that the code is perfect, it handled everything properly and taken into account all the right behaviors.&#xA;Clearly the fault was elsewhere. Before setting out to blame the nearest cat (you can never trust those), I had an idea, what if the problem wasn&#x2019;t during the training process, but afterward?&#xA;Well, that doesn&#x2019;t really matter, does it? RavenDB is a transactional database, if we had a failure after the training process, we&#x2019;ll have to discard some of the data, for sure, but that would be about it. Unless, what if we have some state that wasn&#x2019;t transactional? As part of looking at the compression training code, I ran into just such a scenario. Running the training to generate a new compression dictionary is an expensive proposition, so we don&#x2019;t want to do that often. As such, we&#x2019;ll do that for only about 1K document changes where we exceed the desired compression ratio by over 10%. How do we know to act every 1K documents? Well, we have a counter that we increment on every change. That value is incremented using Interlocked.Increment() and isn&#x2019;t part of the transactional state. If the transaction is aborted, the value is still incremented.&#xA0; The actual value doesn&#x2019;t matter, mind, only that it is moving forward, so that isn&#x2019;t an issue.&#xA;I mentioned the dictionary id before, but I should clarify that this is the zstd&#x2019;s dictionary id. Internally, RavenDB uses a different value. That value is simply the sequence number of the dictionary, RavenDB counts the number of generated dictionaries and gives the new dictionary the next available value. That value, by the way, is part of the transaction. If we rollback a transaction, we&#x2019;ll use the same dictionary id. But that doesn&#x2019;t matter, of course.&#xA;When using compression dictionaries, we need to load them from a buffer. There is quite a bit of work that is involved in that, there is memory allocation, entropy tables to load, etc. In order to save repeated work, RavenDB caches the compression dictionaries (after all, their whole point is to be used repeatedly). That cache can be used by multiple transactions at the same time (two read transactions using the same dictionary will use the same instance).&#xA;Given all of this information, here is the sequence of events that we need to get the error in question:&#xA;&#xA;The user enabled documents compression.&#xA;The user runs a transaction with at least four commands, which needs to satisfy the following conditions.&#xA;A document write as the first action.&#xA;Then a write to document whose compression ratio exceeded the expected ratio by over 10%, as a result, RavenDB tried to train a new compression dictionary.&#xA;That dictionary had a better compression ratio and was accepted as the new default compression dictionary.&#xA;RavenDB persisted the new dictionary and used that to compress the new document.&#xA;Another command (in the same transaction) had stored a document in the same collection, now RavenDB will read the new dictionary and store that in a cache.&#xA;A third command runs, but this one throws an error (such as optimistic concurrency violation).&#xA;&#xA;At this point, RavenDB will rollback the entire transaction and return the error to the user. Let&#x2019;s say the user has chosen to submit the same two documents again, shall we?&#xA;For the first command, we&#x2019;ll again discover that the compression ratio (of the old compression dictionary) is insufficient. We will not generate a new compression dictionary, why is that? Remember the counter that we increment using Interlocked? That one was not rolled back, so we&#x2019;ll need to wait for another 1K documents for the stars to properly align for us. That doesn&#x2019;t impact correctness in any way, shape or form, however.&#xA;At this stage, the stage is set, but everything is still okay. The problem will happen on the next time that we&#x2019;ll trigger a new dictionary. At that point, we&#x2019;ll again scan the most recent documents, build a dictionary, etc. However, the dictionary id that RavenDB will use will be identical to the dictionary id that we previously discarded. The data that dictionary was trained on, however, will almost certainly be different. We persist the new dictionary to disk and everyone is happy, the new document that we wrote will use the new compression dictionary and we are perfectly fine.&#xA;The next write for this collection, however, will run into a problem. It will need to use the current (the new one) dictionary when we want to make a write. In order to do that, it will load the value using the cache, but there is already a value for that dictionary in the cache, the same dictionary that was discarded. At this point, RavenDB will start compressing documents using the in memory dictionary while the on disk dictionary is different.&#xA;If you&#x2019;ll try to access the document which triggered the new dictionary, you&#x2019;ll get an error, but documents that were modified later will continue working with no issue. Until you restart, of course.&#xA;On restart, we&#x2019;ll read the dictionary from disk, where we wrote the new dictionary, at this point, all those documents that we wrote will give us the error above. Note that the sequence of events has to be very exact, you need to have a dictionary training as part of a multi act transaction which failed after the dictionary training has been successful and wrote additional documents. In a year and a half of production usage and very heavy load, that happened only a couple of times, it seems.&#xA;The issue has been fixed, of course and we&#x2019;ll be rolling it out to both users and cloud customers. We&#x2019;ll now rollback such in memory state on a transaction rollback as well, avoiding this issue entirely. It is amazing to me that despite very careful planning, it wasn&#x2019;t the code itself that caused a problem, but a sequence of independent operations and failure modes that we never even considered about this.</p>
        </article>
        <article id="article-852">
            <a href="https://ayende.com/blog/195905-C/beating-fizzbuzz-for-detecting-qualified-candidates" target="_blank">
                <h2 class="title mb-6" id="article-852">Beating FizzBuzz for detecting qualified candidates</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 31, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">FizzBuzz is a well known test to show that you can program. To be rather more exact, it is a simple test that does not tell you if you can program well, but if you cannot do FizzBuzz, you cannot program. This is a fail only kind of metric. We need this thing because sadly, we see people that fail FizzBuzz coming to interviews.&#xA;I have another test, which I feel is simpler than FizzBuzz, which can significantly reduce the field of candidates. I show them this code and ask them to analyze what is going on here:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          public class ControllerBase : Controller&#xA;        &#xA;        &#xA;          &#xA;          {&#xA;        &#xA;        &#xA;          &#xA;               public static bool IsAdminUser;&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          snap.cs&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;Acceptable answers include puking, taking a few moments to breathe into a paper bag and mild to moderate professional swearing.&#xA;This is something that I actually run into (about 15 years ago, in the WebForms days) and I have used it ever since. That is a great way to measure just how much a candidate knows about the environment in which they operate.</p>
        </article>
        <article id="article-853">
            <a href="https://ayende.com/blog/195874-C/code-review-horror-in-4-lines-of-code" target="_blank">
                <h2 class="title mb-6" id="article-853">Code review horror in 4 lines of code</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 30, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I run into the following code during code review and had an immediate and visceral reaction.&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          private readonly List&lt;string&gt; _messages;&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;          public IReadOnlyList&lt;string&gt; Messages&#xA;        &#xA;        &#xA;          &#xA;          {&#xA;        &#xA;        &#xA;          &#xA;              get&#xA;        &#xA;        &#xA;          &#xA;              {&#xA;        &#xA;        &#xA;          &#xA;                  lock (this)&#xA;        &#xA;        &#xA;          &#xA;                  {&#xA;        &#xA;        &#xA;          &#xA;                      return _messages;&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          horror.cs&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;This is a (bad) attempt to add thread safety, because you are getting a value through a read only interface, but there is still the mutable instance to work with at the source, and now you have someone that observes the instance while it is being mutated, outside the lock.&#xA;The proper way to handle this is to copy the list (under the lock) and return a distinct copy.</p>
        </article>
        <article id="article-854">
            <a href="https://ayende.com/blog/195873-C/a-year-or-monitoring-production" target="_blank">
                <h2 class="title mb-6" id="article-854">A year or monitoring production</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 29, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The end of the year is closing fast, and I run into the following metric (below). What you can see here is one of our RavenDB production instances over the past year. We are continuously dogfooding our own software, and there is a clear indication of the results.What you can see here is the total memory used by RavenDB (production load, fairly constant over time)&#xA0; for the past year. As we update RavenDB, we benefit from various optimizations, and the trend line is very encouraging.Around August, we had a change that saved us a single allocation in some cases, here is the chance, you can see the impact it had:We also started using a new feature in production around December, and that seems to have an additional memory cost, so we optimized that as well:You can see the new build deployed around the 17th of the month.</p>
        </article>
        <article id="article-855">
            <a href="https://ayende.com/blog/195745-C/implementing-a-file-pager-in-zig-managing-chunk-metadata" target="_blank">
                <h2 class="title mb-6" id="article-855">Implementing a file pager in Zig</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 28, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The file pager needs to know what values it has in memory and what it needs from the disk. Instead of tracking values on a per page level, we are going to do that on a chunk basis, where each chunk in 2MB (256 pages). A single file is going to be limited to 8 GB in size, so we have a maximum of 4,096 chunks in a file. We can allocate a simple array of metadata for the entire file in a single shot. That means that we don&#x2019;t have to do reallocation when we grow the size of the file (up to the 8GB maximum). Let&#x2019;s consider what metadata we need to know about the chunks we have:&#xA;&#xA;What is the status of the chunk (in memory, on the disk, being loaded or errored).&#xA;How many outstanding references we have for a chunk?&#xA;Where do we find the actual chunk data in memory, when it is loaded?&#xA;&#xA;The whole thing is made complex because we have to consider concurrency. Multiple threads may try to load a chunk at the same time, we may need to release the memory of a chunk to make room for loading another, etc. We also need to consider issues such as I/O failures, optimizing I/O patterns, etc. For now, I/O will be handled by another post. I want to focus just on how we will deal with the metadata.&#xA;A major PITA with concurrency is how to handle reference tracking. If a thread is reading from a chunk, we cannot release it. That leads us to reference counting, but that is tough to do atomically. You have to deal with the ABA problem, to start with. For that reason, we want to limit chunk metadata to 8 bytes in total. This will allow us to use atomic instructions to modify the metadata safely.&#xA;Using just 8 bytes is a very low amount. We know that the chunks we&#x2019;ll use are 2MB in size. We can assume that we&#x2019;ll also align them on 2MB boundary. That means that the lower 20 bits are unused, we can repurpose them. On x64 and ARM64, the top 16 bits are also unused (not always true, since from 2019 we have IceLake that has PML5, which uses 57 bits, but very likely to be the case). In most systems, the 47th bit will be used for kernel vs. user memory, so that will be cleared as well. That means that we actually only need 64 &#x2013; 17 &#x2013; 20 = 27 bits to store the pointer value. We can repurpose the other 37 bits.&#xA;There are actually several ways in which we can do this. The compressed pointer method is just one of them. I decided to not go that route. Instead, we are going to have the following structure:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          packed struct { // 64 bits in total &#xA;        &#xA;        &#xA;          &#xA;              tag: enum(u2) {&#xA;        &#xA;        &#xA;          &#xA;                  Empty = 0b00,&#xA;        &#xA;        &#xA;          &#xA;                  Error = 0b01,&#xA;        &#xA;        &#xA;          &#xA;                  Loading = 0b10,&#xA;        &#xA;        &#xA;          &#xA;                  Value = 0b11,&#xA;        &#xA;        &#xA;          &#xA;              },&#xA;        &#xA;        &#xA;          &#xA;              version: u16,&#xA;        &#xA;        &#xA;          &#xA;              references: u20,&#xA;        &#xA;        &#xA;          &#xA;              offsetInPages: u26,&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          metadata_struct.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;This is a packed bit field struct which can fit into a 64 bits value. Note that we have fields for the type of the value, the version (for ABA) and the number of references. In addition to that, we also have the actual value, which is specified in offsetInPages. Let&#x2019;s talk about sizes here.&#xA;&#xA;The tag field has four options, as you can see.&#xA;The version field is 16 bits, which means that it can have 65,536 possible values. It will be incremented on every change to the value and used to avoid false successes when updating the value concurrently.&#xA;The references field is 20 bits in size, giving us 1 million values here. That is the number of concurrent references that it can support. That looks like big enough value that we shouldn&#x2019;t care about it.&#xA;The offsetInPages field is 26 bits in size. Assuming 4 KB pages, we can reference up to 256 GB of memory. We&#x2019;ll want to support machines with higher memory than that, which is why we&#x2019;ll also add the concept of base. For a single file, all the allocations must come in the same 256 GB range. I don&#x2019;t expect that to be a big problem, and different files can have different bases.&#xA;&#xA;The fact that all of that fits in 64 bits means that we can use simple Compare &amp; Swap atomic operations and avoid the need for 128 bits atomic instructions. To be fair, cmpxchg16b has been around forever. I believe that you can do that on ARM as well, but I&#x2019;m not sure how.&#xA;At any rate, let&#x2019;s look at the ChunkMetadata struct in all its glory, then we&#x2019;ll discuss what is going on:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub const ChunkMetadata = packed union {&#xA;        &#xA;        &#xA;          &#xA;              v: packed struct {&#xA;        &#xA;        &#xA;          &#xA;                  tag: enum(u2) {&#xA;        &#xA;        &#xA;          &#xA;                      Empty = 0b00,&#xA;        &#xA;        &#xA;          &#xA;                      Error = 0b01,&#xA;        &#xA;        &#xA;          &#xA;                      Loading = 0b10,&#xA;        &#xA;        &#xA;          &#xA;                      Value = 0b11,&#xA;        &#xA;        &#xA;          &#xA;                  },&#xA;        &#xA;        &#xA;          &#xA;                  version: u16,&#xA;        &#xA;        &#xA;          &#xA;                  references: u20,&#xA;        &#xA;        &#xA;          &#xA;                  offsetInPages: u26,&#xA;        &#xA;        &#xA;          &#xA;              },&#xA;        &#xA;        &#xA;          &#xA;              raw: u64,&#xA;        &#xA;        &#xA;          &#xA;              half: u32,&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              comptime {&#xA;        &#xA;        &#xA;          &#xA;                  if (@sizeOf(ChunkMetadata) != @sizeOf(u64)) {&#xA;        &#xA;        &#xA;          &#xA;                      @compileError(&quot;ChunkMetadata must be 64 bits in size! was &quot; &#x2B; @sizeOf(ChunkMetadata));&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn get(self: *ChunkMetadata, base: usize) !?*u8 {&#xA;        &#xA;        &#xA;          &#xA;                  while (true) {&#xA;        &#xA;        &#xA;          &#xA;                      var cur = self;&#xA;        &#xA;        &#xA;          &#xA;                      switch (cur.v.tag) {&#xA;        &#xA;        &#xA;          &#xA;                          .Empty =&gt; return null,&#xA;        &#xA;        &#xA;          &#xA;                          .Error =&gt; return @intToError(@intCast(u16, cur.v.offsetInPages)),&#xA;        &#xA;        &#xA;          &#xA;                          .Loading =&gt; return error.ValueIsLoading,&#xA;        &#xA;        &#xA;          &#xA;                          .Value =&gt; {},&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      if (cur.v.offsetInPages == 0) {&#xA;        &#xA;        &#xA;          &#xA;                          return error.ValueIsInvalid;&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      var val = @intToPtr(*u8, @intCast(u64, cur.v.offsetInPages) * std.mem.page_size &#x2B; base);&#xA;        &#xA;        &#xA;          &#xA;                      var updated = cur;&#xA;        &#xA;        &#xA;          &#xA;                      if (updated.v.references == std.math.maxInt(@TypeOf(updated.v.references))) {&#xA;        &#xA;        &#xA;          &#xA;                          // more than 255K concurrent references is unlikley&#xA;        &#xA;        &#xA;          &#xA;                          return error.ChunkReferencesOverflow;&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.references &#x2B;= 1;&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.version &#x2B;%= 1;&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      var result = @cmpxchgWeak(u64, &amp;self.raw, cur.raw, updated.raw, .Monotonic, .Monotonic);&#xA;        &#xA;        &#xA;          &#xA;                      if (result == null)&#xA;        &#xA;        &#xA;          &#xA;                          return val; // successfully incremented the ref count&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn trySetError(self: *ChunkMetadata, err: anyerror) !void {&#xA;        &#xA;        &#xA;          &#xA;                  return trySet(self, null, err);&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub const PtrWithBase = struct { ptr: *u8, base: usize };&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn trySetValue(self: *ChunkMetadata, value: PtrWithBase) !void {&#xA;        &#xA;        &#xA;          &#xA;                  return trySet(self, &amp;value, null);&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn tryLoading(self: *ChunkMetadata) !void {&#xA;        &#xA;        &#xA;          &#xA;                  return trySet(self, null, null);&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              fn trySet(self: *ChunkMetadata, value: ?*const PtrWithBase, err: ?anyerror) !void {&#xA;        &#xA;        &#xA;          &#xA;                  while (true) {&#xA;        &#xA;        &#xA;          &#xA;                      var cur = self;&#xA;        &#xA;        &#xA;          &#xA;                      switch (cur.v.tag) {&#xA;        &#xA;        &#xA;          &#xA;                          .Error =&gt; return @intToError(@intCast(u16, cur.v.offsetInPages)),&#xA;        &#xA;        &#xA;          &#xA;                          .Value =&gt; return error.ValueIsAlreadySet,&#xA;        &#xA;        &#xA;          &#xA;                          .Loading =&gt; {&#xA;        &#xA;        &#xA;          &#xA;                              if (value == null and err == null) {&#xA;        &#xA;        &#xA;          &#xA;                                  return error.ValueIsAlreadyLoading;&#xA;        &#xA;        &#xA;          &#xA;                              }&#xA;        &#xA;        &#xA;          &#xA;                          },&#xA;        &#xA;        &#xA;          &#xA;                          .Empty =&gt; {},&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      var updated = cur;&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.references = 1;&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.version &#x2B;%= 1;&#xA;        &#xA;        &#xA;          &#xA;                      if (value) |val| {&#xA;        &#xA;        &#xA;          &#xA;                          updated.v.tag = .Value;&#xA;        &#xA;        &#xA;          &#xA;                          var v = (@ptrToInt(val.ptr) - val.base) / std.mem.page_size;&#xA;        &#xA;        &#xA;          &#xA;                          if ((try std.math.mod(usize, @ptrToInt(val.ptr), std.mem.page_size)) != 0) {&#xA;        &#xA;        &#xA;          &#xA;                              return error.ValuePtrMustBePageAligned;&#xA;        &#xA;        &#xA;          &#xA;                          }&#xA;        &#xA;        &#xA;          &#xA;                          if (v == 0) {&#xA;        &#xA;        &#xA;          &#xA;                              return error.ValuePtrCannotBeNullOrSamePageAsBase;&#xA;        &#xA;        &#xA;          &#xA;                          }&#xA;        &#xA;        &#xA;          &#xA;                          if (v &gt; std.math.maxInt(@TypeOf(updated.v.offsetInPages))) {&#xA;        &#xA;        &#xA;          &#xA;                              return error.ValuePtrIsTooFarFromBase;&#xA;        &#xA;        &#xA;          &#xA;                          }&#xA;        &#xA;        &#xA;          &#xA;                          updated.v.offsetInPages = @intCast(@TypeOf(updated.v.offsetInPages), v);&#xA;        &#xA;        &#xA;          &#xA;                      } else if (err) |e| {&#xA;        &#xA;        &#xA;          &#xA;                          updated.v.tag = .Error;&#xA;        &#xA;        &#xA;          &#xA;                          updated.v.offsetInPages = @errorToInt(e);&#xA;        &#xA;        &#xA;          &#xA;                      } else {&#xA;        &#xA;        &#xA;          &#xA;                          updated.v.tag = .Loading;&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      var result = @cmpxchgWeak(u64, &amp;self.raw, cur.raw, updated.raw, .Monotonic, .Monotonic);&#xA;        &#xA;        &#xA;          &#xA;                      if (result == null) {&#xA;        &#xA;        &#xA;          &#xA;                          std.Thread.Futex.wake(self.futexPtr(), std.math.maxInt(u32));&#xA;        &#xA;        &#xA;          &#xA;                          return;&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn release(self: *ChunkMetadata) void {&#xA;        &#xA;        &#xA;          &#xA;                  while (true) {&#xA;        &#xA;        &#xA;          &#xA;                      var cur = self;&#xA;        &#xA;        &#xA;          &#xA;                      var updated = cur;&#xA;        &#xA;        &#xA;          &#xA;                      if (updated.v.tag != .Value) {&#xA;        &#xA;        &#xA;          &#xA;                          @panic(&quot;Attempted to release a chunk whose tag isn&#x27;t set to Value.&quot;);&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                      if (updated.v.references == 0) {&#xA;        &#xA;        &#xA;          &#xA;                          @panic(&quot;Attempted to release the chunk more times than you got it&quot;);&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.references -= 1;&#xA;        &#xA;        &#xA;          &#xA;                      updated.v.version &#x2B;%= 1;&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;                      var result = @cmpxchgWeak(u64, &amp;self.raw, cur.raw, update.raw, .Monotonic, .Monotonic);&#xA;        &#xA;        &#xA;          &#xA;                      if (result == null) {&#xA;        &#xA;        &#xA;          &#xA;                          return;&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn waitForValue(self: *ChunkMetadata, base: usize, timeout: ?u64) !?*u8 {&#xA;        &#xA;        &#xA;          &#xA;                  while (true) {&#xA;        &#xA;        &#xA;          &#xA;                      var cur = self;&#xA;        &#xA;        &#xA;          &#xA;                      if (cur.v.tag != .Loading) {&#xA;        &#xA;        &#xA;          &#xA;                          return try self.get(base);&#xA;        &#xA;        &#xA;          &#xA;                      }&#xA;        &#xA;        &#xA;          &#xA;                      try std.Thread.Futex.wait(self.futexPtr(), cur.half, timeout);&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              fn futexPtr(self: *ChunkMetadata) *std.atomic.Atomic(u32) {&#xA;        &#xA;        &#xA;          &#xA;                  // this covers the tag, version &amp; some of the references fields&#xA;        &#xA;        &#xA;          &#xA;                  // given that the version field always changing, it is a good futex value&#xA;        &#xA;        &#xA;          &#xA;                  return @ptrCast(*std.atomic.Atomic(u32), &amp;self.half);&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          };&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          metadata.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;The ChunkMetadata can be in one of four states:&#xA;&#xA;Empty &#x2013; there is no value&#xA;Error &#x2013; we tried to load the chunk, but failed for some reason. In that case, the actual error code is stored in offsetInPages.&#xA;Loading &#x2013; we are currently loading the chunk, and callers can decide to wait for this or try again later.&#xA;Value &#x2013; there is a value in the chunk and it is available immediately.&#xA;&#xA;When we get() a value we check what the current state of the metadata is and in all but the Value case we&#x2019;ll return immediately. If there is a value, we can&#x2019;t just return it to the caller. We need to increment the reference count. That is most of the code in the get() method. We increment the references, do a wrapping increment for the version (so each change will be unique) and then use an atomic operation to update the value. The idea is that two concurrent threads getting the value at the same time will always increment or decrement the references properly. That will be quite important later on.&#xA;After you are done with the chunk, you can release() it, which will decrement the reference count. Note that reference count of 0 is wrong, we aren&#x2019;t handling actual releasing of values yet. That will come in another post.&#xA;The trySet() function is responsible for the other side, it will set the value or the error, taking care of the concurrency aspects of the ChunkMetadata. Of particular interest here, however, is the Futex.wake() call. That deserves some detail.&#xA;Consider the sequence of events for accessing a chunk. We may have two threads that try to get a chunk, but they find that it is not resident in memory. It needs to be loaded, but we don&#x2019;t want both threads to do so at once. Therefore, the threads will compete on moving the chunk from the Empty state to the Loading state. After which, the thread that won the race will need to schedule the actual I/O. What does the other thread do in the meantime? It needs to wait until the I/O is completed. This is done using the waitForValue() method, where we interpret the first half of the chunk metadata (the one holding the version field) as a Futex.wait&#xA0; value. In other words, the thread will sleep until the trySet() call will wake it.&#xA;That is enough talking about the ChunkMetadata, I think. We went over that in detail, for my next post, I want to talk about how we deal with what is likely to be the most interesting bit of the file pager, managing the actual chunks.</p>
        </article>
        <article id="article-856">
            <a href="https://ayende.com/blog/195713-B/implementing-a-file-pager-in-zig-overall-design" target="_blank">
                <h2 class="title mb-6" id="article-856">Implementing a file pager in Zig</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 27, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In the previous post, I showed how we can get a pretty nice pager (important for building a storage system) in under 100 lines of code using mmap(). If that was all of it, it would be a pretty short series of posts. However, I want to explore what it would take to take ownership of that part of the storage system and build our own from scratch. Let&#x2019;s see what it would take to build a pager when we are doing the I/O.&#xA;In the mmap() implementation, I didn&#x2019;t really have a lot of states. Just the mapping and that was pretty much it. When building our own, we need to track a whole lot more states. Off the top of my head, we need to:&#xA;&#xA;Track what pages we handed out to callers.&#xA;Track usage of pages so we&#x2019;ll know when to release them.&#xA;Manage concurrency explicitly between threads.&#xA;Handle several scenarios that were just&#x2026; working on the mmap() implementation.&#xA;&#xA;For example, let&#x2019;s talk about what kind of state I need. Zig comes with a hash table (and does that beautifully for an unmanaged language), so I can do this, right?&#xA;&#xA;pages: std.AutoHashMap(u64, Page),&#xA;&#xA;That would be a mapping between the pages in memory and the memory we allocated for them. Except&#x2026; that it doesn&#x2019;t quite work like that. One of the key issues that we have to deal with is the fact that while most of the time we will ask for a page, we can also ask for a continuous run of pages.&#xA;We can safely assume that the caller is responsible for ensuring that there is no duplication. In other words, the following sequence of calls is invalid:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          var p1 = try pager.tryGet(5, 4); // get 4 pages, from the 5th page (32KB)&#xA;        &#xA;        &#xA;          &#xA;          var p2 = try pager.tryGet(6, 1); // get the 6th page, overlapping with p1&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          invalid.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;That is a very important limit to how much complexity we have to deal with, I have to note. Another thing to deal with is concurrency. How do we deal with scenarios where two threads want to get pages (which may or may not be the same)?&#xA;Anther consideration is about reduce the overall cost of I/O, we don&#x2019;t want to issue too many operations, both for reads and for writes. That pushes us toward batching operations as much as possible. Here is the overall design that I have for the file pager:&#xA;&#xA;&#xA;&#xA;In other words, even though we are dealing with 8KB pages, the pager itself will issue work with chunks of 2MB in size each time. The idea is that we can&#xA0; amortize the cost of going to the disk by ensuring that we&#x2019;ll do bulk I/O. That, in turn, means that we have to consider some aspects of our system very early on.&#xA;In the case of the mmap pager, we didn&#x2019;t really need to think about caching, that was the responsibility of the operating system. In the case of this pager, we must&#xA0;have a cache, and if we cache a chunk, we can probably benefit greatly from locality of reference, which is always nice.&#xA;The 2MB chunk size design decision complicate our lives. The pager needs to handle both single pages access and work with values that may span multiple pages. As long as they reside in a single chunk, that is pretty easy. But we need to consider how we&#x2019;ll manage to work with values that are bigger than 2MB in size. It&#x2019;s interesting, because even at this very early stage, a design decision on how big the size we fetch from the disk will have impact for the implementation of the entire system.&#xA;As early as we are, we can make the following assumption / requirements from our callers:&#xA;&#xA;Most of the access is going to be for single pages.&#xA;Some of the accesses will be for multiple pages, but under the 2 MB chunk limit.&#xA;Few accesses will need to work with multiple pages over the 2 MB limit.&#xA;&#xA;That is important because it impacts the way we think about the system. Earlier in this post, I mentioned using a hash map to store the references to the pages. With chunks, we can probably adjust slightly and be done with it, right?&#xA;Except that we really can&#x2019;t. One of the primary issues that we have to deal with is the fact that this is meant to be concurrent. A hash map isn&#x2019;t going to support that and will need to be protected by a lock. Interestingly, most concurrent data structures pretty much require garbage collection of some sort and building them with an unmanaged system is quite complex.&#xA;How do we deal with this issue? It turns out that it is far simpler to have an array to hold those references and access each element using atomic instructions. Here we run into another design decision. Are we going to have a single file or multiple files? That matters because if we have a single file, we need to deal with increasing the file size on the fly. That means that the array of references would need to grow, and that is also complex with concurrent access. If we have multiple files, we can just create a completely new file as needed. We can allocate a single array at the maximum file size and not worry about it. There are other reasons why we might want to use multiple files (such as making it easier to release space back to the file system), so we&#x2019;ll go with multiple files.&#xA;That means that we can reasonably set the maximum file size at 8GB (remember the big values issue, I think it is reasonable to set the max size of a value at 2GB, so 8GB is plenty). With 8GB files, we are talking about 4,096 chunks of 2 MB each. Assuming that we&#x2019;ll use an 8 bytes struct to hold the data about each chunk, that means that we can safely allocate the maximum size of 32Kb upfront. If we need to increase the size of the file, we already allocated the place for its metadata. That gives us a far simpler system (no need to try to manage concurrent accesses) at a small memory cost.&#xA;Now, we can require that page allocations that are below 2 MB in size will always be aligned inside a page boundary. But what happens when we have a value whose size exceeds 2MB? The answer to that is that we are going to require the calling code to follow specific patterns for that. We require that any value that is greater than 2MB will be aligned on a 2MB boundary from the end of the final chunk. Here is what this looks like, the yellow marked pages are allocated on two separate chunks, and you can see how we aligned this on the end:&#xA;&#xA;The nice thing about this approach is that we know that the caller will not do partial calls. If we asked for pages 5 - 10, there can be no call to page 6 on an independent basis. As such, when we ask for a value that is bigger than a single chunk, it will always be expressed as a load from the starting chunk to the end. That means that we can load the full value in a single I/O call.&#xA0; Here, again, we have very low level concerns affecting how we lay out the data on disk.&#xA;There are other aspects that we need to consider, such as eviction policies, how to handle concurrency, etc. But that is enough for one post, I intentionally want to limit the scope of what we do to avoid getting mired in the details. Expect more in the next post in the series.</p>
        </article>
        <article id="article-857">
            <a href="https://ayende.com/blog/195588-B/implementing-a-file-pager-in-zig-using-mmap" target="_blank">
                <h2 class="title mb-6" id="article-857">Implementing a file pager in Zig</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 24, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Now that we know what we want to implement, let&#x2019;s dig a bit deeper and see how to do it. An interesting way to implement a file pager is to&#x2026; not do that. Instead, we can rely on the OS&#x2019; memory mapping to do most of the heavy lifting. Let&#x2019;s see how we can do that.&#xA;The first thing that we need to manage is the setup and teardown of the pager, which you can see here:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub const MmapPager = struct {&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub const PageSize = 8 * 1024;&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              ptr: []align(std.mem.page_size) u8,&#xA;        &#xA;        &#xA;          &#xA;              len: u64,&#xA;        &#xA;        &#xA;          &#xA;              allocator: *std.mem.Allocator,&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              &#xA;        &#xA;        &#xA;          &#xA;              pub fn init(fd: std.os.fd_t, allocator: *std.mem.Allocator) !MmapPager {&#xA;        &#xA;        &#xA;          &#xA;                  var stats = try std.os.fstat(fd);&#xA;        &#xA;        &#xA;          &#xA;                  var ptr = try std.os.mmap(&#xA;        &#xA;        &#xA;          &#xA;                      null,&#xA;        &#xA;        &#xA;          &#xA;                      @intCast(usize, stats.size),&#xA;        &#xA;        &#xA;          &#xA;                      std.os.PROT_READ | std.os.PROT_WRITE,&#xA;        &#xA;        &#xA;          &#xA;                      std.os.MAP_SHARED,&#xA;        &#xA;        &#xA;          &#xA;                      fd,&#xA;        &#xA;        &#xA;          &#xA;                      0,&#xA;        &#xA;        &#xA;          &#xA;                  );&#xA;        &#xA;        &#xA;          &#xA;                  return MmapPager{&#xA;        &#xA;        &#xA;          &#xA;                      .ptr = ptr,&#xA;        &#xA;        &#xA;          &#xA;                      .len = @intCast(u64, stats.size),&#xA;        &#xA;        &#xA;          &#xA;                      .allocator = allocator,&#xA;        &#xA;        &#xA;          &#xA;                  };&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              pub fn deinit(self: *MmapPager) void {&#xA;        &#xA;        &#xA;          &#xA;                  std.os.munmap(self.ptr);&#xA;        &#xA;        &#xA;          &#xA;                  self.ptr = undefined;&#xA;        &#xA;        &#xA;          &#xA;                  self.len = 0;&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          };&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          init.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;There isn&#x2019;t much here, we simply call mmap() and that is about&#x2026; it. Let&#x2019;s see how we can implement the actual pager behavior. We&#x2019;ll start with the easy pieces here getting and releasing the memory from the pager:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub fn getBlocking(self: *MmapPager, page: u64, count: u32) !Page {&#xA;        &#xA;        &#xA;          &#xA;              return Page{&#xA;        &#xA;        &#xA;          &#xA;                  .buffer = self.ptr[page * PageSize .. (page * PageSize &#x2B; count * PageSize)],&#xA;        &#xA;        &#xA;          &#xA;                  .numberOfPages = count,&#xA;        &#xA;        &#xA;          &#xA;                  .page = page,&#xA;        &#xA;        &#xA;          &#xA;              };&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;        &#xA;          &#xA;          pub fn release(self: *MmapPager, page: Page) void {&#xA;        &#xA;        &#xA;          &#xA;              _ = self;&#xA;        &#xA;        &#xA;          &#xA;              // we don&#x27;t need to actually release anything here&#xA;        &#xA;        &#xA;          &#xA;              page.buffer = undefined;&#xA;        &#xA;        &#xA;          &#xA;              page.numberOfPages = undefined;&#xA;        &#xA;        &#xA;          &#xA;              page.page = undefined;&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          get_release.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;You&#x2019;ll notice that we don&#x2019;t actually have anything here? Even the act of checking that the page is within the bound of the mapped memory is done by slicing the ptr directly. What about the blocking part? How do we actually move the data to memory? The answer is that we aren&#x2019;t. When you access the pointer we return from the get(), we&#x2019;ll just get a page fault and the OS will read the data from the disk.&#xA0; The release() function also doesn&#x2019;t need to do much, all the behavior is inside the mmap() implementation, after all.&#xA;A bit more complex is the part where we try to get the pages from the disk, here is the tryGet() implementation:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub fn tryGet(self: *MmapPager, page: u64, count: u32) !?Page {&#xA;        &#xA;        &#xA;          &#xA;              const buf = try self.allocator.alloc(u8, count);&#xA;        &#xA;        &#xA;          &#xA;              defer self.allocator.free(buf);&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              std.mem.set(u8, buf, 0);&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              const start = self.ptr[page * PageSize ..];&#xA;        &#xA;        &#xA;          &#xA;              const size = count * PageSize;&#xA;        &#xA;        &#xA;          &#xA;              const rc = c.mincore(&amp;start[0], size, &amp;buf[0]);&#xA;        &#xA;        &#xA;          &#xA;              if (rc != 0) {&#xA;        &#xA;        &#xA;          &#xA;                  return @intToError(@intCast(u16, std.os.errno(rc)));&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              for (buf) |b| {&#xA;        &#xA;        &#xA;          &#xA;                  if (b &amp; 1 == 0) {&#xA;        &#xA;        &#xA;          &#xA;                      try std.os.madvise(@ptrCast([*]u8, start), size, std.os.MADV_WILLNEED);&#xA;        &#xA;        &#xA;          &#xA;                      return null; // not all in memory&#xA;        &#xA;        &#xA;          &#xA;                  }&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;              // can return to the caller immediately&#xA;        &#xA;        &#xA;          &#xA;              return try getBlocing(self, page, count);&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          tryGet.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;That is quite a bit of code for not much in practice. We create a temporary array and then call mincore() on the range of memory that we&#x2019;ll return. If the entire range is not already in memory, we&#x2019;ll call madvice() to load it in the background and return null. If the range is already in memory, just return it.&#xA;This isn&#x2019;t 100% safe to do, by the way, there may be race conditions that would cause us to think that the data is in memory just as it is swapped to disk, but that is good enough for our needs. Especially because the whole thing is quite simple overall.&#xA;The next stage is to handle writes and syncing to disk. This is simplicity itself, in this model.&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub fn write(self: *MmapPager, page: Page) !void {&#xA;        &#xA;        &#xA;          &#xA;              // nothing to do, the data is already written to&#xA;        &#xA;        &#xA;          &#xA;              // the memory map&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;        &#xA;          &#xA;          pub fn sync(self: *MmapPager) !void {&#xA;        &#xA;        &#xA;          &#xA;              if (c.msync(&amp;self.ptr[0], self.ptr.len, c.MS_SYNC) != 0) {&#xA;        &#xA;        &#xA;          &#xA;                  return @intToError(@intCast(u16, std.os.errno(rc)));&#xA;        &#xA;        &#xA;          &#xA;              }&#xA;        &#xA;        &#xA;          &#xA;          }&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          write_sync.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;Since we handed out a buffer from the memory map itself, we don&#x2019;t need to do any copying, we already modified that range of memory. And when we sync to the file, we can do that by a single msync() call. There are a few things to note here, though:&#xA;&#xA;Because we are writing directly to the memory mapped file, it is possible that our changes will show up in the file before write and sync are called.&#xA;The msync() will sync the entire range, if we have smaller changes that we made, we can try to reduce the amount of memory that is synced by remembering what parts we have written to, but it ends up being quite a chore. And since the OS is already doing that for us, we can shell that to it directly.&#xA;&#xA;And that is pretty much it. The whole pager is under 100 lines of code.&#xA;There are some things that I don&#x2019;t handle, such as what happens if we want to extend the size of the file. That requires us to re-wire the mapping, if we are going by the strict reading of the API. But in both Linux &amp; Windows, you can define a memory mapping that is greater than the file and that will automatically adjust as you grow the file. That is quite a nice feature for us and can save us a lot of management overhead internally.&#xA;With that out of the way, we can start implementing higher level functions in a storage system. But notice how we moved pretty much everything to the OS? What would it look like if we wanted to build that ourselves?</p>
        </article>
        <article id="article-858">
            <a href="https://ayende.com/blog/195587-B/implementing-a-file-pager-in-zig-what-do-we-need" target="_blank">
                <h2 class="title mb-6" id="article-858">Implementing a file pager in Zig</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 23, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">A file pager is a component in database systems that is responsible for reading and writing pages (typically 8KB blocks) from the file system. The pager is responsible for the I/O operations and is crucial for the overall performance of the system. Ideally, it should manage details such as caching pages in memory, reduce I/O costs and continuously optimize the overall behavior of the storage.&#xA;That can be a pretty big chunk of&#xA0; a storage system, and it can have a significant impact on the way the storage system behaves. Here is the most basic version that I can think of:&#xA;&#xA;&#xA;    &#xA;      &#xA;        &#xA;  &#xA;    &#xA;    &#xA;&#xA;        &#xA;&#xA;&#xA;  &#xA;  &#xA;  &#xA;    &#xA;&#xA;    &#xA;      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.&#xA;      Learn more about bidirectional Unicode characters&#xA;    &#xA;&#xA;&#xA;              Show hidden characters&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;    &#xA;    &#xA;&#xA;&#xA;&#xA;  &#xA;        &#xA;          &#xA;          pub const Page = struct {&#xA;        &#xA;        &#xA;          &#xA;              page: u64,&#xA;        &#xA;        &#xA;          &#xA;              numberOfPages: u32,&#xA;        &#xA;        &#xA;          &#xA;              buffer: []u8,&#xA;        &#xA;        &#xA;          &#xA;          };&#xA;        &#xA;        &#xA;          &#xA;          &#xA;&#xA;        &#xA;        &#xA;          &#xA;          pub const Pager = struct {&#xA;        &#xA;        &#xA;          &#xA;              pub fn tryGet(self: *Pager, page: u64, count: u32) !?Page {}&#xA;        &#xA;        &#xA;          &#xA;              pub fn getBlocking(self: *Pager, page: u64, count: u32) !Page {}&#xA;        &#xA;        &#xA;          &#xA;              pub fn release(self: *Pager, page: Page) void {}&#xA;        &#xA;        &#xA;          &#xA;              pub fn write(self: *Pager, page: Page) !void {}&#xA;        &#xA;        &#xA;          &#xA;              pub fn sync(self: *Pager) !void {}&#xA;        &#xA;        &#xA;          &#xA;          };&#xA;        &#xA;  &#xA;&#xA;&#xA;&#xA;    &#xA;&#xA;  &#xA;&#xA;&#xA;      &#xA;      &#xA;        view raw&#xA;        &#xA;          Pager.zig&#xA;        &#xA;        hosted with &#x2764; by GitHub&#xA;      &#xA;    &#xA;&#xA;&#xA;&#xA;The idea is that whenever you need a particular page, you&#x2019;ll call it using tryGet() which will return the document if it is already in memory, but it will not block. You can call getBlocking() to force the current thread to wait for the page to be in memory. That allows the calling code to perform some really nice optimizations.&#xA;Once we got the page, the Pager is charged with keeping it in memory until we will release it. Note that I&#x2019;m talking about a Page, but that might actually contain multiple sequential pages. The release() call tells the Pager that the memory is no longer in active use, the Pager may decide to do something about that.&#xA;Finally, we have the write() method, which will write the data from the in-memory page to storage, and the sync() method, which will ensure that all previous writes are durable to disk.&#xA;There aren&#x2019;t that many moving pieces, right? Not in particular that we don&#x2019;t have the notion of transactions here, this is lower level than that. This API has the following properties:&#xA;&#xA;The same page will always be represented in memory by the same location. However, if we release and get the page again, it may move.&#xA;The methods tryGet(), getBlocking() and release() have no locking or threading limits. You may call them in any context and the Pager will deal with any concurrency internally.&#xA;The write() and sync() calls, on the other hand, require synchronization by the client. There can be no concurrency between the two.&#xA;&#xA;With that in place, we can build quite a sophisticated storage system. But we&#x2019;ll focus on how the pager works for now.&#xA;There are a bunch of ways to implement this, so I&#x2019;ll have at least a couple of posts on the topic. How would you approach implementing this?</p>
        </article>
        <article id="article-859">
            <a href="https://ayende.com/blog/195778-C/optimizing-local-and-distributed-transactions-with-batching" target="_blank">
                <h2 class="title mb-6" id="article-859">Optimizing local and distributed transactions with batching</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 22, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I got into a&#xA0;good discussion about how RavenDB implements some optimizations with transaction handling. The details got big enough (and hopefully interesting enough) that they warrant their own post.&#xA;When we are talking about transactions, one of the key factors in the cost of a transaction is the amount of time that it takes to persist that. This is different for local and distributed transactions.&#xA;For a local transaction, we can consider the transaction committed if it is durably stored on the disk.&#xA;For a distributed transaction, we can consider the transaction committed if it is durably stored on a majority of the disks in the cluster.&#xA;That factor right there is the primary reason why a distributed transaction is more expensive. For a local transaction, you are waiting for the disk. For a distributed transaction, you are waiting for multiple disks and the network.&#xA;One of the core optimizations for speeding up transactions is the ability to batch things. The cost of writing to the disk is more or less the same, regardless of how much you write (within an order of magnitude or so). In other words, writing 8 KB and writing 32 KB has pretty much the same cost. Writing 1 MB and writing 100 MB does not, but writing 1 MB vs 4 MB isn&#x2019;t meaningfully different (sequential durable write, which is what we care for in the case of transactions).&#xA;The point of this post is how this is actually handled. RavenDB utilizes a process called transaction merging to reduce the number of times that we have to go to the disk. Concurrent transactions will be bundled into the same write call, massively increasing our throughput. To give you some context, without transaction merging, you can peak at a few hundreds transactions per second. With transaction merging, you can jump to high thousands of transactions per second. Here is how this works:&#xA;&#xA;RavenDB actually takes this further, in addition to transaction merging, we also apply something we call async commit. Take a look at the following timeline:&#xA;&#xA;A transaction is actually composed of two separate steps. First we need to execute whatever commands we have in the transaction, then we have to write the transaction changes to disk.&#xA;RavenDB is able to start processing the next transaction as soon as the previous one started the write to the disk. The idea is to parallelize compute and I/O, and we are able to benefit greatly as a result. Note that this is safe to do, since the next transaction won&#x2019;t be committed until the prior transaction has been durably stored.&#xA;How does this work in practice? Whenever we have a new transaction, we add it to a queue. A dedicated thread will merge those transactions and pull them from the queue, running the separate transactions as one big operation. When we run out of pending transactions or hit certain size / timing limits, we&#x2019;ll commit the merged transaction and start working on the next one while the commit is completing in the background.&#xA;There are certain algorithms that try to maximize throughput, such as Nagle. They do that by waiting for additional transactions to arrive before actually going to the disk. RavenDB doesn&#x2019;t use that approach. If a system is idle and we get a single transaction, we&#x2019;ll immediately execute and commit it.&#xA;But the fact that we don&#x2019;t explicitly do Nagle doesn&#x2019;t mean that it isn&#x2019;t useful. Because we have to wait for the disk, what ends up happening is that under load, we start getting more pending transactions in the queue. Which will then be executed as a merged unit. In other words, RavenDB implements a dynamic batching approach, affected by the actual I/O constraints and the load on the system. If we have independent transactions, we&#x2019;ll execute them immediately. As the load increases, we&#x2019;ll start making more merged transactions. This way we can keep a fairly consistent response time even when the load of the system grows by leaps and bounds.&#xA;The situation is similar when we are talking about distributed transactions. RavenDB uses the Raft protocol for managing its distributed behavior. I&#x2019;m going to focus just on the batching aspect of the behavior. RavenDB will send an AppendEntries message to the other members in the cluster every 200 ms or so. However, if we have a new command to send to the cluster, it will go out immediately over the network. An&#xA0; important factor here is that we are using TCP, and we require acknowledgment from the other side before we send the next message. As a result of those behaviors, we have pretty much the same situation. Depending on the network latency and the processing time, we&#x2019;ll send more entries in a single roundtrip.&#xA;In short, the overall behavior for RavenDB is that we&#x2019;ll start the operation immediately on the first action (both for disk and network), and then we&#x2019;ll batch anything that happens while the first operation is in flight and send that as a result.&#xA;After over a decade of working in this manner, I can tell that this has proven to be a highly adaptable system that results in the minimum number of knobs to mess with. It favors latency over throughput when there isn&#x2019;t a lot of activity and shifts toward favoring throughput over latency as the load grows.</p>
        </article>
        <article id="article-860">
            <a href="https://ayende.com/blog/195841-B/work-well-under-pressure-is-a-safety-valve-not-sop" target="_blank">
                <h2 class="title mb-6" id="article-860">&#x201C;Work well under pressure&#x201D; is a safety valve, not SOP</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 21, 2021
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The phrase &#x201C;work well under pressure&#x201D; is something that I consider to be a red flag in a professional environment. My company builds a database that is used as the backend of business critical systems. If something breaks, there is a need to fix it. It costs money (sometimes a lot of money) for every minute of downtime.&#xA;Under such a scenario, I absolutely want the people handling the issue to remain calm, collected and analytical. In such a case, being able to work well under pressure is a huge benefit.&#xA;That is not how this term is typically used, however. The typical manner you&#x2019;ll hear this phrase is to refer to the usual working environment. For example, working under time pressure to deliver certain functionality. That sort of pressure is toxic over time.&#xA;Excess stress is a well known contributor to health issues (mental and physical ones), it will cause you to make mistakes and it adds frictions all around.&#xA;From my perspective, the ability to work well under pressure is an absolutely important quality, which should be hoarded. You may need to utilize this ability in order to deal with a blocking customer issue, but should be careful not to spend that on non-critical stuff.&#xA;And by definition, most things are not critical. If everything is critical, you have a different problem.&#xA;That means that part of the task of the manager is to identify the places where pressure is applied and remove that. In the context of software, that may be delaying a release date or removing features to reduce the amount of work.&#xA;When working with technology, the most valuable asset you have is the people and the knowledge they have. And one of the easiest ways to lose that is to burn the candle at both ends. You get more light, sure, but you also get no candle.</p>
        </article>
        <div class="button flex justify-between">
            <a href="85.html"><span class="back arrow"></span></a>

            <a href="87.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>
</body>
</html>