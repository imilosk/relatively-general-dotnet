
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 403 â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="pagefind/pagefind-ui.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-4021">
            <a href="https://ayende.com/blog/163393/the-storage-wars-shadow-paging-log-structured-merge-and-write-ahead-logging" target="_blank">
                <h2 class="title mb-6" id="article-4021">The storage wars: Shadow Paging, Log Structured Merge and Write Ahead Logging</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 13, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I&#x2019;ve been doing a lot of research lately on storage. And in general, it seems that the most popular ways of writing to disk today are divide into the following categories.  Write Ahead Logging (WAL)&#x2013;&#xA0; Many databases use some sort of variant on that.&#xA0; PostgreSQL, SQLite, MongoDB, SQL Server, etc. Oracle has Redo Log, which seems similar, but I didn&#x2019;t check too deeply. Log Structured Merge&#xA0; (LSM)&#x2013; a lot of NoSQL databases use this method. Cassandra, Riak, LevelDB, SQLite 4, etc. Shadow Paging &#x2013; was quite popular a long time ago (80s), but still somewhat in use. LMDB, Tokyo Cabinet, CoucbDB (sort of). WAL came into being for a very simple reason, it is drastically faster to write sequentially than it is to do random writes. Let us assume that you store the data on disk using some sort of a tree, when you need to insert / update something in that tree, the record can be anywhere. That means that you would need to do random writes, and have to suffer the perf issues associated with that. Instead, you can write to the log and have some sort of a background process that would update the on disk data.  It also means that you really only have to update in memory data, flush the log and you are safe. The recovery procedure is going to be pretty complex, but it gives you some nice performance. Note that you write everything at least twice, once for the log, and once for the read data file. The log writes are sequential, the data writes are random. LSM also take advantage of sequential write speeds, but it takes it even further, instead of updating the actual data, you will wait until the log gets to a certain size, at which point you are going to merge it with the current data file(s). That means that you you will usually write things multiple times, in LevelDB, for example, a lot of the effort has actually gone into eradicating this cost. The cost of compacting your data. Because what ended up happening is that you have user writes competing with the compaction writes. Shadow Paging is not actually trying to optimize sequential writes. Well, that is not really fair. Shadow Paging &amp; sequential writes are just not related. The reason I said CouchDB is sort of using shadow paging is that it is using the exact same mechanics as other shadow paging system, but it always write at the end of the file. That means that is has excellent write speed, but it also means that it needs some way to reduce space. And that means it uses compaction, which brings you right back to the competing write story. For our purposes, we will ignore the way CouchDB work and focus on systems that works like LMDB. In those sort of systems, instead of modifying the data directly, we create a shadow page (copy on write) and modify that. Because the shadow page is only wired up to the rest of the pages on commit, this is absolutely atomic. It also means that modifying a page is going to use one page, and leave another free (the old page). And that, in turn, means that you need to have some way of scavenging for free space. CouchDB does that by creating a whole new file.  LMDB does that by recording the free space and reusing that in the next transaction. That means that writes to LMDB can happen anywhere. We can apply policies on top of that to mitigate that, but that is beside the point. Let us go back to another important aspect that we have to deal with in databases. Backups. As it turn out, it is actually really simple for most LSM / WAL systems to implement that, because you can just use the logs. For LMDB, you can create a backup really easily (in fact, since we are using shadow paging, you pretty much get it for free). However, one feature that I don&#x2019;t think would be possible with LMDB would be incremental backups. WAL/LSM make it easy, just take the logs since a given point. But with LMDB style dbs, I don&#x2019;t think that this would be possible.</p>
        </article>
        <article id="article-4022">
            <a href="https://ayende.com/blog/163362/seek-and-you-shall-find-or-maybe-delay-a-lot" target="_blank">
                <h2 class="title mb-6" id="article-4022">Seek, and you shall find, or maybe delay a lot</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 12, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I have been doing a lot more analysis about the actual disk access patterns that we saw in Voron. In the beginning, I strongly suspected that the problem was with how I was using memory mapped files. In particular, some experiments with using my better knowledge of the environment has led to substantial performance gains. Instead of calling FlushViewOfFile(0, fileLen), I was able to call FlushViewOfFile on just the ranges that I knew changed. That helped, but it wasn&#x2019;t nearly enough. So I run some quick tests using file stream, and realized that the fault was obviously with the broken way Windows is using Memory Mapped files. So I decided to (no, I didn&#x2019;t write my own mmap impl, thank you very much) to take manual care of how Voron is writing to disk. I used WriteFile with all the bells and whistles, even had async I/O for a while there. I was able to directly pinpoint the exact locations where we needed to write, pass that to Windows in an efficient manner, and be done with it. It required me to write malloc implementation in managed code, but it was quite efficient looking code. And then I run it. Just to give you some perspective, the scenario under question here is 10,000 transactions doing 100 random writes each. Using the memory map approach, after the FlushViewOfFile range optimization, I got roughly 7,000 operations / second. Using my own hand written, optimized I/O, I got&#x2026; 262 operations / second. Okaaaay&#x2026; so maybe I need to go back to the drawing board. I sat down and started working on figuring out what is actually going on. I looked at the actual output that we had, in particular, how many writes did we have per transaction? I sat down to analyze what is going on. We are writing 100 records with 16 bytes key and 100 bytes value. That means that the absolute minimum amount we can write would be 11,600 bytes. However, we are writing in 4Kb pages, which bring us to 3 pages and 12,288 bytes per transaction. Of course, this ignore things like the writing of branch pages in the B&#x2B;Tree, so let us see what the real numbers are.      1: Flush     1 with  12 pages   - 48 kb writes and 1  seeks   (11 leaves, 1 branches, 0 overflows)   2: Flush     2 with  13 pages   - 52 kb writes and 1  seeks   (12 leaves, 1 branches, 0 overflows)   3: Flush     3 with  21 pages   - 84 kb writes and 1  seeks   (20 leaves, 1 branches, 0 overflows)   4:     5: Flush    27 with  76 pages   - 304 kb writes and 1 seeks  (75 leaves,  1 branches, 0 overflows)   6: Flush    28 with  73 pages   - 292 kb writes and 1 seeks  (72 leaves,  1 branches, 0 overflows)   7: Flush    29 with  84 pages   - 336 kb writes and 1 seeks  (80 leaves,  4 branches, 0 overflows)   8:&#xA0;    9: Flush 1,153 with 158 pages - 632 kb writes and 67  seeks (107 leaves, 51 branches, 0 overflows)  10: Flush 1,154 with 168 pages - 672 kb writes and 65  seeks (113 leaves, 55 branches, 0 overflows)  11: Flush 1,155 with 165 pages - 660 kb writes and 76  seeks (113 leaves, 52 branches, 0 overflows)  12:&#xA0;   13: Flush 4,441 with 199 pages - 796 kb writes and 146 seeks (111 leaves, 88 branches, 0 overflows)  14: Flush 4,442 with 198 pages - 792 kb writes and 133 seeks (113 leaves, 85 branches, 0 overflows)  15: Flush 4,443 with 196 pages - 784 kb writes and 146 seeks (109 leaves, 87 branches, 0 overflows)  16:&#xA0;   17: Flush 7,707 with 209 pages - 836 kb writes and 170 seeks (111 leaves, 98 branches, 0 overflows)  18: Flush 7,708 with 217 pages - 868 kb writes and 169 seeks (119 leaves, 98 branches, 0 overflows)  19: Flush 7,709 with 197 pages - 788 kb writes and 162 seeks (108 leaves, 89 branches, 0 overflows)  20:&#xA0;   21: Flush 9,069 with 204 pages - 816 kb writes and 170 seeks (108 leaves, 96 branches, 0 overflows)  22: Flush 9,070 with 206 pages - 824 kb writes and 166 seeks (112 leaves, 94 branches, 0 overflows)  23: Flush 9,071 with 203 pages - 812 kb writes and 169 seeks (105 leaves, 98 branches, 0 overflows)&#xA;The very first transactions are already showing something very interesting, we are actually writing 12 - 21 pages, or 48&#xA0; - 84 Kb of data, instead of 12 Kb. Why do we write 4 times as much data as we wanted?&#xA;The answer is that we are writing data that is random in nature, so it can&#x2019;t all sit in the same page, we get a lot of page splits and very quickly we end up with a lot of pages. This is pretty much inevitable, since this is how trees work. But look at what happens down the road. In particular look at lines 9 &#x2013; 10. You can see that we are now at a pretty stable state. We are writing ~160 pages per transaction. And since we write random data, we tend to touch about 100 leaf pages per transaction (the stuff after 100 is usually page splits). But something that is much more interesting can be seen in the count of seeks. &#xA;The way LMDB works, we use copy-on-write, so whenever we modify a page, we are actually modify a copy and mark the actual page as available for future transaction to re-use. This has the great advantage in that we don&#x2019;t ever need to do compaction, but it also means that when we do want to do writes, we have to make them pretty much all over place. And it actually gets worse as more times goes by.&#xA;Now, you have to realize that this is pretty much the worst case scenario, a transaction that does a lot of writes all over the place. But it means that toward the end, we are really hurting.&#xA;You already know the numbers, right? What about just straight out writing 1MB? What is the cost of seeks? I wrote the following code:&#xA;&#xA;&#xA;   1: var buffer = new byte[1024*1024];   2: var random = new Random();   3: random.NextBytes(buffer);   4: if(File.Exists(&quot;test.bin&quot;))   5:     File.Delete(&quot;test.bin&quot;);   6: using (var fs = new FileStream(&quot;test.bin&quot;, FileMode.CreateNew, FileAccess.ReadWrite))   7: {   8:     fs.SetLength(1024 * 1024 * 768);   9:     // warm up  10:     for (int i = 0; i &lt; 200; i&#x2B;&#x2B;)  11:     {  12:         fs.Position = random.Next(0, (int)fs.Length);  13:         fs.Write(buffer,0, random.Next(0, 1024));  14:     }  15:&#xA0;   16:     var sp = Stopwatch.StartNew();  17:     for (int i = 0; i &lt; 200; i&#x2B;&#x2B;)  18:     {  19:           fs.Position = random.Next(0, (int)fs.Length);  20:           fs.WriteByte(1);  21:     }  22:     fs.Flush(true);  23:     sp.Stop();  24:     Console.WriteLine(&quot;200 seeks &amp; 200 bytes {0:#,#} ms&quot;, sp.ElapsedMilliseconds);  25:&#xA0;   26:     sp = Stopwatch.StartNew();  27:     fs.Position = random.Next(0, (int)fs.Length);  28:     fs.Write(buffer, 0, buffer.Length);  29:     fs.Flush(true);  30:     sp.Stop();  31:     Console.WriteLine(&quot;1 MB write {0:#,#} ms&quot;, sp.ElapsedMilliseconds);  32: }&#xA;The results are quite interesting:&#xA;&#xA;&#xA;   1: 200 seeks &amp; 200 bytes 146 ms   2: 1 MB write 6 ms&#xA;Just to note, this is when running on SSD, the numbers are supposed to be a lot worse when running on HDD.&#xA;In other words, it ain&#x2019;t the size of the write, but how you spread it around that really matters. Just to compare, here are the numbers for when we are doing sequential writes:&#xA;&#xA;&#xA;   1: Flush      1 with   6 pages -  24 kb writes and   1 seeks (  5 leaves,   1 branches,   0 overflows)   2: Flush      2 with   6 pages -  24 kb writes and   1 seeks (  5 leaves,   1 branches,   0 overflows)   3: Flush      3 with   6 pages -  24 kb writes and   1 seeks (  5 leaves,   1 branches,   0 overflows)   4:&#xA0;    5: Flush    159 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)   6: Flush    160 with   8 pages -  32 kb writes and   3 seeks (  6 leaves,   2 branches,   0 overflows)   7: Flush    161 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)   8: Flush    162 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)   9:&#xA0;   10: Flush  1,320 with   8 pages -  32 kb writes and   3 seeks (  6 leaves,   2 branches,   0 overflows)  11: Flush  1,321 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)  12: Flush  1,322 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)  13:&#xA0;   14: Flush  4,316 with   7 pages -  28 kb writes and   3 seeks (  5 leaves,   2 branches,   0 overflows)  15: Flush  4,317 with   7 pages -  28 kb writes and   2 seeks (  5 leaves,   2 branches,   0 overflows)  16: Flush  4,318 with   8 pages -  32 kb writes and   3 seeks (  6 leaves,   2 branches,   0 overflows)  17:&#xA0;   18: Flush  7,409 with   8 pages -  32 kb writes and   4 seeks (  5 leaves,   3 branches,   0 overflows)  19: Flush  7,410 with   9 pages -  36 kb writes and   2 seeks (  6 leaves,   3 branches,   0 overflows)  20: Flush  7,411 with   8 pages -  32 kb writes and   4 seeks (  5 leaves,   3 branches,   0 overflows)  21:&#xA0;   22: Flush  9,990 with   8 pages -  32 kb writes and   3 seeks (  5 leaves,   3 branches,   0 overflows)  23: Flush  9,991 with   9 pages -  36 kb writes and   4 seeks (  6 leaves,   3 branches,   0 overflows)  24: Flush  9,992 with   8 pages -  32 kb writes and   3 seeks (  5 leaves,   3 branches,   0 overflows)  25: Flush  9,993 with   8 pages -  32 kb writes and   4 seeks (  5 leaves,   3 branches,   0 overflows)&#xA;Because we are always writing at the end, we only need to touch very few pages. Note that even with the small number of pages, we still need to do quite a bit of seeks, relative to the number of pages we write.&#xA;I have some ideas about this, but they are still unformed. Mostly we need to balance between the amount of free space that is used to the number of seeks allowed. I think we can get there by being smart about tracking the number of pages modified by a transaction, and waiting until free space become available in sufficient numbers to be relevant. Something like that would allow auto tuning of the amount of garbage we accumulate vs. the number of seeks we require.</p>
        </article>
        <article id="article-4023">
            <a href="https://ayende.com/blog/163713/ravendb-2-5-webinar-is-live-and-some-date-stuff" target="_blank">
                <h2 class="title mb-6" id="article-4023">RavenDB 2.5 Webinar is live (and some date stuff)</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 11, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Here is the recording for our RavenDB 2.5 Webinar from Monday. You can start watching it right now, or you can continue reading about the timing snafu we had below.  Basically, we run into a timing error because of daylight savings. Unlike the common error, where we forgot to account for daylight savings taking effect, here we forgot to take into account daylight saving not coming into effect. For a lot of really reasons, daylight savings in Israel is a contentious issue, involving the cross roads of politics, religion and whole bunch of other stuff. As a result, until recently we didn&#x2019;t have a fixed date for daylight saving changes. A few years ago it changed, and that date was supposed to be last week. Then politics happened, and the date moved. We didn&#x2019;t account for a lot of software still thinking that the daylight savings time actually happening on time, and that meant that we actually had the webinar an hour early. I apologize for the mistake, and hopefully you&#x2019;ll still enjoy the recording.</p>
        </article>
        <article id="article-4024">
            <a href="https://ayende.com/blog/163330/degenerate-performance-scenario-for-lmdb" target="_blank">
                <h2 class="title mb-6" id="article-4024">Degenerate performance scenario for LMDB</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 11, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I am working peacefully through some stuff with Voron, when I run into some really bad performance in a pretty important scenario. I decided that this is probably something that I am doing wrong, and set out to reproduce the same scenario in LMDB, to figure out what I am doing wrong. Here it the code: int main(int argc,char * argv[])&#xA;{&#xA;    int i = 0, j = 0, rc;&#xA;    UUID id;&#xA;    MDB_env *env;&#xA;&#xA;    MDB_val key, data;&#xA;&#xA;    MDB_stat mst;&#xA;    MDB_cursor *cursor;&#xA;    char sval[32];&#xA;    clock_t start = clock(), end;&#xA;&#xA;    srandom(time(NULL));&#xA;&#xA;    rc = mdb_env_create(&amp;env);&#xA;    rc = mdb_env_set_mapsize(env, 1024*1024*768);    rc = mdb_env_set_flags(env, MDB_WRITEMAP, 1); &#xA;    rc = mdb_env_open(env, &quot;E:\\data\\lmdb2&quot;, 0, 0664);&#xA;&#xA;    key.mv_size = sizeof(UUID);&#xA;    data.mv_size = sizeof(sval);&#xA;    data.mv_data = sval;&#xA;    &#xA;    for (i=0;i&lt;100;i&#x2B;&#x2B;) {    &#xA;        MDB_txn *txn;&#xA;        MDB_dbi dbi;&#xA;&#xA;        rc = mdb_txn_begin(env, NULL, 0, &amp;txn);&#xA;        rc = mdb_open(txn, NULL, 0, &amp;dbi);&#xA;&#xA;        for (j= 0; j &lt; 100; j&#x2B;&#x2B;)&#xA;        {&#xA;            UuidCreate(&amp;id);&#xA;            &#xA;            key.mv_data = &amp;id;&#xA;            rc = mdb_put(txn, dbi, &amp;key, &amp;data, 0);&#xA;        }&#xA;&#xA;        rc = mdb_txn_commit(txn);&#xA;        mdb_close(env, dbi);&#xA;    }&#xA;&#xA;    end = clock();&#xA;&#xA;    printf(&quot;%i&quot;, (end - start));&#xA;    fgetc(stdin);&#xA;    mdb_env_close(env);&#xA;&#xA;    return 0;&#xA;}&#xA;&#xA;&#xA;As you can see, we are inserting 10,000 items (100 transactions of 100 items each). Each item has key of 16 bytes and a value of 100 bytes. Now, you might note that this is probably the worst case scenario for a B&#x2B;Tree, UUID are unordered, and this generate a lot of fragmentation in the tree. Bad scenario, yes, but also a relatively common one, and one that needs to be handled properly for our needs. It took me a long while to narrow down what is actually going on. At first I was convinced that the problem was with Windows&#x2019; implementation of memory mapped files, but eventually I realized that select ain&#x2019;t broken.&#xA;Here is the Process Monitor&#x2019;s trace of the first few transactions. The highlighted calls are to FlushBuffersFile, which is how FlushFileBuffers look like, which indicate a commit.&#xA;&#xA;As I said, those are the first few transactions. You can see that the OS is doing a pretty good job in merging writes and avoid seeks. However, as times goes by&#x2026;&#xA;&#xA;And as more times goes by, we get to&#x2026; ( there are more rows at the top that I had to remove so I could take the snapshot).&#xA;&#xA;In fact, I put the data in Excel and got:&#xA;&#xA0;&#xA;&#xA;&#xA;&#xA;And those are some really bad numbers, I think you&#x2019;ll agree. After the very short period of time, the cost of committing a transaction goes to over 50 seeks and writing of 350KB.&#xA;Let us compare that to what happens when we are actually writing sequential data (using UuidCreateSequential instead of UuidCreate). The test complete in half the time, and the actual statistics are also very interesting.&#xA;&#xA;&#xA0;&#xA;&#xA;&#xA;We are writing a lot less, but much more important, we are doing a lot less seeks. For reference, here is the final transaction that we have with the sequential write scenario:&#xA;&#xA;I run those tests on a HDD drive, so seeks times matter a lot, but I have gotten similar results when running on SSD.&#xA;Now, the interesting question here is what exactly is going on? And I think that a large part of this is the way LMDB allocate pages. It uses a copy on write method, which means that after the transaction is done, the previously used page are free. That means that they can be reclaimed. And the next transaction will do just that. The problem with this approach is that it tends to spread writes all over the file. This saves disk space, but require a lot more seeks when you need to commit a transaction.&#xA;That means that in order to optimize this particular scenario, I probably need to do some thinking about the free page allocation behavior. We want to be a lot more conservative about when / how we give out those pages, to make sure that we aren&#x2019;t generating a really bad situation for the db when commit time comes.</p>
        </article>
        <article id="article-4025">
            <a href="https://ayende.com/blog/163299/with-malice-aforethought-we-can-try-even-better" target="_blank">
                <h2 class="title mb-6" id="article-4025">With malice aforethought, we can try even better</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 10, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Continuing on with the same theme from our last post. How can we improve the speed in which we write to disk. In particular, I am currently focused on my worst case scenario:  fill rnd buff 10,000 tx&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; :&#xA0;&#xA0;&#xA0; 161,812 ms&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; 6,180 ops / sec This is 10,000 transactions all running one after another, and taking really way too long to go about doing their thing. Now, we did some improvements and we got it all the way to 6,340 ops / sec, but I think you&#x2019;ll agree that even this optimization is probably still bad. We spent more time there, trying to figure out exactly how we can do micro optimizations, and we got all the way up to 8,078 ops /sec. That is the point where I decided that I would really like to look at the raw numbers that I can get from this system. So I wrote the following code:      1: var key = Guid.NewGuid().ToByteArray();   2: var buffer = new byte[100];   3: new Random().NextBytes(buffer);   4:&#xA0;    5: using (var fs = new FileStream(&quot;test.bin&quot;, FileMode.Truncate, FileAccess.ReadWrite))   6: {   7:     fs.SetLength(1024*1024*768);   8:&#xA0;    9:     var sp = Stopwatch.StartNew();  10:&#xA0;   11:     for (int i = 0; i &lt; 10*1000; i&#x2B;&#x2B;)  12:     {  13:         for (int j = 0; j &lt; 100; j&#x2B;&#x2B;)  14:         {  15:             fs.Write(key,0, 16);  16:             fs.Write(buffer, 0, 100);  17:         }  18:         fs.Flush(true);  19:     }  20:     Console.WriteLine(&quot;{0:#,#} ms for {1:#,#} ops / sec&quot;, sp.ElapsedMilliseconds, (1000*1000)/sp.Elapsed.TotalSeconds);  21: }&#xA;This code mimic the absolute best scenario we could hope for. Zero cost for managing the data, pure sequential writes. Note that we call to Flush(true) to simulate 10,000 transactions. This code gives me: 147,201 ops / sec.&#xA;This is interesting, mostly because I thought the reason our random writes with 10K transactions are bad was the calls to Flush(), but it appears that this is actually working very well. I then tested this with some random writes, by adding the following lines before line 13:&#xA;&#xA;&#xA;   1: var next = random.Next(0, 1024*1024*512);   2: fs.Position = next - next%4096;&#xA;I then decided to try it with memory mapped files, and I wrote:&#xA;&#xA;&#xA;   1: using (var fs = new FileStream(&quot;test.bin&quot;, FileMode.Truncate, FileAccess.ReadWrite))   2: {   3:     fs.SetLength(1024 * 1024 * 768);   4:&#xA0;    5:     var memoryMappedFile = MemoryMappedFile.CreateFromFile(fs,   6:                                     &quot;test&quot;, fs.Length, MemoryMappedFileAccess.ReadWrite,   7:                                     null, HandleInheritability.None, true);   8:     var memoryMappedViewAccessor = memoryMappedFile.CreateViewAccessor();   9:&#xA0;   10:     byte* p = null;  11:     memoryMappedViewAccessor.SafeMemoryMappedViewHandle.AcquirePointer(ref p);  12:&#xA0;   13:     var sp = Stopwatch.StartNew();  14:&#xA0;   15:     for (int i = 0; i &lt; 10 * 1000; i&#x2B;&#x2B;)  16:     {  17:         var next = random.Next(0, 1024 * 1024 * 512);  18:         byte* basePtr = p &#x2B; next;  19:         using (var ums = new UnmanagedMemoryStream(basePtr, 12 * 1024,12*1024, FileAccess.ReadWrite))  20:         {  21:             for (int j = 0; j &lt; 100; j&#x2B;&#x2B;)  22:             {  23:                 ums.Write(key, 0, 16);  24:                 ums.Write(buffer, 0, 100);  25:             }  26:         }  27:     }  28:     Console.WriteLine(&quot;{0:#,#} ms for {1:#,#} ops / sec&quot;, sp.ElapsedMilliseconds, (1000 * 1000) / sp.Elapsed.TotalSeconds);  29: }&#xA;You&#x2019;ll note that I am not doing any flushing here. That is intention for now, using this, I am getting 5&#x2B; million ops per second. But since I am not doing flushing, this is pretty much me testing how fast I can write to memory.&#xA;Adding a single flush cost us 1.8 seconds for a 768MB file. And what about doing the right thing? Adding the following in line 26 means that we are actually flushing the buffers.&#xA;&#xA;&#xA;   1: FlushViewOfFile(basePtr, new IntPtr(12 * 1024));&#xA;Note that we are not flushing to disk, we still need to do that. But for now, let us try doing it. This single line changed the code from 5&#x2B; million ops to doing 170,988 ops / sec. And that does NOT include actual flushing to disk. When we do that, too, we get a truly ridiculous number: 20,547 ops / sec. And that explains quite a lot, I think.&#xA;For reference, here is the full code:&#xA;&#xA;&#xA;   1: unsafe class Program   2: {   3:     [DllImport(&quot;kernel32.dll&quot;, SetLastError = true)]   4:     [return: MarshalAs(UnmanagedType.Bool)]   5:     extern static bool FlushViewOfFile(byte* lpBaseAddress, IntPtr dwNumberOfBytesToFlush);   6:&#xA0;    7:     static void Main(string[] args)   8:     {   9:         var key = Guid.NewGuid().ToByteArray();  10:         var buffer = new byte[100];  11:         var random = new Random();  12:         random.NextBytes(buffer);  13:&#xA0;   14:         using (var fs = new FileStream(&quot;test.bin&quot;, FileMode.Truncate, FileAccess.ReadWrite))  15:         {  16:             fs.SetLength(1024 * 1024 * 768);  17:&#xA0;   18:             var memoryMappedFile = MemoryMappedFile.CreateFromFile(fs,  19:                                             &quot;test&quot;, fs.Length, MemoryMappedFileAccess.ReadWrite,  20:                                             null, HandleInheritability.None, true);  21:             var memoryMappedViewAccessor = memoryMappedFile.CreateViewAccessor();  22:&#xA0;   23:             byte* p = null;  24:             memoryMappedViewAccessor.SafeMemoryMappedViewHandle.AcquirePointer(ref p);  25:&#xA0;   26:             var sp = Stopwatch.StartNew();  27:&#xA0;   28:             for (int i = 0; i &lt; 10 * 1000; i&#x2B;&#x2B;)  29:             {  30:                 var next = random.Next(0, 1024 * 1024 * 512);  31:                 byte* basePtr = p &#x2B; next;  32:                 using (var ums = new UnmanagedMemoryStream(basePtr, 12 * 1024, 12 * 1024, FileAccess.ReadWrite))  33:                 {  34:                     for (int j = 0; j &lt; 100; j&#x2B;&#x2B;)  35:                     {  36:                         ums.Write(key, 0, 16);  37:                         ums.Write(buffer, 0, 100);  38:                     }  39:                 }  40:                 FlushViewOfFile(basePtr, new IntPtr(12 * 1024));  41:                 fs.Flush(true);  42:             }  43:             Console.WriteLine(&quot;{0:#,#} ms for {1:#,#} ops / sec&quot;, sp.ElapsedMilliseconds, (1000 * 1000) / sp.Elapsed.TotalSeconds);  44:         }  45:     }  46: }&#xA;This is about as efficient a way you can get for writing to the disk using memory mapped files if you need to do that using memory mapped files in a transactional manner. And that is the absolute best case scenario, pretty much. Where we know exactly what we wrote and were we wrote it. And we always write a single entry, of a fixed size, etc. In Voron&#x2019;s case, we might write to multiple pages at the same transaction (in fact, we are pretty much guaranteed to do just that).&#xA;This means that I need to think about other ways of doing that.</p>
        </article>
        <article id="article-4026">
            <a href="https://ayende.com/blog/163650/ravendb-3-0-mystery-feature-1-webinar" target="_blank">
                <h2 class="title mb-6" id="article-4026">RavenDB 3.0&#x2013;Mystery Feature #1&#x2013;Webinar</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 09, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In this Webinar, we will discuss one of the upcoming features of RavenDB 3.0We won&#x27;t tell you what exactly, but it is a pretty cool one.Join us to hear all about it. &#xA0; Space is limited.Reserve your Webinar seat now at:https://www2.gotomeeting.com/register/274102194</p>
        </article>
        <article id="article-4027">
            <a href="https://ayende.com/blog/163682/ravendb-2-x-beginners-guide-is-out" target="_blank">
                <h2 class="title mb-6" id="article-4027">RavenDB 2.x Beginner&#x2019;s Guide is out</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 09, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This is the second book about RavenDB in as many days, and I know of a few more that are coming soon.  The previous book was meant for experts, this one is for beginners, enjoy!  http://www.packtpub.com/ravendb-2-x-beginners-guide/book</p>
        </article>
        <article id="article-4028">
            <a href="https://ayende.com/blog/163649/ravendb-high-performance-book-is-out" target="_blank">
                <h2 class="title mb-6" id="article-4028">RavenDB High Performance Book is OUT</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 08, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">You can get the new book here.   Learn how to build your application for scalability and high availability  Make highly interactive applications that support client-side notifications, faceted search, search suggestions, and more  Take advantage of advanced RavenDB APIs to make your application fly</p>
        </article>
        <article id="article-4029">
            <a href="https://ayende.com/blog/163298/with-a-little-knowledge-and-a-profiler-let-us-optimize" target="_blank">
                <h2 class="title mb-6" id="article-4029">With a little knowledge and a profiler, let us optimize!</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 06, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">As part of the work we have been doing on Voron, I wrote a few benchmarks and looked at where the hot spots are. One of the major ones was this function:      1: public override void Flush()   2: {   3:     if (_flushMode == FlushMode.None)   4:         return;   5:&#xA0;    6:     PagerState.Accessor.Flush();   7:     _fileStream.Flush(_flushMode == FlushMode.Full);   8: }&#xA;This is the &#x201C;fsync()&#x201D; call, effectively. Accessor.Flush() call will resolve to a FlushViewOfFile(0, size); and _fileStream.Flush(true) will resolve to FlushFileBuffers on Windows.&#xA;It isn&#x2019;t surprising that this would be THE hotspot, it is the part where we actually have to wait for the hardware to do stuff, after all. But further investigation revealed that it wasn&#x2019;t the FlushFileBuffers that was really costly, it was the FlushViewOfFile. What FlushViewOfFile will do is scan all of the pages in range, and flush them to the OS (not to disk) if they are dirty. That is great, but it is effectively an O(N) operation. We have more knowledge about what is going on, so we can do better. We already know what are the dirty pages, so we can actually use that, instead of letting the OS do all the work.&#xA;But then we run into another problem. If we actually just call FlushViewOfFile for every page separately, we are going to have to spend a lot of time just calling to the OS when we have to do a large write. So we need to balance the amount of data we send to FlushViewOfFile with the number of times we are going to call FlushViewOfFile. Therefor, I came up with the following logic. We are going to group calls to FlushViewOfFile, as long as they are nearby (within 256KB of one another), this will give us the best balance between reducing the number of pages that FlushViewOfFile needs to call and the number of times we call FlushViewOfFile.&#xA;This now looks like this:&#xA;&#xA;&#xA;   1: public override void Flush(List&lt;long&gt; sortedPagesToFlush)   2: {   3:     if (_flushMode == FlushMode.None || sortedPagesToFlush.Count == 0)   4:         return;   5:&#xA0;    6:     // here we try to optimize the amount of work we do, we will only    7:     // flush the actual dirty pages, and we will do so in sequential order   8:     // ideally, this will save the OS the trouble of actually having to flush the    9:     // entire range  10:     long start = sortedPagesToFlush[0];  11:     long count = 1;  12:     for (int i = 1; i &lt; sortedPagesToFlush.Count; i&#x2B;&#x2B;)  13:     {  14:         var difference = sortedPagesToFlush[i] - sortedPagesToFlush[i - 1];  15:         // if the difference between them is not _too_ big, we will just merge it into a single call  16:         // we are trying to minimize both the size of the range that we flush AND the number of times  17:         // we call flush, so we need to balance those needs.  18:         if (difference &lt; 64)  19:         {  20:             count &#x2B;= difference;  21:             continue;  22:         }  23:         FlushPages(start, count);  24:         start = sortedPagesToFlush[i];  25:         count = 1;  26:     }  27:     FlushPages(start, count);  28:&#xA0;   29:     if (_flushMode == FlushMode.Full)  30:         _fileStream.Flush(true);  31: }&#xA;A side affect of this is that we are more likely to be writing to the disk in a sequential fashion because of this.&#xA;The end result of this change was doubling the performance of the system under worse case scenario to &#x201C;just&#x201D; 25% faster under best conditions.</p>
        </article>
        <article id="article-4030">
            <a href="https://ayende.com/blog/163617/my-ravendbs-story-contest" target="_blank">
                <h2 class="title mb-6" id="article-4030">My RavenDB&#x2019;s Story Contest</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 05, 2013
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">With the public release of RavenDB 2.5, we want to hear a lot more from users about what they are doing with RavenDB. Therefor, we decided to have a contest. Basically, we would ask you to write a post about your RavenDB experience on the RavenDB page in Facebook. We will send a free RavenDB care package (which includes an awesome T-Shirt &amp; laptop stickers) to the first 50 people to send us their stories. We will also raffle 3 RavenDB DVDs from those who will submit their stories. The contest will end on Sep 20.</p>
        </article>
        <div class="button flex justify-between">
            <a href="402.html"><span class="back arrow"></span></a>

            <a href="404.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="pagefind/pagefind-ui.js"></script>
</body>
</html>