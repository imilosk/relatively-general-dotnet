
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 375 &#x2022; Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="/pagefind/pagefind-ui.css">
    <!-- Google Analytics -->
    <script>
        // Only load GA if consent is given
        function loadGA() {
            const script = document.createElement('script');
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-MDFXJY3FCY';
            script.async = true;
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }

            gtag('js', new Date());
            gtag('config', 'G-MDFXJY3FCY');
        }

        // Check if consent was previously given
        if (localStorage.getItem('cookieConsent') === 'accepted') {
            loadGA();
        }
    </script>
    <!-- End Google Analytics -->
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline underline"
               href="index.html"> Home </a><a
                aria-current="" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline " href="about.html">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>


<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-3741">
            <a href="https://ayende.com/blog/169345/tail-feather-snapshots" target="_blank">
                <h2 class="title mb-6" id="article-3741">Tail/Feather&#x2013;Snapshots</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 10, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The Raft protocol gives us a stable replicated distributed log. In other words, all servers in the cluster will agree on all the committed entries to the log (both what they are, and in what position). We usually fill the logs in operations that a state machine will execute. In the Tail/Feather example, the commands are set/del operations on the key value store. Note that this doesn&#x2019;t mean that all servers will always have the same state. It is possible that a server (or set of servers) will have an outdated view of the log, but the log that they have will match up to the point that they have it. So, what is the problem? What happens when we have an active system? Well, every time that we make a modification, we&#x2019;ll add it to the log. That is all good and great, but what about the actual log? Well, it is going to stay there, we need it so we can catch up any new server that will join the cluster. But that means that over time, we are going to have an unbounded growth. Which isn&#x2019;t a very nice thing to have. Rachis handle this by asking the state machine to implement snapshots. A way to take the current state of the state machine and transmit it over the network. For example, assume that we have an entry full of these logs: { Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 2}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 3}&#xA;&#xA;// ...&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 300000}&#xA;&#xA;&#xA;The log for that is 300,000 entries long, but the current state of the machine:&#xA;{ &quot;users/1/login-attempts&quot;: 300000 }&#xA;Which is obviously much smaller. Rachis doesn&#x2019;t force a state machine to implement this, but if it isn&#x2019;t doing so, we can never clear the log. But implementing snapshots has its own problems.What about the actual cost of creating the snapshot? Imagine that we ask the state machine for a snapshot every 10,000 entries. In the example above, that would mean just writing out { &quot;users/1/login-attempts&quot;: 300000 } or whatever the actual current value is.&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/2/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/3/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;&#xA;// ...&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/300000/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;&#xA;&#xA;Note that instead of having 300,000 changes to the same key, we are going to have 300,000 keys. In this case, writing the full list down on every snapshot is very expensive. That is what incremental backups are here to solve.&#xA0; We let Voron know that this is what we want by specifying:&#xA;options.IncrementalBackupEnabled = true;&#xA;&#xA;&#xA;And now it is time to define policies about taking snapshots. We are going to handle this using Voron full &amp; incremental snapshots. You can see the logic in the following code.&#xA;public void CreateSnapshot(long index, long term, ManualResetEventSlim allowFurtherModifications)&#xA;{&#xA;    // we have not snapshot files, so this is the first time that we create a snapshot&#xA;    // we handle that by asking voron to create a full backup&#xA;    var files = Directory.GetFiles(_storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;    Array.Sort(files, StringComparer.OrdinalIgnoreCase); // make sure we get it in sort order&#xA;    if (files.Any() == false)&#xA;    {&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;    string lastFullBackup = null;&#xA;    int fullBackupIndex = -1;&#xA;    for (int i = files.Length - 1; i &gt;= 0; i--)&#xA;    {&#xA;        if (!files[i].StartsWith(&quot;Full&quot;)) &#xA;            continue;&#xA;        fullBackupIndex = i;&#xA;        lastFullBackup = files[i];&#xA;        break;&#xA;    }&#xA;            &#xA;    if (lastFullBackup == null)&#xA;    {&#xA;        // this shouldn&#x27;t be the case, we must always have at least one full backup. &#xA;        // maybe user deleted it? We&#x27;ll do a full backup here to compensate&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;            &#xA;    var fullBackupSize = new FileInfo(lastFullBackup).Length;&#xA;    var incrementalBackupsSize = files.Skip(fullBackupIndex &#x2B; 1).Sum(f =&gt; new FileInfo(f).Length);&#xA;&#xA;    // now we need to decide whatever to do a full or incremental backup, doing incremental backups stop &#xA;    // making sense if they will take more space than the full backup. Our cutoff point is when it passes to 50%&#xA;    // size of the full backup.&#xA;    // If full backup size is 1 GB, and we have 25 incrmeental backups that are 600 MB in size, we need to transfer&#xA;    // 1.6 GB to restore. If we generate a new full backup, we&#x27;ll only need to transfer 1 GB to restore.&#xA;&#xA;    if (incrementalBackupsSize / 2 &gt; fullBackupSize)&#xA;    {&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;&#xA;    DeleteOldSnapshots(files.Take(fullBackupIndex - 1));// delete snapshots older than the current full backup&#xA;&#xA;    var incrementalBackup = new IncrementalBackup();&#xA;    incrementalBackup.ToFile(_storageEnvironment,&#xA;        Path.Combine(_storageEnvironment.Options.BasePath, string.Format(&quot;Inc-{0:D19}-{1:D19}.Snapshot&quot;, index, term)),&#xA;        infoNotify: Console.WriteLine,&#xA;        backupStarted: allowFurtherModifications.Set);&#xA;}&#xA;&#xA;private void DoFullBackup(long index, long term, ManualResetEventSlim allowFurtherModifications)&#xA;{&#xA;    var snapshotsToDelete = Directory.GetFiles(_storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;&#xA;    var fullBackup = new FullBackup();&#xA;    fullBackup.ToFile(_storageEnvironment,&#xA;        Path.Combine(_storageEnvironment.Options.BasePath, string.Format(&quot;Full-{0:D19}-{1:D19}.Snapshot&quot;, index, term)),&#xA;        infoNotify: Console.WriteLine,&#xA;        backupStarted: allowFurtherModifications.Set&#xA;        );&#xA;&#xA;    DeleteOldSnapshots(snapshotsToDelete);&#xA;}&#xA;&#xA;private static void DeleteOldSnapshots(IEnumerable&lt;string&gt; snapshotsToDelete)&#xA;{&#xA;    foreach (var snapshot in snapshotsToDelete)&#xA;    {&#xA;        try&#xA;        {&#xA;            File.Delete(snapshot);&#xA;        }&#xA;        catch (Exception)&#xA;        {&#xA;            // we ignore snapshots we can&#x27;t delete, they are expected if we are concurrently writing&#xA;            // the snapshot and creating a new one. We&#x27;ll get them the next time.&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;Basically, we need to strike a balance between full and incremental backups. We do that by first taking a full backup, and then starting to take incremental backups until our incremental backups takes more than 50% of the full backup, at which point we are probably better off doing another full backup. Note that we use the event of a full backup to clear the old incremental and full backup files. &#xA;And with that, we can move to actually sending the snapshot over the wire. This is exposed by the GetSnapshotWriter() method. This just shell all the responsibility to the SnapshotWriter:&#xA;public ISnapshotWriter GetSnapshotWriter()&#xA;{&#xA;    return new SnapshotWriter(this);&#xA;}&#xA;&#xA;public class SnapshotWriter : ISnapshotWriter&#xA;{&#xA;    private readonly KeyValueStateMachine _parent;&#xA;&#xA;    private List&lt;FileStream&gt; _files = new List&lt;FileStream&gt;();&#xA;&#xA;    public SnapshotWriter(KeyValueStateMachine parent)&#xA;    {&#xA;        _parent = parent;&#xA;        var files = Directory.GetFiles(_parent._storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;        var fullBackupIndex = GetFullBackupIndex(files);&#xA;&#xA;        if (fullBackupIndex == -1)&#xA;            throw new InvalidOperationException(&quot;Could not find a full backup file to start the snapshot writing&quot;);&#xA;&#xA;        var last = Path.GetFileNameWithoutExtension(files[files.Length-1]);&#xA;        Debug.Assert(last != null);&#xA;        var parts = last.Split(&#x27;-&#x27;);&#xA;        if(parts.Length != 3)&#xA;            throw new InvalidOperationException(&quot;Invalid snapshot file name &quot; &#x2B; files[files.Length - 1] &#x2B; &quot;, could not figure out index &amp; term&quot;);&#xA;&#xA;        Index = long.Parse(parts[1]);&#xA;        Term = long.Parse(parts[2]);&#xA;&#xA;        for (int i = fullBackupIndex; i &lt; files.Length; i&#x2B;&#x2B;)&#xA;        {&#xA;            _files.Add(File.OpenRead(files[i]));&#xA;        }&#xA;    }&#xA;&#xA;    public void Dispose()&#xA;    {&#xA;        foreach (var file in _files)&#xA;        {&#xA;            file.Dispose();&#xA;        }&#xA;    }&#xA;&#xA;    public long Index { get; private set; }&#xA;    public long Term { get; private set; }&#xA;    public void WriteSnapshot(Stream stream)&#xA;    {&#xA;        var writer = new BinaryWriter(stream);&#xA;        writer.Write(_files.Count);&#xA;        foreach (var file in _files)&#xA;        {&#xA;            writer.Write(file.Name);            writer.Write(file.Length);&#xA;            writer.Flush();&#xA;            file.CopyTo(stream);&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;What is going on here? We get the snapshot files, and find the latest full backup, then we open all the files that we&#x2019;ll need for the snapshot (the last full backup and everything afterward). We need to open them in the constructor to lock them for deletion by the CreateSnapshot() method.&#xA;Then we just concatenate them all and send them over the wire. And getting them? That is pretty easy as well:&#xA;public void ApplySnapshot(long term, long index, Stream stream)&#xA;{&#xA;    var basePath = _storageEnvironment.Options.BasePath;&#xA;    _storageEnvironment.Dispose();&#xA;&#xA;    foreach (var file in Directory.EnumerateFiles(basePath))&#xA;    {&#xA;        File.Delete(file);&#xA;    }&#xA;&#xA;    var files = new List&lt;string&gt;();&#xA;&#xA;    var buffer = new byte[1024*16];&#xA;    var reader = new BinaryReader(stream);&#xA;    var filesCount = reader.ReadInt32();&#xA;    if (filesCount == 0)&#xA;        throw new InvalidOperationException(&quot;Snapshot cannot contain zero files&quot;);&#xA;    for (int i = 0; i &lt; filesCount; i&#x2B;&#x2B;)&#xA;    {&#xA;        var name = reader.ReadString();&#xA;        files.Add(name);&#xA;        var len = reader.ReadInt64();&#xA;        using (var file = File.Create(Path.Combine(basePath, name)))&#xA;        {&#xA;            file.SetLength(len);&#xA;            var totalFileRead = 0;&#xA;            while (totalFileRead &lt; len)&#xA;            {&#xA;                var read = stream.Read(buffer, 0, (int) Math.Min(buffer.Length, len - totalFileRead));&#xA;                if (read == 0)&#xA;                    throw new EndOfStreamException();&#xA;                totalFileRead &#x2B;= read;&#xA;                file.Write(buffer, 0, read);&#xA;            }&#xA;        }&#xA;    }&#xA;            &#xA;    new FullBackup().Restore(Path.Combine(basePath, files[0]), basePath);&#xA;&#xA;    var options = StorageEnvironmentOptions.ForPath(basePath);&#xA;    options.IncrementalBackupEnabled = true;&#xA;    //TODO: Copy any other customizations that might have happened on the options&#xA;&#xA;    new IncrementalBackup().Restore(options, files.Skip(1));&#xA;&#xA;    _storageEnvironment = new StorageEnvironment(options);&#xA;&#xA;    using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))&#xA;    {&#xA;        var metadata = tx.ReadTree(&quot;$metadata&quot;);&#xA;        metadata.Add(&quot;last-index&quot;, EndianBitConverter.Little.GetBytes(index));&#xA;        LastAppliedIndex = index;&#xA;        tx.Commit();&#xA;    }&#xA;}&#xA;&#xA;&#xA;Unpack the snapshots from the stream, then first apply a full backup, then all the incremental backups. Make sure to update the last applied index, and we are set .</p>
        </article>
        <article id="article-3742">
            <a href="https://ayende.com/blog/169249/tail-feather-the-client-api" target="_blank">
                <h2 class="title mb-6" id="article-3742">Tail/Feather&#x2013;The client API</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 09, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">As I mentioned Tail/Feather is a weekend project to test out how stuff works for real. After creating the highly available distributed key/value store, we are now in need of actually building a client API for it. Externally, that API is going to look like this:  public class TailFeatherClient : IDisposable{    public TailFeatherClient(params Uri[] nodes);    public Task Set(string key, JToken value);    public Task&lt;JToken&gt; Get(string key);    public Task Remove(string key);    public void Dispose();}&#xA;If this wasn&#x2019;t a weekend project, I would add batch support, but that isn&#x2019;t important for our purposes right now. The API itself is pretty stupid, which is great, but what about the actual behavior?&#xA;We want it to be able to handle dynamic cluster changes, and we need it to be smart about it. A lot of that is shared among all operations, so the next layer of the API is:&#xA;&#xA;public Task Set(string key, JToken value){    return ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/set?key={0}&amp;val={1}&quot;,         Uri.EscapeDataString(key), Uri.EscapeDataString(value.ToString(Formatting.None)))));}public async Task&lt;JToken&gt; Get(string key){    var reply = await ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/del?key={0}&quot;,        Uri.EscapeDataString(key))));    var result = JObject.Load(new JsonTextReader(new StreamReader(await reply.Content.ReadAsStreamAsync())));    if (result.Value&lt;bool&gt;(&quot;Missing&quot;))        return null;    return result[&quot;Value&quot;];}public Task Remove(string key){    return ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/del?key={0}&quot;,        Uri.EscapeDataString(key))));}&#xA;The actual behavior is in ContactServer:&#xA;&#xA;&#xA;private readonly ConcurrentDictionary&lt;Uri, HttpClient&gt; _cache = new ConcurrentDictionary&lt;Uri, HttpClient&gt;();private Task&lt;TailFeatherTopology&gt; _topologyTask;public TailFeatherClient(params Uri[] nodes){    _topologyTask = FindLatestTopology(nodes);}private HttpClient GetHttpClient(Uri node){    return _cache.GetOrAdd(node, uri =&gt; new HttpClient { BaseAddress = uri });}private async Task&lt;TailFeatherTopology&gt; FindLatestTopology(IEnumerable&lt;Uri&gt; nodes){    var tasks = nodes.Select(node =&gt; GetHttpClient(node).GetAsync(&quot;tailfeather/admin/flock&quot;)).ToArray();    await Task.WhenAny(tasks);    var topologies = new List&lt;TailFeatherTopology&gt;();    foreach (var task in tasks)    {        var message = task.Result;        if (message.IsSuccessStatusCode == false)            continue;        topologies.Add(new JsonSerializer().Deserialize&lt;TailFeatherTopology&gt;(            new JsonTextReader(new StreamReader(await message.Content.ReadAsStreamAsync()))));    }    return topologies.OrderByDescending(x =&gt; x.CommitIndex).FirstOrDefault();}private async Task&lt;HttpResponseMessage&gt; ContactServer(Func&lt;HttpClient, Task&lt;HttpResponseMessage&gt;&gt; operation, int retries = 3){    if (retries &lt; 0)        throw new InvalidOperationException(&quot;Cluster is not reachable, or no leader was selected. Out of retries, aborting.&quot;);    var topology = (await _topologyTask ?? new TailFeatherTopology());            var leader = topology.AllVotingNodes.FirstOrDefault(x =&gt; x.Name == topology.CurrentLeader);    if (leader == null)    {        _topologyTask = FindLatestTopology(topology.AllVotingNodes.Select(x =&gt; x.Uri));        return await ContactServer(operation, retries - 1);    }    // now we have a leader, we need to try calling it...    var httpResponseMessage = await operation(GetHttpClient(leader.Uri));    if (httpResponseMessage.IsSuccessStatusCode == false)    {        // we were sent to a different server, let try that...        if (httpResponseMessage.StatusCode == HttpStatusCode.Redirect)        {            var redirectUri = httpResponseMessage.Headers.Location;            httpResponseMessage = await operation(GetHttpClient(redirectUri));            if (httpResponseMessage.IsSuccessStatusCode)            {                // we successfully contacted the redirected server, this is probably the leader, let us ask it for the topology,                // it will be there for next time we access it                _topologyTask = FindLatestTopology(new[] { redirectUri }.Union(topology.AllVotingNodes.Select(x =&gt; x.Uri)));                return httpResponseMessage;            }        }        // we couldn&#x27;t get to the server, and we didn&#x27;t get redirected, we&#x27;ll check in the cluster in general        _topologyTask = FindLatestTopology(topology.AllVotingNodes.Select(x =&gt; x.Uri));        return await ContactServer(operation, retries - 1);    }    // happy path, we are done    return httpResponseMessage;}&#xA;There is quite a bit going on here. But the basic idea is simple. Starting from the initial list of nodes we have, contact all of them and find the topology with the highest commit index. That means that it is the freshest, so more likely to be the current one. From the topology, we take the leader, and send all queries to the leader.&#xA;If there is any sort of errors, we&#x2019;ll contact all other servers to find who we are supposed to be using now. If we can&#x2019;t find it after three tries, we give us and we let the caller sort it out, probably by retrying once the cluster is in a steady state again.&#xA;Now, this is really nice, but it is falling into the heading of weekend code. That is means that this is quite far from what I would call production code. What is missing?&#xA;&#xA;Caching the topology locally in a persistent manner so we can restart when the known servers are down from last known good topology.&#xA;Proper error handling, and in particular, error reporting, to make sure that we can understand what is actually is going on.&#xA;Features such as allowing reads from non leaders, testing, etc.&#xA;But overall, I&#x2019;m quite happy with this.</p>
        </article>
        <article id="article-3743">
            <a href="https://ayende.com/blog/169218/tail-feather-highly-available-distributed-key-value-store-weekend-project" target="_blank">
                <h2 class="title mb-6" id="article-3743">Tail/Feather&#x2013;highly available distributed key/value store weekend project</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 08, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Weekend project means just that, I&#x2019;m trying some things out, and writing something real is the best way to exercise. This isn&#x2019;t going to be a full blown project, but it should be functional and usable. The basic idea, I&#x2019;m going to build a distributed key/value configuration store. Similar to etcd, this will allow me to explore how to handle full blown Rachis from both server &amp; client sides. We want this to be a full&#xA0; blown implementation, which means persistence, snapshots, network api, the works. In terms of the data model, we&#x2019;ll go for the simplest possible one. A key/value store. A key is a string of up to 128 characters. A value is a json formatted value of up to 16Kb. Persistence will be handled by Voron. The persistent of the project is mostly Voron, so what we are left with is the following:   public enum KeyValueOperationTypes{    Add,    Del}public class KeyValueOperation{    public KeyValueOperationTypes Type;    public string Key;    public JToken Value;}public class OperationBatchCommand : Command{    public KeyValueOperation[] Batch { get; set; }}&#xA;This gives us the background for the actual state machine:&#xA;&#xA;public class KeyValueStateMachine : IRaftStateMachine{    readonly StorageEnvironment _storageEnvironment;    public KeyValueStateMachine(StorageEnvironmentOptions options)    {        _storageEnvironment = new StorageEnvironment(options);        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))        {            _storageEnvironment.CreateTree(tx, &quot;items&quot;);            var metadata = _storageEnvironment.CreateTree(tx, &quot;$metadata&quot;);            var readResult = metadata.Read(&quot;last-index&quot;);            if (readResult != null)                LastAppliedIndex = readResult.Reader.ReadLittleEndianInt64();            tx.Commit();        }    }    public event EventHandler&lt;KeyValueOperation&gt; OperatonExecuted;    protected void OnOperatonExecuted(KeyValueOperation e)    {        var handler = OperatonExecuted;        if (handler != null) handler(this, e);    }    public JToken Read(string key)    {        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.Read))        {            var items = tx.ReadTree(&quot;items&quot;);            var readResult = items.Read(key);            if (readResult == null)                return null;            return JToken.ReadFrom(new JsonTextReader(new StreamReader(readResult.Reader.AsStream())));        }    }    public long LastAppliedIndex { get; private set; }    public void Apply(LogEntry entry, Command cmd)    {        var batch = (OperationBatchCommand)cmd;        Apply(batch.Batch, cmd.AssignedIndex);    }        private void Apply(IEnumerable&lt;KeyValueOperation&gt; ops, long commandIndex)    {        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))        {            var items = tx.ReadTree(&quot;items&quot;);            var metadata = tx.ReadTree(&quot;$metadata&quot;);            metadata.Add(&quot;last-index&quot;, EndianBitConverter.Little.GetBytes(commandIndex));            var ms = new MemoryStream();            foreach (var op in ops)            {                switch (op.Type)                {                    case KeyValueOperationTypes.Add:                        ms.SetLength(0);                        var streamWriter = new StreamWriter(ms);                        op.Value.WriteTo(new JsonTextWriter(streamWriter));                        streamWriter.Flush();                        ms.Position = 0;                        items.Add(op.Key, ms);                        break;                    case KeyValueOperationTypes.Del:                        items.Delete(op.Key);                        break;                    default:                        throw new ArgumentOutOfRangeException();                }                OnOperatonExecuted(op);            }            tx.Commit();        }    }    public void Dispose()    {        if (_storageEnvironment != null)            _storageEnvironment.Dispose();    }}&#xA;As you can see, there isn&#x2019;t much here. Not surprising, since we are storing a key/value data structure. I&#x2019;m also ignoring snapshots for now. That is good enough for now, let us go for the network portion of the work. We are going to be using Web API for the network stuff. And we&#x2019;ll be initializing it like so:&#xA;&#xA;var nodeName = options.NodeName ?? (Environment.MachineName &#x2B; &quot;:&quot; &#x2B; options.Port);var kvso = StorageEnvironmentOptions.ForPath(Path.Combine(options.DataPath, &quot;KeyValue&quot;));using (var statemachine = new KeyValueStateMachine(kvso)){    using (var raftEngine = new RaftEngine(new RaftEngineOptions(        new NodeConnectionInfo        {            Name = nodeName,            Url = new Uri(&quot;http://&quot; &#x2B; Environment.MachineName &#x2B; &quot;:&quot; &#x2B; options.Port),        },        StorageEnvironmentOptions.ForPath(Path.Combine(options.DataPath, &quot;Raft&quot;)),        new HttpTransport(nodeName),        statemachine        )))    {        using (WebApp.Start(new StartOptions        {            Urls = { &quot;http://&#x2B;:&quot; &#x2B; options.Port &#x2B; &quot;/&quot; }        }, builder =&gt;        {            var httpConfiguration = new HttpConfiguration();            RaftWebApiConfig.Register(httpConfiguration);            httpConfiguration.Properties[typeof(HttpTransportBus)] = new HttpTransportBus(nodeName);            httpConfiguration.Properties[typeof(RaftEngine)] = raftEngine;            builder.UseWebApi(httpConfiguration);        }))        {            Console.WriteLine(&quot;Ready &amp; processing requests, press ENTER to sop&quot;);            Console.ReadLine();        }    }}&#xA;Note that we need to initialize both the state machine and the raft engine, then wire the raft engine controllers. Now we are pretty much done with setup, and we can turn to the actual semantics of running the cluster. The first thing that I want to do is to setup the baseline, so we create this base controller:&#xA;&#xA;public abstract class TailFeatherController : ApiController{    public KeyValueStateMachine StateMachine { get; private set; }    public RaftEngine RaftEngine { get; private set; }    public override async Task&lt;HttpResponseMessage&gt; ExecuteAsync(HttpControllerContext controllerContext, CancellationToken cancellationToken)    {        RaftEngine = (RaftEngine)controllerContext.Configuration.Properties[typeof(RaftEngine)];        StateMachine = (KeyValueStateMachine)RaftEngine.StateMachine;        try        {            return await base.ExecuteAsync(controllerContext, cancellationToken);        }        catch (NotLeadingException)        {            var currentLeader = RaftEngine.CurrentLeader;            if (currentLeader == null)            {                return new HttpResponseMessage(HttpStatusCode.PreconditionFailed)                {                    Content = new StringContent(&quot;{ &#x27;Error&#x27;: &#x27;No current leader, try again later&#x27; }&quot;)                };            }            var leaderNode = RaftEngine.CurrentTopology.GetNodeByName(currentLeader);            if (leaderNode == null)            {                return new HttpResponseMessage(HttpStatusCode.InternalServerError)                {                    Content = new StringContent(&quot;{ &#x27;Error&#x27;: &#x27;Current leader &quot; &#x2B; currentLeader &#x2B; &quot; is not found in the topology. This should not happen.&#x27; }&quot;)                };            }            return new HttpResponseMessage(HttpStatusCode.Redirect)            {                Headers =                {                    Location = leaderNode.Uri                }            };        }    }}&#xA;That is a lot of error handling, but basically it just get the right values from the configuration and expose them to the controller actions, then a lot of error handling when we have a command that requires a leader that hit a follower. &#xA;Next step, actually managing the cluster, here we go:&#xA;&#xA;public class AdminController : TailFeatherController{    [HttpGet]    [Route(&quot;tailfeather/admin/fly-with-us&quot;)]    public async Task&lt;HttpResponseMessage&gt; Join([FromUri] string url, [FromUri] string name)    {        var uri = new Uri(url);        name = name ?? uri.Host &#x2B; (uri.IsDefaultPort ? &quot;&quot; : &quot;:&quot; &#x2B; uri.Port);        await RaftEngine.AddToClusterAsync(new NodeConnectionInfo        {            Name = name,            Uri = uri        });        return new HttpResponseMessage(HttpStatusCode.Accepted);    }    [HttpGet]    [Route(&quot;tailfeather/admin/fly-away&quot;)]    public async Task&lt;HttpResponseMessage&gt; Leave([FromUri] string name)    {        await RaftEngine.RemoveFromClusterAsync(new NodeConnectionInfo        {            Name = name        });        return new HttpResponseMessage(HttpStatusCode.Accepted);    }}&#xA;So now we have a way to add and remove items from the cluster, which is all the admin stuff that we need to handle right now. Next, we need to actually wire the operations, this is done here:&#xA;&#xA;public class KeyValueController : TailFeatherController{    [HttpGet]    [Route(&quot;tailfeather/key-val/read&quot;)]    public HttpResponseMessage Read([FromUri] string key)    {        var read = StateMachine.Read(key);        if (read == null)        {            return Request.CreateResponse(HttpStatusCode.NotFound, new            {                RaftEngine.State,                Key = key,                Missing = true            });        }        return Request.CreateResponse(HttpStatusCode.OK, new        {            RaftEngine.State,            Key = key,            Value = read        });    }    [HttpGet]    [Route(&quot;tailfeather/key-val/set&quot;)]    public Task&lt;HttpResponseMessage&gt; Set([FromUri] string key, [FromUri] string val)    {        JToken jVal;        try        {            jVal = JToken.Parse(val);        }        catch (JsonReaderException)        {            jVal = val;        }        var op = new KeyValueOperation        {            Key = key,            Type = KeyValueOperationTypes.Add,            Value = jVal        };        return Batch(new[] { op });    }    [HttpGet]    [Route(&quot;tailfeather/key-val/del&quot;)]    public Task&lt;HttpResponseMessage&gt; Del([FromUri] string key)    {        var op = new KeyValueOperation        {            Key = key,            Type = KeyValueOperationTypes.Del,        };        return Batch(new[] { op });    }    [HttpPost]    [Route(&quot;tailfeather/key-val/batch&quot;)]    public async Task&lt;HttpResponseMessage&gt; Batch()    {        var stream = await Request.Content.ReadAsStreamAsync();        var operations = new JsonSerializer().Deserialize&lt;KeyValueOperation[]&gt;(new JsonTextReader(new StreamReader(stream)));        return await Batch(operations);    }    private async Task&lt;HttpResponseMessage&gt; Batch(KeyValueOperation[] operations)    {        var taskCompletionSource = new TaskCompletionSource&lt;object&gt;();        RaftEngine.AppendCommand(new OperationBatchCommand        {            Batch = operations,            Completion = taskCompletionSource        });        await taskCompletionSource.Task;        return Request.CreateResponse(HttpStatusCode.Accepted);    }}&#xA;And we are pretty much set. &#xA;Note that I&#x2019;ve been writing this post while I&#x2019;m writing the code, so I&#x2019;ve made some small changes, you can see actual code here. &#xA;Anyway, we are pretty much done. Now we can compile and try testing what is going on.&#xA;First, we seed the cluster, but running:&#xA;&#xA;.\TailFeather.exe --port=9079 --DataPath=One --Name=One &#x2013;Bootstrap&#xA;This tell us that this node is allowed to become a leader without having to pre-configure a cluster. This command runs and exit, so now we&#x2019;ll run three such copies:&#xA;&#xA;start .\TailFeather.exe &quot;--port=9079 --DataPath=One --Name=One&quot;&#xA;start .\TailFeather.exe &quot;--port=9078 --DataPath=Two --Name=Two&quot;&#xA;start .\TailFeather.exe &quot;--port=9077 --DataPath=Three --Name=Three&quot;&#xA;We have all three nodes up and running, so now is the time to actually make use of it:&#xA;&#xA;http://localhost:9079/tailfeather/key-val/set?key=ravendb&amp;val={ &#x27;Url&#x27;: &#x27;http://live-test.ravendb.net&#x27;, &#x27;Database&#x27;: &#x27;Sample&#x27; }&#xA;In this case, you can see that we are setting a configuration value to point to a RavenDB database on the first node. Note that at this point, we have a single node cluster, and the two other are waiting to join it, but are taking no action.&#xA;We can get the value back using:&#xA;&#xA;So far, so good. Now, let us add a second node in by inviting it to fly with our cluster. We do that using the following command:&#xA;http://localhost:9079/tailfeather/admin/fly-with-us?url=http://localhost:9078&amp;name=Two&#xA;Which will give us:&#xA;&#xA;Note that we are using the just added node for too look at this.&#xA;Next, we can add the third node. &#xA;http://localhost:9079/tailfeather/admin/fly-with-us?url=http://localhost:9077&amp;name=Three&#xA;I would put the image in, but I think you get the point.&#xA;This is it for now. We have a highly available persistent &amp; distributed key/value store. Next, we need to tackle the idea of snapshots and the client API, but I&#x2019;ll deal with that at another post.</p>
        </article>
        <article id="article-3744">
            <a href="https://enterprisecraftsmanship.com/posts/separation-of-concerns-in-orm/" target="_blank">
                <h2 class="title mb-6" id="article-3744">Separation of Concerns in ORM</h2>
            </a>
            <p class="mb-2">by Vladimir Khorikov</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 06, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Last week we&#xA0;compared Entity Framework and NHibernate from a&#xA0;DDD perspective. Today, I&#x2019;d like to dive deeper into what Separation of Concerns (SoC) is and why it is so important. We&#x2019;ll look at some code examples and features that break the boundaries between the domain and persistence logic.&#xA; Separation of concerns in ORM There are several concerns we deal with in software development. In most applications, there are at least three of them clearly defined: UI, business logic and database.</p>
        </article>
        <article id="article-3745">
            <a href="https://ayende.com/blog/169217/introducing-rachis-ravens-raft-implementation" target="_blank">
                <h2 class="title mb-6" id="article-3745">Introducing Rachis: Raven&#x2019;s Raft implementation</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 05, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Rachis, def: Spinal column, also the distal part of the shaft of a feather that bears the web.  Rachis is the name we picked for RavenDB&#x2019;s Raft implementation. Raft is a consensus protocol that can actually be understood without resorting to Greek philosophy. You can read all about it in here (there is a very cool interactive visualization there). I would also like to thank Diego Ongaro for both the Raft paper and a lot of help while I tried to understand the finer points of it. Why Raft?  Raft is a distributed consensus protocol. It allows you to reach an order set of operations across your entire cluster. This means that you can apply a set of operations on a state machine, and have the same final state machine in all nodes in the cluster. It is also drastically simpler to understand than Paxos, which is the more known alternative. What is Rachis? Well, it is a Raft implementation. To be rather more exact, it is a Raft implementation with the following features:  (Obviously) the ability to manage a distributed set of state machine and reliability commits updates to said state machines.  Dynamic topology (nodes can join and leave the cluster on the fly, including state sync). Large state machines (snapshots, efficient transfers, non voting members). ACID local log using Voron. Support for in memory and persistent state machines. Support for voting &amp; non voting members. A lot of small tweaks for best behavior in strange situations (forced step down, leader timeout and many more). What are you going to use this for? To reach a consensus, of course . More to the point, we got some really nice idea where this is going to allow us to do some really nice stuff. In particular, we want to use that as the backbone for the event and time series replication models. But I&#x2019;m getting ahead of myself. Before we do that, I want to build a simple reliable distributed service. We&#x2019;ll call it Tail/Feather and it will be awesome, in a weekend project kind of way. I&#x2019;ll post full details about this in my next post. Where can I look at it? The current version is here, note that you&#x2019;ll need to pull Voron as well (from the ravendb repository) to get it working. How does this work? You can read the Raft paper and the full thesis, of course, but there are some subtleties that I had to work through (with great help from Diego), so it is worth going into a bit more detail. Clusters are typically composed of odd number of servers (3,5 or 7), which can communicate freely with one another. The startup process for a cluster require us to designate a single server as the seed. This is the only server that can become the cluster leader during the cluster bootstrap process. This is done to make sure that during startup, before we had the chance to tell the servers about the cluster topology, they won&#x2019;t consider themselves a single node cluster and start accepting requests before we add them to the cluster. Only the seed server will become the leader, and all the others will wait for instructions. We can then let the seed server know about the other nodes in the cluster. It will initiate a join operation which will reach to the other node, setup the appropriate cluster topology. At that point, all the other servers are on equal footing, and there is no longer any meaningful distinction between them. The notion of a seed node it only&#xA0; relevant for cluster bootstrap, once that is done, all servers have the same configuration, and there isn&#x2019;t any difference between them. Dynamically adding and removing nodes from the cluster Removing a node from the cluster is a simple process. All we need to do is to update the cluster topology, and we are done. The removed server will get a notification to let it know that is has been disconnected from the cluster, and will move itself to a passive state (note that it is okay if it doesn&#x2019;t get this notification, we are just being nice about it ). The process of adding a server is a bit more complex. Not only are we having to add a new node, we need to make sure that it has the same state as all other nodes in the cluster. In order to do that, we handle it in multiple stages. A node added to the cluster can be in one of three states: Voting (full member of the cluster, able to become a leader), Non Voting (just listening to what is going on, can&#x2019;t be a leader), Promotable (getting up to speed with the cluster state). Non voting members are a unique case, they are there to enable some advance scenarios (cross data center communication, as we currently envision it). Promotable is a lot more interesting. Adding a node to an existing cluster can be a long process, especially if we are managing a lot of data. In order to handle that, we adding a server to the promotable category, in which case we are starting to send it the state it needs to catch up with the rest of the cluster. Once it has caught up with the cluster (it has all the committed entries in the cluster), we will automatically move it to the voting members in the cluster. Note that it is fine for crashes to happen throughout this process. The cluster leader can crash during this, and we&#x2019;ll recover and handle this properly. Normal operations During normal operations, there is going to be a leader that is going to be accepting all the requests for the cluster, and handle committing them cluster wide. During those operations, you can spread reads across members in the cluster, for better performance.  Now, if you don&#x2019;t mind, I&#x2019;m going to be writing Tail/Feather now, and see how long it takes.</p>
        </article>
        <article id="article-3746">
            <a href="https://ayende.com/blog/169155/nhibernate-entity-framework-profiler-3-0" target="_blank">
                <h2 class="title mb-6" id="article-3746">NHibernate &amp; Entity Framework Profiler 3.0</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 04, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">It may not get enough attention, but we have been working on the profilers as well during the past few months.&#xA;&#xA;&#x9;&#xA;&#x9;&#x9;TLDR; You can get the next generation of NHibernate Profiler and Entity Framework Profiler now, lots of goodies to look at!&#xA;&#xA;&#xA;&#x9;I&#x2019;m sure that a lot of people would be thrilled to hear that we dropped Silverlight in favor of going back to WPF UI. The idea was that we would be able to deploy anywhere, including in production. But Silverlight just made things harder all around, and customers didn&#x2019;t like the production profiling mode.&#xA;&#xA;&#x9;Production Profiling&#xA;&#xA;&#x9;We have changed how we profile in production. You can now make the following call in your code:&#xA;&#xA;&#x9;NHibernateProfiler.InitializeForProduction(port, password);&#xA;&#x9;&#xA;&#xA;&#xA;&#x9;And then connect to your production system:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;At which point you can profile what is going on in your production system safely and easily. The traffic between your production server and the profiler is SSL encrypted.&#xA;&#xA;&#x9;NHibernate 4.x and Entity Framework vNext support&#xA;&#xA;&#x9;The profilers now support the latest version of NHibernate and Entity Framework. That include profiling async operations, better suitability for modern apps, and more.&#xA;&#xA;&#x9;New SQL Paging Syntax&#xA;&#xA;&#x9;We are now properly support SQL Server paging syntax:&#xA;&#xA;&#x9;select * from Users&#xA;order by Name&#xA;offset 0 /* @p0 */ rows fetch next 250 /* @p1 */ rows only&#xA;&#xA;&#x9;&#xA;&#xA;&#xA;&#x9;This is great for NHibernate users, who finally can have a sane paging syntax as well as beautiful queries in the profiler.&#xA;&#xA;&#x9;At a glance view&#xA;&#xA;&#x9;A lot of the time, you don&#x2019;t want the profiler to be front and center, you want to just run it and have it there to glance at once in a while. The new compact view gives you just that:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;You can park it at some point in your screen and work normally, glancing to see if it found anything. This is much less distracting than the full profiler for normal operations.&#xA;&#xA;&#x9;Scopes and groups&#xA;&#xA;&#x9;When we started working on the profilers, we followed the &#x201C;one session per request&#x201D; rule, and that was pretty good. But a lot of people, especially in the Entity Framework group are using multiple sessions or data contexts in a single request, but they still want to see the ability to see the operations in a request at a glance. We are now allowing you to group things, like this:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;By default, we use the current request to group things, but we also give you the ability to define your own scopes. So if you are profiling NServiceBus application, you can set the scope as your message handling by setting ProfilerIntegration.GetCurrentScopeName or explicitly calling ProfilerIntegration.StartScope whenever you want.&#xA;&#xA;&#x9;Customized profiling&#xA;&#xA;&#x9;You can now surface troublesome issues directly from your code. If you have an issue with a query, you can mark it for attention using CustomQueryReporting .ReportError() that would flag it in the UI for further investigation.&#xA;&#xA;&#x9;You can also just mark interesting pieces in the UI without an error, like so:&#xA;&#xA;&#x9;using (var db = new Entities(conStr))&#xA;{&#xA;    var post1 = db.Posts.FirstOrDefault();&#xA;&#xA;    using (ProfilerIntegration.StarStatements(&quot;Blue&quot;))&#xA;    {&#xA;        var post2 = db.Posts.FirstOrDefault();&#xA;    }&#xA;&#xA;    var post3 = db.Posts.FirstOrDefault();&#xA;    &#xA;    ProfilerIntegration.StarStatements();&#xA;    var post4 = db.Posts.FirstOrDefault();&#xA;    ProfilerIntegration.StarStatementsClear();&#xA;&#xA;    var post5 = db.Posts.FirstOrDefault();&#xA;}&#xA;&#x9;&#xA;&#xA;&#xA;&#x9;Which will result in:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;Disabling profiler from configuration&#xA;&#xA;&#x9;You can now disable the profiler by setting:&#xA;&#xA;&#x9;&lt;add key=&quot;HibernatingRhinos.Profiler.Appender.NHibernate&quot; value=&quot;Disabled&quot; /&gt;&#xA;&#xA;&#x9;&#xA;&#xA;&#xA;&#x9;This will avoid initializing the profiler, obviously. The intent is that you can setup production profiling, disable it by default, and enable it selectively if you need to actually figure things out.&#xA;&#xA;&#x9;Odds &amp; ends&#xA;&#xA;&#x9;We move to WebActivatorEx&#xA0; from the deprecated WebActivator, added xml file for the appender, fixed a whole bunch of small bugs, the most important among them is:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;&#xA0;&#xA;&#xA;&#x9;Linq to SQL, Hibernate and LLBLGen Profilers, RIP&#xA;&#xA;&#x9;You might have noticed that I talked only about NHibernate and Entity Framework Profilers. The sales for the rests weren&#x2019;t what we hoped they would be, and we are no longer going to sale them.&#xA;&#xA;&#x9;Go get them, there is a new release discount&#xA;&#xA;&#x9;You can get the NHibernate Profiler and Entity Framework Profiler for a 15% discount for the next two weeks.</p>
        </article>
        <article id="article-3747">
            <a href="https://ayende.com/blog/169123/the-process-of-performance-problem-fixes-with-ravendb" target="_blank">
                <h2 class="title mb-6" id="article-3747">The process of performance problem fixes with RavenDB</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 03, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This post isn&#x2019;t so much about this particular problem, but about the way we solved this.&#xA;&#xA;&#x9;We have a number of ways to track performance problems, but this is a good example, we can see that for some reason, this test has failed because it took too long to run:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;In order to handle that, I don&#x2019;t want to run the test, I don&#x2019;t actually care that much about this. So I wanted to be able to run this independently.&#xA;&#xA;&#x9;To do that, I added:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;This opens us the studio with all the data that we have for this test. Which is great, since this means that we can export the data.&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;That done, we can import it to an instance that we control, and start testing the performance.&#xA0; In particular, we can run in under a profiler, to see what it is doing.&#xA;&#xA;&#x9;The underlying reason ended up being an issue with how we flush things to disk, which was easily fixed once we could narrow it down. The problem was just getting it working in a reproducible manner. This approach, being able to just stop midway through a test and capture the full state of the system is invaluable in troubleshooting what is going on.</p>
        </article>
        <article id="article-3748">
            <a href="https://ayende.com/blog/169473/transactions-are-a-figment-of-your-imagination" target="_blank">
                <h2 class="title mb-6" id="article-3748">Transactions are a figment of your imagination</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 02, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This post is in response for a few comments here. In particular, I get the sense that people expect businesses and systems to behave as if transactions are a real thing. The only problem here is that this is quite far from the truth. Let me define what I mean by a transaction here. I&#x2019;m not talking about database transactions, ACID or any such thing. I&#x2019;m talking about the notion that any interaction between a user and a business, or between two businesses can actually be modeled with the notion of a transaction similar to what we see in databases. That is, that we have an interaction that would either be all there, or won&#x2019;t be there at all. The most obvious example is the notion of financial transaction, the notion that we debit an account and then we credit another account. And we have to do that in such a way that either both accounts were modified or none of them were modified. That is the classic example for database transactions, and it is wrong. As anyone who ever wrote a check or sent an wire money transfer can tell. A good discussion on how that actually works can be found here. Note that in this case, the way money transfer works, in the real world, is that you upload a file over FTP, then wait three to five days to see if the orders your sent were rejected.  Another example is the notion of accepting an order, in a transactional manner. If I accepted your order, after verifying that I have reserved everything, and my warehouse burned down, what do I do with your order? I can hardly roll it back. To move away from businesses, let us consider doing something as unimportant as voting in a national election. Logically speaking, this is a pretty simple process. Identify the voter, record their vote, total the votes, select winner. Except that you can go back and force a re-election in a particular district if such is needed, or you might find a box of lost votes, or any of a hundred evil little things that crop up in the real world.  Any attempt to model such systems in neat transactional boxes with &#x201C;all in or none at all&#x201D; is going to break.</p>
        </article>
        <article id="article-3749">
            <a href="https://ayende.com/blog/169185/lies-service-level-agreements-trust-and-failure-mores" target="_blank">
                <h2 class="title mb-6" id="article-3749">Lies, Service Level Agreements, Trust and failure mores</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: December 01, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I had a very interesting discussion with Kelly Sommers in twitter. But 140 characters isn&#x2019;t really enough to explain things. Also, it is interesting topic in general. Kelly disagreed with this post: http://www.shopify.ca/technology/14909841-kafka-producer-pipeline-for-ruby-on-rails  You can read the full discussion here. The basic premise is, there is a highly reliable distributed queue that is used to process messages, but because they didn&#x2019;t have operational experience with this, they used a local queue to store the messages sending them over the network. Kelly seems to think that this is decreasing reliability. I disagree. The underlying premise is simple, when do you consider it acceptable to lose a message. If returning an error to the client is fine, sure, go ahead and do that if you can&#x2019;t reach the cluster. But if you are currently processing a 10 million dollar order, that is going to kinda suck, and anything that you can do to reduce the chance of that happening is good. Note that key part in this statement, we can only reduce the chance of this happening, we can&#x2019;t ensure it.  One way to try that is to get a guaranteed SLA from the distributed queue. Once we have that, we can rely that it works. This seems to be what Kelly is aiming at:  And that is true, if you could rely on SLAs. Just this week we had a multi hour, multi region Azure outage. In fact, outages, include outages that violate SLAs are unfortunately common.  In fact, if we look at recent history, we have:  February 2012 &#x2013; Azure &#x2013; incorrect leap year calculation took down multiple regions. October 2012 &#x2013; AWS &#x2013; memory leak due to misconfiguration took down a single availability zone, API throttling caused other availability zones to be affected. December 2012 &#x2013; AWS &#x2013; a developer was running against production, and delete some key data, resulting in Netflix (among others) being unable to stream video. August 2013 &#x2013; Azure &#x2013; more servers brought online to increase capacity caused a misconfigured network appliance to believe that it is under attack, resulting in Azure Europe going dark. There are actually more of them, but I think that 5 outages in 2 years is enough to show a pattern. And note specifically that I&#x2019;m talking about global outages like the ones above. Most people don&#x2019;t realize that complex systems operate in a constant mode of partial failure. If you ever read an accident investigative report, you&#x2019;ll know that there is almost never just a single cause of failure. For example, the road was slippery and the driver was speeding and the ABS system failed and the road barrier foundation rotted since being installed. Even a single change in one of those would mitigate the accident from a fatal crash to didn&#x2019;t happen to a &#x201C;honey, we need a new car&#x201D;. You can try to rely on the distribute queue in this case, because it has an SLA. And Toyota also promises that your car won&#x2019;t suddenly accelerate into a wall, but if you had a Toyota Camry in 2010&#x2026; well, you know&#x2026; From my point of view, saving the data locally before sending over the network makes a lot of sense. In general, the local state of the machine is much more stable than than the network. And if there is an internal failure in the machine, it is usually too hosed to do anything about anyway. I might try to write to disk, and write to the network even if I can&#x2019;t do that ,because I want to do my utmost to not lose the message.  Now, let us consider the possible failure scenarios. I&#x2019;m starting all of them with the notion that I just got a message for a 10 million dollars order, and I need to send it to the backend for processing.  We can&#x2019;t communicate with the distributed queue. That can be because it is down, hopefully that isn&#x2019;t the case, but from our point of view, if our node became split from the network, this has the same effect. We are writing this down to disk, so when we become available again, we&#x2019;ll be able to forward the stored message to the distributed queue. We can&#x2019;t communicate with the disk, maybe it is full, or there is an error, or something like that .We can still talk to the network, so we place it in the distributed queue, and we go on with our lives. We can&#x2019;t communicate with the disk, we can&#x2019;t communicate with the network. We can&#x2019;t keep it in memory (we might overflow the memory), and anyway, if we are out of disk and network, we are probably going to be rebooted soon anyway. SOL, there is nothing else we can do at this point. Note that the first case assumes that we actually do come back up. If the admin just blew this node away, then the data on that node isn&#x2019;t coming back, obviously. But since the admin knows that we are storing things locally, s/he will at least try to restore the data from that machine. We are safer (not safe, but more safe than without it). The question is whatever this is worth it? If your messages aren&#x2019;t actually carrying financial information, you can probably just drop a few messages as long as you let the end user know about that, so they can retry. If you really care about each individual message, if it is important enough to go the extra few miles for it, then the store and forward model gives you a measurable level of extra safety.</p>
        </article>
        <article id="article-3750">
            <a href="https://ayende.com/blog/169377/the-bug-that-ruined-my-weekend" target="_blank">
                <h2 class="title mb-6" id="article-3750">The bug that ruined my weekend</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: November 29, 2014
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This is bloody strange. I have a test failing in our unit tests, which isn&#x2019;t an all too uncommon occurrence after a big work. The only problem is that this test shouldn&#x2019;t fail, no one touched this part. For reference, here is the commit where this is failing. You can reproduce this by running the Raven.Tryouts console project. Note that it has to be done in Release mode. When that happens, we consistently get the following error:  Unhandled Exception: System.NullReferenceException: Object reference not set to an instance of an object.   at Raven.Client.Connection.MultiGetOperation.&lt;TryResolveConflictOrCreateConcurrencyException&gt;d__b.MoveNext() in c:\Work\ravendb\Raven.Client.Lightweight\Connection\MultiGetOperation.cs:line 156--- End of stack trace from previous location where exception was thrown ---   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&#xA;Here is the problem with this stack trace:&#xA;&#xA;Now, this only happens in release mode, but it happens there consistently. Now, I&#x2019;ve verified that this isn&#x2019;t an issue of me running old version of the code. So this isn&#x2019;t possible. There is no concurrency going on, all the data this method is touching is only touched by this thread. &#xA;What is more, the exception is not thrown from inside the foreach loop in line 139. I&#x2019;ve verified that by putting a try catch around the inside of the loop and still getting the NRE when thrown outside it. In fact, I have tried to figure it out in pretty much any way I can. Attaching a debugger make the problem disappear, as does disabling optimization, or anything like that.&#xA;In fact, at this point I&#x2019;m going to throw up my hands in disgust, because this is not something that I can figure out. Here is why, this is my &#x201C;fix&#x201D; for this issue. I replaced the following failing code:&#xA;&#xA;With the following passing code:&#xA;&#xA;And yes, this should make zero difference to the actual behavior, but it does. I&#x2019;m suspecting a JIT issue.</p>
        </article>
        <div class="button flex justify-between">
            <a href="374.html"><span class="back arrow"></span></a>

            <a href="376.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>

<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">© Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;🚀&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="about.html"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="/pagefind/pagefind-ui.js"></script>

<!-- Cookie Consent Banner -->
<div class="cookie-consent" id="cookieConsent">
    <div>
        <p class="text-sm">We use cookies to analyze our website traffic and provide a better browsing experience. By
            continuing to use our site, you agree to our use of cookies.</p>
    </div>
    <div class="cookie-consent-buttons">
        <button class="cookie-consent-decline" onclick="declineCookies()">Decline</button>
        <button class="cookie-consent-accept" onclick="acceptCookies()">Accept</button>
    </div>
</div>

<script>
    // Cookie consent management
    function showCookieConsent() {
        const consent = localStorage.getItem('cookieConsent');
        if (!consent) {
            document.getElementById('cookieConsent').classList.add('show');
        }
    }

    function acceptCookies() {
        localStorage.setItem('cookieConsent', 'accepted');
        document.getElementById('cookieConsent').classList.remove('show');
        loadGA(); // Load Google Analytics after consent
    }

    function declineCookies() {
        localStorage.setItem('cookieConsent', 'declined');
        document.getElementById('cookieConsent').classList.remove('show');
    }

    // Show the consent banner only for EU visitors (you can add more country codes as needed)
    fetch('https://ipapi.co/json/')
            .then(response => response.json())
            .then(data => {
                const euCountries = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE'];
                if (euCountries.includes(data.country_code)) {
                    showCookieConsent();
                } else {
                    // For non-EU visitors, automatically load GA
                    if (!localStorage.getItem('cookieConsent')) {
                        localStorage.setItem('cookieConsent', 'accepted');
                        loadGA();
                    }
                }
            })
            .catch(() => {
                // If we can't determine location, show the consent banner to be safe
                showCookieConsent();
            });
</script>
</body>
</html>
