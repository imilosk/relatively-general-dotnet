
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Home â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<script>
    const lightModePref = window.matchMedia("(prefers-color-scheme: light)");

    function getUserPref() {
        const storedTheme = typeof localStorage !== "undefined" && localStorage.getItem("theme");
        return storedTheme || (lightModePref.matches ? "light" : "dark");
    }

    function setTheme(newTheme) {
        if (newTheme !== "light" && newTheme !== "dark") {
            return console.warn(
                `Invalid theme value '${newTheme}' received. Expected 'light' or 'dark'.`,
            );
        }

        const root = document.documentElement;

        // root already set to newTheme, exit early
        if (newTheme === root.getAttribute("data-theme")) {
            return;
        }

        root.setAttribute("data-theme", newTheme);

        const colorThemeMetaTag = document.querySelector("meta[name='theme-color']");
        const bgColour = getComputedStyle(document.body).getPropertyValue("--theme-bg");
        colorThemeMetaTag.setAttribute("content", `hsl(${bgColour})`);
        if (typeof localStorage !== "undefined") {
            localStorage.setItem("theme", newTheme);
        }
    }

    // initial setup
    setTheme(getUserPref());

    document.addEventListener("DOMContentLoaded", function () {
        document.getElementById("theme-toggle").addEventListener("click", () => {
            const theme = localStorage.getItem("theme");

            if (theme === "dark") {
                setTheme("light");
            } else {
                setTheme("dark");
            }
        });

        document.getElementById("toggle-navigation-menu").addEventListener("click", (e) => {
            const button = e.target;
            const ariaExpanded = button.getAttribute("aria-expanded");
            const header = document.getElementById("main-header");

            if (ariaExpanded === "true") {
                button.setAttribute("aria-expanded", "false");
                header.classList.remove("menu-open");
            } else {
                button.setAttribute("aria-expanded", "true");
                header.classList.add("menu-open");
            }
        });
    });
</script>

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <theme-toggle class="ms-auto">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main">
    <section aria-label="Blog post list">
        <a href="https://ayende.com/blog/169474/gossip-much-use-cases-and-bad-practices-for-gossip-protocols" target="_blank"><h1 class="title mb-6">Gossip much? Use cases and bad practices for gossip protocols</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 18, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">My previous few posts has talked about specific algorithms for gossip protocols, specifically: HyParView and Plumtrees. They dealt with the technical behavior of the system, the process in which we are sending data over the cluster to all the nodes. In this post, I want to talk a bit about what kind of messages we are going to send in such a system. The obvious one is to try to keep the entire state of the system up to date using gossip. So whenever we make a change, we gossip about it to the entire network, and we are able to get to an eventually consistent system in which all nodes have roughly the same data. There is one problem with that, you now have a lot of nodes with the same data on them. At some point, that stop making sense. Usually gossip is used when you have a large group of servers, and just keep all the data on all the nodes is not a good idea unless your data set is very small. So you don&#x2019;t do that.&#xA0; Gossip is usually used to disseminate a small data set, one that can fit comfortably inside a single machine (usually it is a very small data set, a few hundred MB at most). Let us consider a few types of messages that would fit in a gossip setting. The obvious example is the actual topology of the whole network. A node joining up the cluster will announce its presence, and that will percolate to the entire cluster, eventually. That can allow you to have an idea (note, this isn&#x2019;t a certainty) about what is the structure of the cluster, and maybe make decisions based on it. The system wide configuration data is also a good candidate for gossip, for example, you can use gossip as a distributed service locator in the cluster. Whenever a new SMTP server comes online, it announces itself via gossip to the cluster. It is added to the list of SMTP servers in all the nodes that heard about it, and then it get used. In this kind of system, you have to take into account that servers can be down for a long period of time, and miss up on messages. Gossip does not guarantee that the messages will arrive, after all. Oh, it is going to do its best, but you need to also build an anti entropy system. If a server finds that it missed up on too much, it can request one of its peers to send it a full snapshot of the current global state as that peer know it. Going in the same vein, nodes can gossip about the health state of the network. If I&#x2019;m trying to send an email via an SMTP server, and it is down, I&#x2019;m going to try another server, and let the network know that I&#x2019;ve failed to talk to that particular server. If enough nodes fail to communicate with the server, that become part of the state of the system, so nodes that learned about it can avoid that server for a period of time. Moving into a different direction, you can also do gossip queries, that can be done by sending a gossip message on the cluster with a specific query to it. A typical example might be &#x201C;which node has a free 10GB that I can use?&#x201D;. Such queries typically carry with them a timeout element. You send the query, and any matches are sent back to (either directly or also via gossip). After a predefined timeout, you can assume that you got all the replies that you are going to get, so you can operate on that. More interesting is when you want to query for the actual data held in each node. If we want to find all the users who logged in today, for example.  The problem with doing something like that is that you might have a large result set, and you&#x2019;ll need to have some way to work with that. You don&#x2019;t want to send it all to a single destination, and what would you do with it, anyway? For that reason, most of the time gossip queries are actually aggregation. We can use that to get an estimate of certain things in our cluster. If we wanted to get the number of users per country, that would be a good candidate for this, for example. Note that you won&#x2019;t necessarily get accurate results, if you have failures, so there are aggregation methods for getting a good probability of the actual value.  For fun, here is an interesting exercise. Look at trending topics in a large number of conversations. In this case, whenever you would get a new message, you would analyze the topics for this message, and periodically (every second, let us say), you&#x2019;ll gossip to your peers about this. In this case, we don&#x2019;t just blindly pass the gossip between nodes. Instead, we&#x2019;ll use a slightly different method. Each second, every node will contact its peers to send them the current trending topics in the node. Each time the trending topics change, a version number is incremented. In addition, the node also send its peer the node ids and versions of the messages it got from other nodes. The peer, in reply, will send a confirmation about all the node ids and versions that it has. So the origin node can fill in about any new information that it go, or ask to get updates for information that it doesn&#x2019;t have. This reduce the number of updates that flow throughout the cluster, while still maintain an eventually consistent model. We&#x2019;ll be able to tell, from each node, what are the current trending topics globally.</p>
        <a href="https://ayende.com/blog/169442/gossip-much-operating-with-partial-information-and-getting-the-right-result" target="_blank"><h1 class="title mb-6">Gossip much? Operating with partial information, and getting the right result.</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 17, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Unlike the previous two posts, this is going to be short. Primarily because what I wanted to talk about it what impresses me most with both HyParView and Plumtree. The really nice thing about them is that they are pretty simple, easy to understand and produce good results. But the fun part, and what make it impressive is that they manage to achieve that with a small set of simple rules, and without any attempt to create a global view. They operate just fine with potentially very small set of the data overall, but still manage to operate, self optimize and get to the correct result. In fact, I did some very minor attempts to play with this at large scale, and we see a pretty amazing emergent behavior. Without anyone knowing what is going on globally, we are able to get to the optimal number of interactions in the cluster to distribute information.  That is really pretty cool. And because this post is too short, I&#x2019;ll leave you with a question. Given that you have this kind of infrastructure, what would you do with it? What sort of information or operations would you try to send using this way?</p>
        <a href="https://ayende.com/blog/169569/inside-ravendb-book-chapter-8-is-done" target="_blank"><h1 class="title mb-6">Inside RavenDB Book&#x2013;Chapter 8 is done</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 16, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Chapter 8 talks about indexing, this time from the point of view of what you can do with them, and how to best utilize them. You can read it here: https://github.com/ayende/book/releases/</p>
        <a href="https://ayende.com/blog/169441/gossip-much-the-gossip-epidemic-and-other-issues-in-polite-society" target="_blank"><h1 class="title mb-6">Gossip much? The gossip epidemic and other issues in polite society</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 15, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In my previous post, I talked about the Hybrid Partial View protocol, and showed a visualization about how it actually works. Something that is important to note about this protocol, it is mostly meant to create a gossip topology that is resilient to failure. It is not meant to actually send messages, it is meant to serve as the backbone topology (the peer sampling service) for figuring out what are the nodes. The reason for that can be seen in the following 10 node cluster (after running heartbeat enough times to get to a stable state:   Let us assume that we want to disseminate a message across the cluster. We select node A as our root, and then send a message. The rules are as follow:  Each node send the message to all its active connections (except the sender, of course).  A node that got the same message twice will ignore the message. Based on those rules, and the topology above, we&#x2019;re going to have the following chain of messages:  F &#x2013; initial broadcast F -&gt; E, G, J E -&gt; G, I G -&gt; E, H J -&gt; I, H, J H -&gt; C, I C -&gt; B, A B -&gt; D, A A -&gt; B, D D -&gt; A The total number of messages passed is 20. Which is twice as much as the optimal solution would generate. What is worse, this is a very small network, and as the network grows, so will the number of redundant messages. This approach (called eager gossiping) has a major advantage, because it will traverse all paths in the graph, it will also traverse all the shortest paths. That means that the time to get a message from the origin to all nodes is the smallest, but the number of operations is high. The Plumtree paper (Epidemic Broadcast Trees) presents a solution to this problem. It tries to minimize the number of messages while still maintaining both reliability and optimizing the number of messages that are passed as well as the distance they have to pass. The way Plumtree works is explained in quite beautiful detail in the paper, but the underlying idea goes like this, we start using the same approach as the eager gossiping, but whenever we get a message that we already got, we will reply to the source and tell it to stop sending us further messages. This is done so the next time that a message will be sent, we can skip the known duplicate path, and reduce the number of overall messages that we have. So the first run is going to generate 20 messages on the network. The second is going to generate just 13, you can see the non traversed paths in the following image:  Note that we didn&#x2019;t pass any messages between I and J, or D and A. But a lot of the saving was achieved by avoiding duplicate notifications. So node I notified node H, but not vice versa. The next time we&#x2019;ll run this, we have exactly 10 messages passing:  Now, obviously this is pretty cool, but that is under a stable state. What happens when they are failures? Well, at that point, the notion of lazy vs. eager peers come into play. One of the things we did initially was to clear the duplicate paths in the network, so we can optimize the number of messages being passed. That is pretty cool, but it also leave us vulnerable to failures. For example, imagine that nod H is down. What happens then? There are two aspects of this that are interesting. Plumtrees only care about the notion of message passing. They don&#x2019;t deal with topology changes. In this case, the responsibility to join the different parts of the network lies with the peer sampling service, which is HyParView in this case. That would figure out the communication issue, and forge new connections with the remaining nodes. Plumtree will get notified about that, and the process continue. But let us leave that one aside, let us say that we have a static topology, how would Plumtree handle this? Well, at this point you have to realize that Plumtree doesn&#x2019;t just drop a connection when a node tell it that it already heard about a message. It just move it to a lazy state. Periodically, a node will contact other nodes which told it that it wasn&#x2019;t needed and tell them: &#x201C;Hi, I got messages with ids (43,41,81), do you have them?&#x201D;. In this way, a node whose contact point went down would become aware that there are missing messages. At that point, it start a timer, and if it didn&#x2019;t hear about those missing messages, it will ask the node that told it about those messages to send them over, and initiate an active link. The end result here is that we send additional messages, but those tend to be pretty small, just the message ids.   During steady state, we&#x2019;ll just ignore those messages, but if there is a failure, they can help us recover from errors by letting us know that there are messages that we are missing, and taking action to recover that. There is also another important aspect of this behavior, detecting and circumventing slow nodes. If a node is slow to distribute messages to its peers, other nodes will notify those peers that those messages exists, and if that is the case, we&#x2019;ll eventually move to a more efficient topology by routing around that slow node. You can see a full visualization of that (and admire my rapidly improving UI skills) here. The JavaScript implementation of the algorithm is here. Plumtree has a few weaknesses, mostly it is that it is optimized for a single source topology. In other words, the first node you start from will influence the optimization of the network, and if you start a broadcast from another node, it won&#x2019;t be an optimal operation. That said, there are a few ways to handle that. The actual topology remains the same, what influence Plumtree is the rejection replies from nodes that say that the information it transmitted was already received. We can keep track on not only the nodes that rejected us, but the root source of that rejection, so a message originating in E wouldn&#x2019;t stop us from propagating a message originating in J.  Because Plumtree is meant for very large clusters (the paper talks about testing this with 10,000 nodes), and you might have a message originate from any one of those, you probably want to limit the notion of &#x201C;origin&#x201D;, if you track the past three nodes it passed through, you get a reasonably small amount of data that you have to keep, and it is likely to be accurate enough to build multiple topologies that will optimize themselves based on actual conditions. That is it for this post, I&#x2019;ve got a couple more posts that I want to write about gossips, but that would be it for today.</p>
        <a href="https://enterprisecraftsmanship.com/posts/io-threads-explained/" target="_blank"><h1 class="title mb-6">I/O Threads Explained</h1></a>
        <p class="mb-2">by Vladimir Khorikov</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 13, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Microsoft has released async/await feature in .Net 4.5. It&#x2019;s a really great stuff as it significantly simplifies one of the most painful areas - asynchronous programming. Before that, Task Parallel Library (TPL) and Parallel LINQ (PLINQ) were released in .Net 4.0. They address problems with parallel programming - another painful area in .Net.&#xA;&#xA;&#xA;I often see programmers struggling with a question when to use each of these features. Let&#x2019;s step back and recall what does it actually mean to be asynchronous or parallel.</p>
        <a href="https://ayende.com/blog/169410/gossip-much-disseminating-information-among-high-number-10k-of-nodes" target="_blank"><h1 class="title mb-6">Gossip much? Disseminating information among high number (10K) of nodes</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 12, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Every once in a while, I like to sit down and read about what is going on outside my current immediate field of interest. This weekend, I chose to focus on efficient information dissemination with very large number of nodes.&#xA;&#xA;&#x9;The articles of interests for this weekend are HyParView and Epidemic Broadcast Trees (Plumtrees). There are a great read, and complement one another to a nice degree. HyParView is an algorithm that seeks to connect a set (of potentially very large number) of nodes together without trying to make each node connect to each other node. To simplify things, I&#x2019;m going to talk about clusters of several dozens nodes, the articles have both been tested to the 10,000 nodes and with failure rates of up to 95% of the network. This post is here so I can work out the details in my mind, it may be that I&#x2019;m wrong, so don&#x2019;t try to treat this as a definitive source.&#xA;&#xA;&#x9;Let us assume that we have a network with 15 nodes in it. And we want to add a new node. One way of doing that would be to maintain a list of all the nodes in the system (that are what admins are for, after all) and have the node connect to all the other nodes. In this way, we can communicate between all the nodes very easily. Of course, that means that the number of connections we have in a network of 16(15&#x2B; new) nodes is 120. And that utterly ignore the notion of failure. But let us continue with this path, to see what unhappy landscape it is going to land us on.&#xA;&#xA;&#x9;We have a 15 node cluster, and we add a new node (so we have to give it all the other nodes), and it connects to all the other nodes and register with them. So far, so good. Now, let us say that there is a state change that we want to send to all the nodes in the network. We can do that by connecting to a single node, and having it distribute this information to all the other nodes. Cost of this would be 16 (1 to talk to the first node, then 15 for it to talk to the rest). That is very efficient, and it is easy to prove that this is indeed the most optimal way to disseminate information over the network (each node is only contacted once).&#xA;&#xA;&#x9;In a 16 node network, maybe that is even feasible. It is a small cluster, after all. But that is a big maybe, and I wouldn&#x2019;t recommend it. If we grow the cluster size to a 100 node cluster, that gives us about 4,950(!) connections between all nodes, and the cost of sending a single piece of information is still the optimal N. But I think that this is easy to see that this isn&#x2019;t the way to go about it. Mostly because you can&#x2019;t do that, not even for the 16 node cluster. Usually when we talk about clusters we like to think about them as flat topologies, but that isn&#x2019;t actually how it goes. Let us look at a better approximation of a real topology:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;Yes, this isn&#x2019;t quite right, but it is good enough for our purposes.&#xA;&#xA;&#x9;In this 16 node cluster, we have the green node, which is the one we initially contact to send some data to the entire cluster. What would happen if we tried to talk from that node to all the other nodes? Well, notice how much load it would place on the green&#x2019;s node router. Or the general cost for the network in the area of the green node. Because of that, just straight on direct connection for the entire cluster is no something that you really want to do.&#xA;&#xA;&#x9;An alternative to do that, assuming that you have a fixed topology is to create a static tree structure, so you start with the green node, it then contacts three other nodes, who then each contact four other nodes. We still have the nice property so that each node is only getting the new information once. But we can parallelize the communication and reduce the load on a single segment of the network.&#xA;&#xA;&#x9;Which is great, if we have a static topology and zero failures. In practice, none of those is true, so we want something else, and hopefully something that would make this a lot easier to handle. This is where HyParView comes into play. I sat down and wrote a whole big description of how HyParView works, but it wasn&#x2019;t something that you couldn&#x2019;t get from the article. And one of the things that I did along the way was create a small implementation in JavaScript and plug this into a graph visualization, so I could follow what is going on there.&#xA;&#xA;&#x9;&#xA0;&#xA;&#xA;&#x9;That means that I had to implement the HyParView protocol in JavaScript, but it turned out to be a great way to actually explore how the thing works, and it ended up with great visualization.&#xA;&#xA;&#x9;You can see it in action in this url, and you can read the actual ocde for the HyParView protocol here.&#xA;&#xA;&#x9;Here is the cluster at 5 nodes, just after we added E:&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;And here it is at 9 nodes, after it had a chance to be stable.&#xA;&#xA;&#x9;&#xA;&#xA;&#x9;Note that we have the connections (active view) from each node to a up to 3 other nodes, but we also have other letters next to the node name, in []. That is the passive list, the list of nodes that we are not connected to, but will try if our connection to the one of the active list goes down.&#xA;&#xA;&#x9;In addition to just adding themselves to one of the nodes, the nodes will also attempt to learn the topology of the network in such a way that if there is a failure, they can recover from it. The JavaScript code I wrote is not a good JavaScript code, that isn&#x2019;t my forte, but it should be enough to follow what is going on there. We are able to do very little work to have a self organizing system of nodes that discover the network.&#xA;&#xA;&#x9;Note that in large networks, none of the nodes would have the full picture of the entire network, but each node will have a partial view of it, and that is enough to send a message through the entire network. But I&#x2019;m going to talk about this in another post.&#xA;&#xA;&#x9;In the meantime, go to&#xA0;this url&#xA0;and see it in action, (the actual ocde for the HyParView protocol&#xA0;here). Note that I&#x27;ve made the different action explicit, so you need to do heartbeats (and the algorithm relies on them for healing failures) to get proper behavior for the system. I&#x27;ve also created a predictable RNG, so we can always follow the same path in our iterations.</p>
        <a href="https://ayende.com/blog/169537/end-of-year-discount-for-all-our-products" target="_blank"><h1 class="title mb-6">End of year discount for all our products</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 11, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">To celebrate the new year, we offer a 21% discount for all our products. This is available for the first 33 customers that use the coupon code: 0x21-celebrate-new-year&#xA;&#xA;&#x9;In previous years, we offered a similar number of uses for the coupon code, and they run out fast, so hurry up. This offer is valid for:&#xA;&#xA;&#x9;&#xA;&#x9;&#x9;RavenDB&#xA;&#x9;&#xA;&#x9;&#x9;NHibernate Profiler&#xA;&#x9;&#xA;&#x9;&#x9;Entity Framework Profiler&#xA;&#xA;&#xA;&#x9;Happy Holidays and a great new years.&#xA;&#xA;&#x9;On a personal note, this marks the full release of all our product lines, and it took an incredible amount of work. I&#x27;m very pleased that we have been able to get the new version out there and in your hands, and to have you start making use of the features that we have been working on for so long.</p>
        <a href="https://ayende.com/blog/169345/tail-feather-snapshots" target="_blank"><h1 class="title mb-6">Tail/Feather&#x2013;Snapshots</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 10, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">The Raft protocol gives us a stable replicated distributed log. In other words, all servers in the cluster will agree on all the committed entries to the log (both what they are, and in what position). We usually fill the logs in operations that a state machine will execute. In the Tail/Feather example, the commands are set/del operations on the key value store. Note that this doesn&#x2019;t mean that all servers will always have the same state. It is possible that a server (or set of servers) will have an outdated view of the log, but the log that they have will match up to the point that they have it. So, what is the problem? What happens when we have an active system? Well, every time that we make a modification, we&#x2019;ll add it to the log. That is all good and great, but what about the actual log? Well, it is going to stay there, we need it so we can catch up any new server that will join the cluster. But that means that over time, we are going to have an unbounded growth. Which isn&#x2019;t a very nice thing to have. Rachis handle this by asking the state machine to implement snapshots. A way to take the current state of the state machine and transmit it over the network. For example, assume that we have an entry full of these logs: { Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 2}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 3}&#xA;&#xA;// ...&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 300000}&#xA;&#xA;&#xA;The log for that is 300,000 entries long, but the current state of the machine:&#xA;{ &quot;users/1/login-attempts&quot;: 300000 }&#xA;Which is obviously much smaller. Rachis doesn&#x2019;t force a state machine to implement this, but if it isn&#x2019;t doing so, we can never clear the log. But implementing snapshots has its own problems.What about the actual cost of creating the snapshot? Imagine that we ask the state machine for a snapshot every 10,000 entries. In the example above, that would mean just writing out { &quot;users/1/login-attempts&quot;: 300000 } or whatever the actual current value is.&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/1/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/2/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/3/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;&#xA;// ...&#xA;&#xA;{ Op: &quot;Add&quot;, Key: &quot;users/300000/login-attempts&quot;, &quot;Value&quot;: 1}&#xA;&#xA;&#xA;Note that instead of having 300,000 changes to the same key, we are going to have 300,000 keys. In this case, writing the full list down on every snapshot is very expensive. That is what incremental backups are here to solve.&#xA0; We let Voron know that this is what we want by specifying:&#xA;options.IncrementalBackupEnabled = true;&#xA;&#xA;&#xA;And now it is time to define policies about taking snapshots. We are going to handle this using Voron full &amp; incremental snapshots. You can see the logic in the following code.&#xA;public void CreateSnapshot(long index, long term, ManualResetEventSlim allowFurtherModifications)&#xA;{&#xA;    // we have not snapshot files, so this is the first time that we create a snapshot&#xA;    // we handle that by asking voron to create a full backup&#xA;    var files = Directory.GetFiles(_storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;    Array.Sort(files, StringComparer.OrdinalIgnoreCase); // make sure we get it in sort order&#xA;    if (files.Any() == false)&#xA;    {&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;    string lastFullBackup = null;&#xA;    int fullBackupIndex = -1;&#xA;    for (int i = files.Length - 1; i &gt;= 0; i--)&#xA;    {&#xA;        if (!files[i].StartsWith(&quot;Full&quot;)) &#xA;            continue;&#xA;        fullBackupIndex = i;&#xA;        lastFullBackup = files[i];&#xA;        break;&#xA;    }&#xA;            &#xA;    if (lastFullBackup == null)&#xA;    {&#xA;        // this shouldn&#x27;t be the case, we must always have at least one full backup. &#xA;        // maybe user deleted it? We&#x27;ll do a full backup here to compensate&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;            &#xA;    var fullBackupSize = new FileInfo(lastFullBackup).Length;&#xA;    var incrementalBackupsSize = files.Skip(fullBackupIndex &#x2B; 1).Sum(f =&gt; new FileInfo(f).Length);&#xA;&#xA;    // now we need to decide whatever to do a full or incremental backup, doing incremental backups stop &#xA;    // making sense if they will take more space than the full backup. Our cutoff point is when it passes to 50%&#xA;    // size of the full backup.&#xA;    // If full backup size is 1 GB, and we have 25 incrmeental backups that are 600 MB in size, we need to transfer&#xA;    // 1.6 GB to restore. If we generate a new full backup, we&#x27;ll only need to transfer 1 GB to restore.&#xA;&#xA;    if (incrementalBackupsSize / 2 &gt; fullBackupSize)&#xA;    {&#xA;        DoFullBackup(index, term, allowFurtherModifications);&#xA;        return;&#xA;    }&#xA;&#xA;    DeleteOldSnapshots(files.Take(fullBackupIndex - 1));// delete snapshots older than the current full backup&#xA;&#xA;    var incrementalBackup = new IncrementalBackup();&#xA;    incrementalBackup.ToFile(_storageEnvironment,&#xA;        Path.Combine(_storageEnvironment.Options.BasePath, string.Format(&quot;Inc-{0:D19}-{1:D19}.Snapshot&quot;, index, term)),&#xA;        infoNotify: Console.WriteLine,&#xA;        backupStarted: allowFurtherModifications.Set);&#xA;}&#xA;&#xA;private void DoFullBackup(long index, long term, ManualResetEventSlim allowFurtherModifications)&#xA;{&#xA;    var snapshotsToDelete = Directory.GetFiles(_storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;&#xA;    var fullBackup = new FullBackup();&#xA;    fullBackup.ToFile(_storageEnvironment,&#xA;        Path.Combine(_storageEnvironment.Options.BasePath, string.Format(&quot;Full-{0:D19}-{1:D19}.Snapshot&quot;, index, term)),&#xA;        infoNotify: Console.WriteLine,&#xA;        backupStarted: allowFurtherModifications.Set&#xA;        );&#xA;&#xA;    DeleteOldSnapshots(snapshotsToDelete);&#xA;}&#xA;&#xA;private static void DeleteOldSnapshots(IEnumerable&lt;string&gt; snapshotsToDelete)&#xA;{&#xA;    foreach (var snapshot in snapshotsToDelete)&#xA;    {&#xA;        try&#xA;        {&#xA;            File.Delete(snapshot);&#xA;        }&#xA;        catch (Exception)&#xA;        {&#xA;            // we ignore snapshots we can&#x27;t delete, they are expected if we are concurrently writing&#xA;            // the snapshot and creating a new one. We&#x27;ll get them the next time.&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;Basically, we need to strike a balance between full and incremental backups. We do that by first taking a full backup, and then starting to take incremental backups until our incremental backups takes more than 50% of the full backup, at which point we are probably better off doing another full backup. Note that we use the event of a full backup to clear the old incremental and full backup files. &#xA;And with that, we can move to actually sending the snapshot over the wire. This is exposed by the GetSnapshotWriter() method. This just shell all the responsibility to the SnapshotWriter:&#xA;public ISnapshotWriter GetSnapshotWriter()&#xA;{&#xA;    return new SnapshotWriter(this);&#xA;}&#xA;&#xA;public class SnapshotWriter : ISnapshotWriter&#xA;{&#xA;    private readonly KeyValueStateMachine _parent;&#xA;&#xA;    private List&lt;FileStream&gt; _files = new List&lt;FileStream&gt;();&#xA;&#xA;    public SnapshotWriter(KeyValueStateMachine parent)&#xA;    {&#xA;        _parent = parent;&#xA;        var files = Directory.GetFiles(_parent._storageEnvironment.Options.BasePath, &quot;*.Snapshot&quot;);&#xA;        var fullBackupIndex = GetFullBackupIndex(files);&#xA;&#xA;        if (fullBackupIndex == -1)&#xA;            throw new InvalidOperationException(&quot;Could not find a full backup file to start the snapshot writing&quot;);&#xA;&#xA;        var last = Path.GetFileNameWithoutExtension(files[files.Length-1]);&#xA;        Debug.Assert(last != null);&#xA;        var parts = last.Split(&#x27;-&#x27;);&#xA;        if(parts.Length != 3)&#xA;            throw new InvalidOperationException(&quot;Invalid snapshot file name &quot; &#x2B; files[files.Length - 1] &#x2B; &quot;, could not figure out index &amp; term&quot;);&#xA;&#xA;        Index = long.Parse(parts[1]);&#xA;        Term = long.Parse(parts[2]);&#xA;&#xA;        for (int i = fullBackupIndex; i &lt; files.Length; i&#x2B;&#x2B;)&#xA;        {&#xA;            _files.Add(File.OpenRead(files[i]));&#xA;        }&#xA;    }&#xA;&#xA;    public void Dispose()&#xA;    {&#xA;        foreach (var file in _files)&#xA;        {&#xA;            file.Dispose();&#xA;        }&#xA;    }&#xA;&#xA;    public long Index { get; private set; }&#xA;    public long Term { get; private set; }&#xA;    public void WriteSnapshot(Stream stream)&#xA;    {&#xA;        var writer = new BinaryWriter(stream);&#xA;        writer.Write(_files.Count);&#xA;        foreach (var file in _files)&#xA;        {&#xA;            writer.Write(file.Name);            writer.Write(file.Length);&#xA;            writer.Flush();&#xA;            file.CopyTo(stream);&#xA;        }&#xA;    }&#xA;}&#xA;&#xA;&#xA;What is going on here? We get the snapshot files, and find the latest full backup, then we open all the files that we&#x2019;ll need for the snapshot (the last full backup and everything afterward). We need to open them in the constructor to lock them for deletion by the CreateSnapshot() method.&#xA;Then we just concatenate them all and send them over the wire. And getting them? That is pretty easy as well:&#xA;public void ApplySnapshot(long term, long index, Stream stream)&#xA;{&#xA;    var basePath = _storageEnvironment.Options.BasePath;&#xA;    _storageEnvironment.Dispose();&#xA;&#xA;    foreach (var file in Directory.EnumerateFiles(basePath))&#xA;    {&#xA;        File.Delete(file);&#xA;    }&#xA;&#xA;    var files = new List&lt;string&gt;();&#xA;&#xA;    var buffer = new byte[1024*16];&#xA;    var reader = new BinaryReader(stream);&#xA;    var filesCount = reader.ReadInt32();&#xA;    if (filesCount == 0)&#xA;        throw new InvalidOperationException(&quot;Snapshot cannot contain zero files&quot;);&#xA;    for (int i = 0; i &lt; filesCount; i&#x2B;&#x2B;)&#xA;    {&#xA;        var name = reader.ReadString();&#xA;        files.Add(name);&#xA;        var len = reader.ReadInt64();&#xA;        using (var file = File.Create(Path.Combine(basePath, name)))&#xA;        {&#xA;            file.SetLength(len);&#xA;            var totalFileRead = 0;&#xA;            while (totalFileRead &lt; len)&#xA;            {&#xA;                var read = stream.Read(buffer, 0, (int) Math.Min(buffer.Length, len - totalFileRead));&#xA;                if (read == 0)&#xA;                    throw new EndOfStreamException();&#xA;                totalFileRead &#x2B;= read;&#xA;                file.Write(buffer, 0, read);&#xA;            }&#xA;        }&#xA;    }&#xA;            &#xA;    new FullBackup().Restore(Path.Combine(basePath, files[0]), basePath);&#xA;&#xA;    var options = StorageEnvironmentOptions.ForPath(basePath);&#xA;    options.IncrementalBackupEnabled = true;&#xA;    //TODO: Copy any other customizations that might have happened on the options&#xA;&#xA;    new IncrementalBackup().Restore(options, files.Skip(1));&#xA;&#xA;    _storageEnvironment = new StorageEnvironment(options);&#xA;&#xA;    using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))&#xA;    {&#xA;        var metadata = tx.ReadTree(&quot;$metadata&quot;);&#xA;        metadata.Add(&quot;last-index&quot;, EndianBitConverter.Little.GetBytes(index));&#xA;        LastAppliedIndex = index;&#xA;        tx.Commit();&#xA;    }&#xA;}&#xA;&#xA;&#xA;Unpack the snapshots from the stream, then first apply a full backup, then all the incremental backups. Make sure to update the last applied index, and we are set .</p>
        <a href="https://ayende.com/blog/169249/tail-feather-the-client-api" target="_blank"><h1 class="title mb-6">Tail/Feather&#x2013;The client API</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 09, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">As I mentioned Tail/Feather is a weekend project to test out how stuff works for real. After creating the highly available distributed key/value store, we are now in need of actually building a client API for it. Externally, that API is going to look like this:  public class TailFeatherClient : IDisposable{    public TailFeatherClient(params Uri[] nodes);    public Task Set(string key, JToken value);    public Task&lt;JToken&gt; Get(string key);    public Task Remove(string key);    public void Dispose();}&#xA;If this wasn&#x2019;t a weekend project, I would add batch support, but that isn&#x2019;t important for our purposes right now. The API itself is pretty stupid, which is great, but what about the actual behavior?&#xA;We want it to be able to handle dynamic cluster changes, and we need it to be smart about it. A lot of that is shared among all operations, so the next layer of the API is:&#xA;&#xA;public Task Set(string key, JToken value){    return ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/set?key={0}&amp;val={1}&quot;,         Uri.EscapeDataString(key), Uri.EscapeDataString(value.ToString(Formatting.None)))));}public async Task&lt;JToken&gt; Get(string key){    var reply = await ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/del?key={0}&quot;,        Uri.EscapeDataString(key))));    var result = JObject.Load(new JsonTextReader(new StreamReader(await reply.Content.ReadAsStreamAsync())));    if (result.Value&lt;bool&gt;(&quot;Missing&quot;))        return null;    return result[&quot;Value&quot;];}public Task Remove(string key){    return ContactServer(client =&gt; client.GetAsync(string.Format(&quot;tailfeather/key-val/del?key={0}&quot;,        Uri.EscapeDataString(key))));}&#xA;The actual behavior is in ContactServer:&#xA;&#xA;&#xA;private readonly ConcurrentDictionary&lt;Uri, HttpClient&gt; _cache = new ConcurrentDictionary&lt;Uri, HttpClient&gt;();private Task&lt;TailFeatherTopology&gt; _topologyTask;public TailFeatherClient(params Uri[] nodes){    _topologyTask = FindLatestTopology(nodes);}private HttpClient GetHttpClient(Uri node){    return _cache.GetOrAdd(node, uri =&gt; new HttpClient { BaseAddress = uri });}private async Task&lt;TailFeatherTopology&gt; FindLatestTopology(IEnumerable&lt;Uri&gt; nodes){    var tasks = nodes.Select(node =&gt; GetHttpClient(node).GetAsync(&quot;tailfeather/admin/flock&quot;)).ToArray();    await Task.WhenAny(tasks);    var topologies = new List&lt;TailFeatherTopology&gt;();    foreach (var task in tasks)    {        var message = task.Result;        if (message.IsSuccessStatusCode == false)            continue;        topologies.Add(new JsonSerializer().Deserialize&lt;TailFeatherTopology&gt;(            new JsonTextReader(new StreamReader(await message.Content.ReadAsStreamAsync()))));    }    return topologies.OrderByDescending(x =&gt; x.CommitIndex).FirstOrDefault();}private async Task&lt;HttpResponseMessage&gt; ContactServer(Func&lt;HttpClient, Task&lt;HttpResponseMessage&gt;&gt; operation, int retries = 3){    if (retries &lt; 0)        throw new InvalidOperationException(&quot;Cluster is not reachable, or no leader was selected. Out of retries, aborting.&quot;);    var topology = (await _topologyTask ?? new TailFeatherTopology());            var leader = topology.AllVotingNodes.FirstOrDefault(x =&gt; x.Name == topology.CurrentLeader);    if (leader == null)    {        _topologyTask = FindLatestTopology(topology.AllVotingNodes.Select(x =&gt; x.Uri));        return await ContactServer(operation, retries - 1);    }    // now we have a leader, we need to try calling it...    var httpResponseMessage = await operation(GetHttpClient(leader.Uri));    if (httpResponseMessage.IsSuccessStatusCode == false)    {        // we were sent to a different server, let try that...        if (httpResponseMessage.StatusCode == HttpStatusCode.Redirect)        {            var redirectUri = httpResponseMessage.Headers.Location;            httpResponseMessage = await operation(GetHttpClient(redirectUri));            if (httpResponseMessage.IsSuccessStatusCode)            {                // we successfully contacted the redirected server, this is probably the leader, let us ask it for the topology,                // it will be there for next time we access it                _topologyTask = FindLatestTopology(new[] { redirectUri }.Union(topology.AllVotingNodes.Select(x =&gt; x.Uri)));                return httpResponseMessage;            }        }        // we couldn&#x27;t get to the server, and we didn&#x27;t get redirected, we&#x27;ll check in the cluster in general        _topologyTask = FindLatestTopology(topology.AllVotingNodes.Select(x =&gt; x.Uri));        return await ContactServer(operation, retries - 1);    }    // happy path, we are done    return httpResponseMessage;}&#xA;There is quite a bit going on here. But the basic idea is simple. Starting from the initial list of nodes we have, contact all of them and find the topology with the highest commit index. That means that it is the freshest, so more likely to be the current one. From the topology, we take the leader, and send all queries to the leader.&#xA;If there is any sort of errors, we&#x2019;ll contact all other servers to find who we are supposed to be using now. If we can&#x2019;t find it after three tries, we give us and we let the caller sort it out, probably by retrying once the cluster is in a steady state again.&#xA;Now, this is really nice, but it is falling into the heading of weekend code. That is means that this is quite far from what I would call production code. What is missing?&#xA;&#xA;Caching the topology locally in a persistent manner so we can restart when the known servers are down from last known good topology.&#xA;Proper error handling, and in particular, error reporting, to make sure that we can understand what is actually is going on.&#xA;Features such as allowing reads from non leaders, testing, etc.&#xA;But overall, I&#x2019;m quite happy with this.</p>
        <a href="https://ayende.com/blog/169218/tail-feather-highly-available-distributed-key-value-store-weekend-project" target="_blank"><h1 class="title mb-6">Tail/Feather&#x2013;highly available distributed key/value store weekend project</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: December 08, 2014
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Weekend project means just that, I&#x2019;m trying some things out, and writing something real is the best way to exercise. This isn&#x2019;t going to be a full blown project, but it should be functional and usable. The basic idea, I&#x2019;m going to build a distributed key/value configuration store. Similar to etcd, this will allow me to explore how to handle full blown Rachis from both server &amp; client sides. We want this to be a full&#xA0; blown implementation, which means persistence, snapshots, network api, the works. In terms of the data model, we&#x2019;ll go for the simplest possible one. A key/value store. A key is a string of up to 128 characters. A value is a json formatted value of up to 16Kb. Persistence will be handled by Voron. The persistent of the project is mostly Voron, so what we are left with is the following:   public enum KeyValueOperationTypes{    Add,    Del}public class KeyValueOperation{    public KeyValueOperationTypes Type;    public string Key;    public JToken Value;}public class OperationBatchCommand : Command{    public KeyValueOperation[] Batch { get; set; }}&#xA;This gives us the background for the actual state machine:&#xA;&#xA;public class KeyValueStateMachine : IRaftStateMachine{    readonly StorageEnvironment _storageEnvironment;    public KeyValueStateMachine(StorageEnvironmentOptions options)    {        _storageEnvironment = new StorageEnvironment(options);        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))        {            _storageEnvironment.CreateTree(tx, &quot;items&quot;);            var metadata = _storageEnvironment.CreateTree(tx, &quot;$metadata&quot;);            var readResult = metadata.Read(&quot;last-index&quot;);            if (readResult != null)                LastAppliedIndex = readResult.Reader.ReadLittleEndianInt64();            tx.Commit();        }    }    public event EventHandler&lt;KeyValueOperation&gt; OperatonExecuted;    protected void OnOperatonExecuted(KeyValueOperation e)    {        var handler = OperatonExecuted;        if (handler != null) handler(this, e);    }    public JToken Read(string key)    {        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.Read))        {            var items = tx.ReadTree(&quot;items&quot;);            var readResult = items.Read(key);            if (readResult == null)                return null;            return JToken.ReadFrom(new JsonTextReader(new StreamReader(readResult.Reader.AsStream())));        }    }    public long LastAppliedIndex { get; private set; }    public void Apply(LogEntry entry, Command cmd)    {        var batch = (OperationBatchCommand)cmd;        Apply(batch.Batch, cmd.AssignedIndex);    }        private void Apply(IEnumerable&lt;KeyValueOperation&gt; ops, long commandIndex)    {        using (var tx = _storageEnvironment.NewTransaction(TransactionFlags.ReadWrite))        {            var items = tx.ReadTree(&quot;items&quot;);            var metadata = tx.ReadTree(&quot;$metadata&quot;);            metadata.Add(&quot;last-index&quot;, EndianBitConverter.Little.GetBytes(commandIndex));            var ms = new MemoryStream();            foreach (var op in ops)            {                switch (op.Type)                {                    case KeyValueOperationTypes.Add:                        ms.SetLength(0);                        var streamWriter = new StreamWriter(ms);                        op.Value.WriteTo(new JsonTextWriter(streamWriter));                        streamWriter.Flush();                        ms.Position = 0;                        items.Add(op.Key, ms);                        break;                    case KeyValueOperationTypes.Del:                        items.Delete(op.Key);                        break;                    default:                        throw new ArgumentOutOfRangeException();                }                OnOperatonExecuted(op);            }            tx.Commit();        }    }    public void Dispose()    {        if (_storageEnvironment != null)            _storageEnvironment.Dispose();    }}&#xA;As you can see, there isn&#x2019;t much here. Not surprising, since we are storing a key/value data structure. I&#x2019;m also ignoring snapshots for now. That is good enough for now, let us go for the network portion of the work. We are going to be using Web API for the network stuff. And we&#x2019;ll be initializing it like so:&#xA;&#xA;var nodeName = options.NodeName ?? (Environment.MachineName &#x2B; &quot;:&quot; &#x2B; options.Port);var kvso = StorageEnvironmentOptions.ForPath(Path.Combine(options.DataPath, &quot;KeyValue&quot;));using (var statemachine = new KeyValueStateMachine(kvso)){    using (var raftEngine = new RaftEngine(new RaftEngineOptions(        new NodeConnectionInfo        {            Name = nodeName,            Url = new Uri(&quot;http://&quot; &#x2B; Environment.MachineName &#x2B; &quot;:&quot; &#x2B; options.Port),        },        StorageEnvironmentOptions.ForPath(Path.Combine(options.DataPath, &quot;Raft&quot;)),        new HttpTransport(nodeName),        statemachine        )))    {        using (WebApp.Start(new StartOptions        {            Urls = { &quot;http://&#x2B;:&quot; &#x2B; options.Port &#x2B; &quot;/&quot; }        }, builder =&gt;        {            var httpConfiguration = new HttpConfiguration();            RaftWebApiConfig.Register(httpConfiguration);            httpConfiguration.Properties[typeof(HttpTransportBus)] = new HttpTransportBus(nodeName);            httpConfiguration.Properties[typeof(RaftEngine)] = raftEngine;            builder.UseWebApi(httpConfiguration);        }))        {            Console.WriteLine(&quot;Ready &amp; processing requests, press ENTER to sop&quot;);            Console.ReadLine();        }    }}&#xA;Note that we need to initialize both the state machine and the raft engine, then wire the raft engine controllers. Now we are pretty much done with setup, and we can turn to the actual semantics of running the cluster. The first thing that I want to do is to setup the baseline, so we create this base controller:&#xA;&#xA;public abstract class TailFeatherController : ApiController{    public KeyValueStateMachine StateMachine { get; private set; }    public RaftEngine RaftEngine { get; private set; }    public override async Task&lt;HttpResponseMessage&gt; ExecuteAsync(HttpControllerContext controllerContext, CancellationToken cancellationToken)    {        RaftEngine = (RaftEngine)controllerContext.Configuration.Properties[typeof(RaftEngine)];        StateMachine = (KeyValueStateMachine)RaftEngine.StateMachine;        try        {            return await base.ExecuteAsync(controllerContext, cancellationToken);        }        catch (NotLeadingException)        {            var currentLeader = RaftEngine.CurrentLeader;            if (currentLeader == null)            {                return new HttpResponseMessage(HttpStatusCode.PreconditionFailed)                {                    Content = new StringContent(&quot;{ &#x27;Error&#x27;: &#x27;No current leader, try again later&#x27; }&quot;)                };            }            var leaderNode = RaftEngine.CurrentTopology.GetNodeByName(currentLeader);            if (leaderNode == null)            {                return new HttpResponseMessage(HttpStatusCode.InternalServerError)                {                    Content = new StringContent(&quot;{ &#x27;Error&#x27;: &#x27;Current leader &quot; &#x2B; currentLeader &#x2B; &quot; is not found in the topology. This should not happen.&#x27; }&quot;)                };            }            return new HttpResponseMessage(HttpStatusCode.Redirect)            {                Headers =                {                    Location = leaderNode.Uri                }            };        }    }}&#xA;That is a lot of error handling, but basically it just get the right values from the configuration and expose them to the controller actions, then a lot of error handling when we have a command that requires a leader that hit a follower. &#xA;Next step, actually managing the cluster, here we go:&#xA;&#xA;public class AdminController : TailFeatherController{    [HttpGet]    [Route(&quot;tailfeather/admin/fly-with-us&quot;)]    public async Task&lt;HttpResponseMessage&gt; Join([FromUri] string url, [FromUri] string name)    {        var uri = new Uri(url);        name = name ?? uri.Host &#x2B; (uri.IsDefaultPort ? &quot;&quot; : &quot;:&quot; &#x2B; uri.Port);        await RaftEngine.AddToClusterAsync(new NodeConnectionInfo        {            Name = name,            Uri = uri        });        return new HttpResponseMessage(HttpStatusCode.Accepted);    }    [HttpGet]    [Route(&quot;tailfeather/admin/fly-away&quot;)]    public async Task&lt;HttpResponseMessage&gt; Leave([FromUri] string name)    {        await RaftEngine.RemoveFromClusterAsync(new NodeConnectionInfo        {            Name = name        });        return new HttpResponseMessage(HttpStatusCode.Accepted);    }}&#xA;So now we have a way to add and remove items from the cluster, which is all the admin stuff that we need to handle right now. Next, we need to actually wire the operations, this is done here:&#xA;&#xA;public class KeyValueController : TailFeatherController{    [HttpGet]    [Route(&quot;tailfeather/key-val/read&quot;)]    public HttpResponseMessage Read([FromUri] string key)    {        var read = StateMachine.Read(key);        if (read == null)        {            return Request.CreateResponse(HttpStatusCode.NotFound, new            {                RaftEngine.State,                Key = key,                Missing = true            });        }        return Request.CreateResponse(HttpStatusCode.OK, new        {            RaftEngine.State,            Key = key,            Value = read        });    }    [HttpGet]    [Route(&quot;tailfeather/key-val/set&quot;)]    public Task&lt;HttpResponseMessage&gt; Set([FromUri] string key, [FromUri] string val)    {        JToken jVal;        try        {            jVal = JToken.Parse(val);        }        catch (JsonReaderException)        {            jVal = val;        }        var op = new KeyValueOperation        {            Key = key,            Type = KeyValueOperationTypes.Add,            Value = jVal        };        return Batch(new[] { op });    }    [HttpGet]    [Route(&quot;tailfeather/key-val/del&quot;)]    public Task&lt;HttpResponseMessage&gt; Del([FromUri] string key)    {        var op = new KeyValueOperation        {            Key = key,            Type = KeyValueOperationTypes.Del,        };        return Batch(new[] { op });    }    [HttpPost]    [Route(&quot;tailfeather/key-val/batch&quot;)]    public async Task&lt;HttpResponseMessage&gt; Batch()    {        var stream = await Request.Content.ReadAsStreamAsync();        var operations = new JsonSerializer().Deserialize&lt;KeyValueOperation[]&gt;(new JsonTextReader(new StreamReader(stream)));        return await Batch(operations);    }    private async Task&lt;HttpResponseMessage&gt; Batch(KeyValueOperation[] operations)    {        var taskCompletionSource = new TaskCompletionSource&lt;object&gt;();        RaftEngine.AppendCommand(new OperationBatchCommand        {            Batch = operations,            Completion = taskCompletionSource        });        await taskCompletionSource.Task;        return Request.CreateResponse(HttpStatusCode.Accepted);    }}&#xA;And we are pretty much set. &#xA;Note that I&#x2019;ve been writing this post while I&#x2019;m writing the code, so I&#x2019;ve made some small changes, you can see actual code here. &#xA;Anyway, we are pretty much done. Now we can compile and try testing what is going on.&#xA;First, we seed the cluster, but running:&#xA;&#xA;.\TailFeather.exe --port=9079 --DataPath=One --Name=One &#x2013;Bootstrap&#xA;This tell us that this node is allowed to become a leader without having to pre-configure a cluster. This command runs and exit, so now we&#x2019;ll run three such copies:&#xA;&#xA;start .\TailFeather.exe &quot;--port=9079 --DataPath=One --Name=One&quot;&#xA;start .\TailFeather.exe &quot;--port=9078 --DataPath=Two --Name=Two&quot;&#xA;start .\TailFeather.exe &quot;--port=9077 --DataPath=Three --Name=Three&quot;&#xA;We have all three nodes up and running, so now is the time to actually make use of it:&#xA;&#xA;http://localhost:9079/tailfeather/key-val/set?key=ravendb&amp;val={ &#x27;Url&#x27;: &#x27;http://live-test.ravendb.net&#x27;, &#x27;Database&#x27;: &#x27;Sample&#x27; }&#xA;In this case, you can see that we are setting a configuration value to point to a RavenDB database on the first node. Note that at this point, we have a single node cluster, and the two other are waiting to join it, but are taking no action.&#xA;We can get the value back using:&#xA;&#xA;So far, so good. Now, let us add a second node in by inviting it to fly with our cluster. We do that using the following command:&#xA;http://localhost:9079/tailfeather/admin/fly-with-us?url=http://localhost:9078&amp;name=Two&#xA;Which will give us:&#xA;&#xA;Note that we are using the just added node for too look at this.&#xA;Next, we can add the third node. &#xA;http://localhost:9079/tailfeather/admin/fly-with-us?url=http://localhost:9077&amp;name=Three&#xA;I would put the image in, but I think you get the point.&#xA;This is it for now. We have a highly available persistent &amp; distributed key/value store. Next, we need to tackle the idea of snapshots and the client API, but I&#x2019;ll deal with that at another post.</p>
        <div class="button flex justify-between">
            <a href="251.html"><span class="back arrow"></span></a>

            <a href="253.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2024<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
</body>
</html>