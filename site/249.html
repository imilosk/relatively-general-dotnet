
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Home â€¢ Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<script>
    const lightModePref = window.matchMedia("(prefers-color-scheme: light)");

    function getUserPref() {
        const storedTheme = typeof localStorage !== "undefined" && localStorage.getItem("theme");
        return storedTheme || (lightModePref.matches ? "light" : "dark");
    }

    function setTheme(newTheme) {
        if (newTheme !== "light" && newTheme !== "dark") {
            return console.warn(
                `Invalid theme value '${newTheme}' received. Expected 'light' or 'dark'.`,
            );
        }

        const root = document.documentElement;

        // root already set to newTheme, exit early
        if (newTheme === root.getAttribute("data-theme")) {
            return;
        }

        root.setAttribute("data-theme", newTheme);

        const colorThemeMetaTag = document.querySelector("meta[name='theme-color']");
        const bgColour = getComputedStyle(document.body).getPropertyValue("--theme-bg");
        colorThemeMetaTag.setAttribute("content", `hsl(${bgColour})`);
        if (typeof localStorage !== "undefined") {
            localStorage.setItem("theme", newTheme);
        }
    }

    // initial setup
    setTheme(getUserPref());

    document.addEventListener("DOMContentLoaded", function () {
        document.getElementById("theme-toggle").addEventListener("click", () => {
            const theme = localStorage.getItem("theme");

            if (theme === "dark") {
                setTheme("light");
            } else {
                setTheme("dark");
            }
        });

        document.getElementById("toggle-navigation-menu").addEventListener("click", (e) => {
            const button = e.target;
            const ariaExpanded = button.getAttribute("aria-expanded");
            const header = document.getElementById("main-header");

            if (ariaExpanded === "true") {
                button.setAttribute("aria-expanded", "false");
                header.classList.remove("menu-open");
            } else {
                button.setAttribute("aria-expanded", "true");
                header.classList.add("menu-open");
            }
        });
    });
</script>

<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline"
               href="index.html"> Home </a><a
                class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline" href="/about/">
                About </a>
        </nav>
    </div>
    <theme-toggle class="ms-auto">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>
<main id="main">
    <section aria-label="Blog post list">
        <a href="https://ayende.com/blog/170017/ravendb-in-qcon-london" target="_blank"><h1 class="title mb-6">RavenDB in QCon London</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: February 02, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">We&#x2019;ll be in QCon London in March 4-6 this year, talking about RavenDB and giving away some cool swag. I urge you to come an join us. And if you can&#x2019;t make it to QCon, I&#x2019;ll be giving a free talk at Skills Matter on March 5. In this talk, I&#x2019;ll talk about the kind of performance optimizations work that went into RavenDB in the past few months, and what kind of things we had to do to get even more speed out of the system.</p>
        <a href="https://enterprisecraftsmanship.com/posts/ienumerable-interface-in-net-and-lsp/" target="_blank"><h1 class="title mb-6">IEnumerable interface in .NET and LSP</h1></a>
        <p class="mb-2">by Vladimir Khorikov</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 30, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">I often see developers saying that in most cases, use of IEnumerable breaks LSP. Does it? Let&#x2019;s find out.&#xA; This is the continuation of my article Read-Only Collections and LSP. It this post, I&#x2019;d like to discuss IEnumerable interface from a Liskov Substitution Principle (LSP) perspective.&#xA; Liskov Substitution Principle and IEnumerable interface To answer the question whether or not use of IEnumerable breaks LSP, we should step back and see what it means to break LSP.</p>
        <a href="https://ayende.com/blog/169829/excerpts-from-the-ravendb-performance-team-report-optimizing-compare-dont-you-shake-that-branch-at-me" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 30, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Note, this post was written by Federico. In the previous post after inspecting the decompiled source using ILSpy&#xA0; we were able to uncover potential things we could do.   By now we already squeeze almost all the obvious inefficiencies that we had uncovered through static analysis of the decompiled code, so now we will need another strategy. For that we need to analyze the behavior in runtime in the average case. We did something like that when in this post when we made an example using a 16 bytes compare with equal arrays.   To achieve that analysis live we will need to somehow know the size of the typical memory block while running the test under a line-by-line profiler run. We built a modified version of the code that stored the size of the memory chunk to compare and then we built an histogram with that (that&#x2019;s why exact replicability matters). From our workload the histogram showed that there were a couple of clusters for the length of the memory to be compared. The first cluster was near 0 bytes but not exactly 0. The other cluster was centered around 12 bytes, which makes sense as the keys of the documents were around 11 bytes. This gave us a very interesting insight. Armed with that knowledge we made our first statistical based optimization.   You can notice the if statement at the start of the method, which is a pretty standard bounding condition. If the memory blocks are empty, therefore they are equal. In a normal environment such check is so simple that nobody would bother, but in our case when we are measuring the runtime in the nanoseconds, 3 extra instructions and a potential branch-miss do count.   That code looks like this:    That means that not only I am making the check, we are also forcing a short-jump every single time it happens. But our histogram also tells us that memory blocks of 0 size almost never happen. So we are paying with 3 instructions and a branch for something that almost never happen. But we also knew that there was a cluster near the 0 that we could exploit. The problem is that we would be paying 3 cycles (1 nanosecond in our idealized processor) per branch. As our average is 97.5 nanoseconds, we have 1% improvement in almost any call (except the statistically unlikely case) if we are able to get rid of it.   Resistance is futile, that branch needs to go.   In C and Assembler and almost any low level architecture like GPUs, there are 2 common approaches to optimize this kind of scenarios.    The ostrich method. (Hide your head in the sand and pray it just work).  Use a lookup table.  The first is simple, if you don&#x2019;t check and the algorithm can deal with the condition in the body, zero instructions always beats more than zero instruction (this case is a corner case anyways, no damage is dealt). This one is usually used in massive parallel computing where the cost of instructions is negligible while memory access is not. But it has its uses in more traditional superscalar and branch-predicting architectures (you just don&#x2019;t have so much instructions budget to burn).   The second is more involved. You need to be able to &#x201C;index&#x201D; somehow the input and pay with less instructions than do the actual branches (at a minimum of 1 nanosecond each aka 3 instructions of our idealized processor). Then create a branch table and jump to the appropriate index which itself will jump to the proper code block using just 2 instructions.   Note: Branch tables are very well explained at http://en.wikipedia.org/wiki/Branch_table. If you made it that far you should read it, don&#x2019;t worry I will wait.   As the key take away if your algorithm have a sequence of 0..n, you are in the best world, you already have your index. Which we did .   I know what you are thinking: Will the C# JIT compiler be smart enough to convert such a pattern into a branch table?  The short answer is yes, if we give it a bit of help. The if-then-elseif pattern won&#x2019;t cut it, but what about switch-case?  The compiler will create a switch opcode, in short our branch table, if our values are small and contiguous.   Therefore that is what we did. The impact? Big, but this is just starting. Here is what this looks like in our code:   I&#x2019;ll talk about the details of branch tables in C# more in the next post, but I didn&#x2019;t want to leave you hanging too much.</p>
        <a href="https://ayende.com/blog/170049/voron-on-linux" target="_blank"><h1 class="title mb-6">Voron on Linux</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 29, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">So, this just happened:  Note that this is a very important step, but it is just a first step. We have a few Linux experts review the code, and we haven&#x2019;t even started yet with working on RavenDB itself. But I&#x2019;m pretty happy right now.</p>
        <a href="https://ayende.com/blog/169828/excerpts-from-the-ravendb-performance-team-report-optimizing-memory-comparisons-size-does-matter" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 29, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Note, this post was written by Federico. In the previous post after inspecting the decompiled source using ILSpy&#xA0; we were able to uncover potential things we could do. In this fragment we have a pretty optimized method to compare an entire 4 bytes per loop. What if we could do that on 8 bytes?  To achieve that we will use a ulong instead of a uint. This type of optimization makes sense for 2 reasons.  Most of our users are already running RavenDB in x64 where the native word is 8 bytes and Voron is compiled on x64 only. But even if that were not true, since the late 2000&#x2019; most CPUs would have a 64 bytes L1 cache line with half a cycle cost for a hit. So even if you can&#x2019;t handle 64 bits in one go and the JIT or processor have to issue 2 instructions you are still getting a L1 cache hit and no pipeline stall. Which is GREAT .  So without farther ado, this is the resulting code:    Ayende&#x2019;s note: In the code, the lp &#x2B;= (IntPtr)8/8; is actually defined as lp &#x2B;= 1; What is actually happening is that we are increasing by 8 bytes (size of ulong), and this is how ILSpy decided to represent that for some reason. The actual IL generated for this is good:  It is just that the translation here is kind of strange.   Therefore the question to ask here is: Will skipping over the parts of the memory block that is equal at a faster rate will compensate for the cost of doing a final check with 8&#xA0; bytes instead of 4 bytes?  Well the answer is a resounding yes. It won&#x2019;t have much impact in the first 32 bytes (around 3% or less). We won&#x2019;t lose, but we won&#x2019;t win much either. But after that it skyrocket. // Bandwidth optimization kicks inSize:&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; 32 Original:&#xA0;&#xA0;&#xA0;&#xA0; 535 Optimized:&#xA0;&#xA0; 442 Gain:&#xA0;&#xA0;&#xA0; 5.01%Size:&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; 64 Original:&#xA0;&#xA0;&#xA0;&#xA0; 607 Optimized:&#xA0;&#xA0; 493 Gain:&#xA0;&#xA0;&#xA0; 7.08%Size:&#xA0;&#xA0;&#xA0; 128 Original:&#xA0;&#xA0;&#xA0;&#xA0; 752 Optimized:&#xA0;&#xA0; 573 Gain:&#xA0;&#xA0; 11.77%Size:&#xA0;&#xA0;&#xA0;&#xA0; 256 Original: 1,080 Optimized:&#xA0;&#xA0; 695 Gain:&#xA0;&#xA0; 35.69%Size:&#xA0;&#xA0;&#xA0;&#xA0; 512 Original: 1,837 Optimized:&#xA0;&#xA0; 943 Gain:&#xA0;&#xA0; 74.40%Size: 1,024 Original: 3,200 Optimized: 1,317 Gain: 122.25%Size: 2,048 Original: 5,135 Optimized: 2,110 Gain: 123.13%Size: 4,096 Original: 8,753 Optimized: 3,690 Gain: 117.29% Those are real measurements. You can see that when bandwidth optimization kicks in the gains start to get really high. This means that changing the bandwidth size alone from 4 byte to 8 bytes got us an order of magnitude improvement stabilizing around 120%.  Not bad for 2 lines of work.</p>
        <a href="https://ayende.com/blog/169827/excerpts-from-the-ravendb-performance-team-report-optimizing-memory-comparisons-digging-into-the-il" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 28, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Note, this post was written by Federico. Where I had notes or stuff to extend, I explicitly marked it as such. In the previous post after inspecting the decompiled source using ILSpy&#xA0; we were able to uncover potential things we could do.   Did you remember how dotPeek and ILSpy didn&#x2019;t agree on the last for-loop?   dotPeek      ILSpy       Well to really know which one is right, lets dig deeper. Looks like dotPeek is just too smart for our purposes.       MSIL is an stack machine, so everything has to be pushed to the stack to be operated. And the lower you go the less context you have to make optimization choices. The compiler knows a lot more, therefore it can make sensible choices that the JIT can&#x2019;t. Well this is one of those, the problem here is that the compiler is treating those native memory references in a very &#x201C;un-native&#x201D; way, leaving small room to the JIT to do its magic. Therefore we are going to give the compiler a nudge to point him in the right direction.&#xA0;   We know that most architecture have a set of indexed instructions that will allow you to load from memory at a base address plus an offset and special ones optimized to operate with constants. Yeah all that magic in a single opcode.   Therefore if we can find a way that the compiler would emit such&#xA0; a sequence, there is a high chance that the JIT will understand it and emit such a load statement. What could appear to be a long shot is actually quite easy. Instead of doing pointer arithmetic (pre/post increment and dereferencing) as usual, we will do something we would never do in C/C&#x2B;&#x2B;; we will just ask for it at face value.   So what would be:   var v = *(lhs&#x2B;&#x2B;) &#x2013; *(rhs&#x2B;&#x2B;); &#xA;&#xA;Now becomes: &#xA;&#xA;&#xA;var v = lhs[0] - rhs[0]; &#xA;&#xA;lhs&#x2B;&#x2B;; &#xA;&#xA;rhs&#x2B;&#x2B;;&#xA;&#xA;&#xA;&#xA;What if we need the next one? &#xA;&#xA;&#xA;var v = lhs[1] - rhs[1]; &#xA;&#xA;&#xA;And so on&#x2026; However, that is true if and only if the number can be loaded into the stack using an special short instruction (a shortcut) that encodes the value to load as a named constant. &#xA;&#xA;Why this work? &#xA;&#xA;Because the MSIL pattern is unequivocal: &#xA;&#xA; &#xA;&#xA;We push the first pointer (lhs) &#xA;&#xA;We load a byte from it and put it into an int32 register in the stack &#xA;&#xA;We push the second pointer (rhs) &#xA;&#xA;We load a byte from it and put it into an int32 register in the stack &#xA;&#xA;We subtract the two loaded int32. &#xA;&#xA;We store it into an stack variable (v) &#xA;&#xA;We load it into the stack from (v) &#xA;&#xA;We check if it is distinct from (0) &#xA;&#xA;&#xA;The JIT now can figure out how to optimize this with a load &#x2B; offset instruction easily. Moreover the offset is also a constant, anyone said &#x201C;special opcode&#x201D;?. Now let&#x2019;s compare the IL code&#xA0; from each approach. &#xA;&#xA;Before Optimization: &#xA;&#xA; &#xA;&#xA;After Optimization &#xA;&#xA; &#xA;&#xA;While the amount of instructions is the same and the avid reader would have figured out by now; the code is not that different either. &#xA;However, the former translate to far more native instructions than the latter. Why? We will have to ask the JIT or the compiler guys, but my hypothesis is that the first version requires a much more deeper analysis than the second and in an effort to keep the JIT overhead low, that pattern can&#x2019;t be optimized so much. &#xA;&#xA;The bottom line is: &#x201C;Do not optimize pointers in C# as you do in C/C&#x2B;&#x2B;. Translating an optimized algorithm that uses pointers from C/C&#x2B;&#x2B; to C# will not be optimal.&#x201D; &#xA;&#xA;Remember this, it will make sense soon, because in the next post, we&#x2019;ll tie it all together.</p>
        <a href="https://ayende.com/blog/169826/excerpts-from-the-ravendb-performance-team-report-optimizing-memory-comparisons" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 27, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Note, this post was written by Federico. Where I had notes or stuff to extend, I explicitly marked it as such. In the previous post after inspecting the decompiled source using ILSpy&#xA0; we were able to uncover potential things we could do.  Getting rid of unwanted type conversion may seem as an small cost, but let&#x2019;s make an example. Let&#x2019;s say we are comparing 2 memory arrays of 16 bytes and they are equal (our worst case scenario).  Just for the sake of simplification from the 3 potential causes the memory is aligned so there is no need to the first 2 unwanted conversions. That leaves us with the main body as the only source of unwanted conversions.    Now this loops moves our pointer 4 bytes each time and causes 2 conversions. Therefore for a 16 bytes array (a pretty average size) we are performing 8 conversions, that is grand total of 8 conversions. Assuming our idealized processor, at 0.33 ns per conversion instruction we have 2.64 ns or roughly 3% of the total time per average call. Getting rid of that is easy, as the size of an unsigned int is a constant.  private const int sizeOfUint = sizeof(uint);&#xA;&#xA;&#xA;Therefore the final executable code will be:&#xA;&#xA;Here we have 2 interesting side effects:&#xA;&#xA;&#xA;We no longer have the conversion but also the constant got put instead of the indirection to an stack variable.&#xA;Almost every comparison you do over a constant that is 2^n based can be converted to a shift operation.&#xA;&#xA;If the JIT is smart enough, this check can be compiled into a shift of 2 places and asking if the result is bigger than 0. Squeezing 4 instructions into 2 per each while cycle.&#xA;&#xA;You guessed right, the JIT is.</p>
        <a href="https://ayende.com/blog/169825/excerpts-from-the-ravendb-performance-team-report-optimizing-memory-compare-copy-costs" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 26, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Note, this post was written by Federico. Where I had notes or stuff to extend, I explicitly marked it as such. TLDR: Optimizing at this level is really hard. To achieve gains of 20%&#x2B; for Compare and from 200% to 6% in Copy (depending on the workload) we will need to dig very deep at the IL level.  Another area we looked deeply into is, how do we move and access the memory. This type of optimization work is especially relevant if you are using Voron to handle big workloads. With small databases the improvements can be felt, but where they shine is when dealing with multi-gigabyte databases or high-throughput key-value retrieves and put workloads (did anyone thought Bulk-Inserts?).  Using FreeDB as in this previous post we build an experiment which we could use to pinpoint the pain points making sure we could also repro it every single time (no indexes, no extra call around). Under the microscope 2 pain points were evident when dealing with memory. Comparing and moving memory around.  We usually compare memory straight from the mmaped unmanaged memory when looking for a particular document in Voron Trees; and to copy from and to Voron pages when storing and retrieving documents. These are very core operations for any storage engine, Voron is not an special case. Before we started the optimization effort we already had a pretty optimized routine.  What this method does is:   If the memory blocks have zero size, there is no doubt they are equal. If the memory blocks are bigger than the size of a word (32 bits) we do a pre-compare over the aligned memory blocks (for performance) in order to rule out all the equals. As we cannot use words to calculate the output (handling the Endianness would cost us), we do a byte by byte comparison for the final check.&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;   For our insert workload we were roughly in the 97.5 nanoseconds per memory compare in average. To put in context, if each assembler instruction could be executed in exactly 1 cycle (which usually is not true) then 3 instruction is an entire nanosecond, therefore our average instruction budget is 291 instructions. Remember this idealized processor, we will use this same comparison later for more complex analysis.  Memory compares can be of different sizes that is why controlling the environment is very important for this type of optimization work.  To deal with that and we were using many tricks from the optimization book. From ensuring that memory alignment is optimal to batch compares with bigger primitive sizes to pointer arithmetic. At first sight this one is the kind of method you won&#x27;t optimize at all, it is pretty damn tight.  Ayende&#x2019;s node &#x2013; We have already done a optimization step on memory comparisons. We initially just shelled out to the native memcmp method, but the cost of doing a pinvoke call ended up being noticable, and we wrote the previously optimized version (and had several rounds of that) to alleviate that cost.  However, we took to the challenge because the payoff can be huge. For a very small bulk insert of 50,000 documents inserted in an empty database, we are talking about in the ballpark of 5 million compares (yeah you read it right). Even if we manage to squeeze 1% off, the sheer volume of calls will make it worthwhile. To achieve that we had to do the unthinkable, we had to resort to dig into the MSIL that method was generating. Armed with ILSpy we found out we may have a way to shave off some inefficiencies. Here is the what this look like when we start actually putting analysis to action. You can see the method code (after decompilation, so we can be closer to the IL) as well as the issues that were discovered in the process.     Because of the size of the method the fastest way was to resort to use a C# decompile, even though we then matched it with the generated IL. The trick to use the C# decompiled version requires that we use a decompiler that is not too smart when dealing with the code. If the decompiler would have understood what was the original code intention and acted upon it, we would have never spotted some of the optimizations at this level. For example, the last loop decompiled with JetBrains dotPeek would look like this:    Always keep around an old version of a decompiler just in case you may need it .  Ayende&#x2019;s note: In most cases, you can select the level of details that a decompiler can give you. With Reflector, for example, you can select how deeply it will decompile things, but even so, doing stupid decompilation can be very beneficial by showing us what is actually going on.  Understanding where the inefficiencies may be, is one thing, being able to prove them is another matter. And we will tackle all of them in future posts. We will also leave the memcpy analysis for later because it builds on the optimizations used in memcmp and also requires a deep analysis of the Buffer.Memcpy method already available in the .Net Framework (for internal use of course).   If what we did to the poor Etags was evil. You are now arriving at the gates of the underworld.  Ayende&#x2019;s note: This is a pretty complex topic, and it goes on for quite a while. In order to maintain interest, and to avoid having people getting lost in the details, I broke it apart for several posts. In the meantime, given the details in this post, how would you suggest improving this?</p>
        <a href="https://ayende.com/blog/169800/excerpts-from-the-ravendb-performance-team-report-expensive-headers-and-cache-effects" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 23, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This ended up being a pretty obvious, in retrospect. We noticed in the profiler that we spent a lot of time working with headers. Now, RavenDB is using REST as the communication layer, so it is doing a lot with that, but we should be able to do better. Then Tal dug into the actual implementation and found:  public string GetHeader(string key)&#xA;{&#xA;&#x9;if (InnerHeaders.Contains(key) == false)&#xA;&#x9;&#x9;return null;&#xA;&#x9;return InnerHeaders.GetValues(key).FirstOrDefault();&#xA;}&#xA;&#xA;public List&lt;string&gt; GetHeaders(string key)&#xA;{&#xA;&#x9;if (InnerHeaders.Contains(key) == false)&#xA;&#x9;&#x9;return null;&#xA;&#x9;return InnerHeaders.GetValues(key).ToList();&#xA;}&#xA;&#xA;&#xA;public HttpHeaders InnerHeaders&#xA;{&#xA;&#x9;get&#xA;&#x9;{&#xA;&#x9;&#x9;var headers = new Headers();&#xA;&#x9;&#x9;foreach (var header in InnerRequest.Headers)&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;if (header.Value.Count() == 1)&#xA;&#x9;&#x9;&#x9;&#x9;headers.Add(header.Key, header.Value.First());&#xA;&#x9;&#x9;&#x9;else&#xA;&#x9;&#x9;&#x9;&#x9;headers.Add(header.Key, header.Value.ToList());&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;if (InnerRequest.Content == null)&#xA;&#x9;&#x9;&#x9;return headers;&#xA;&#xA;&#x9;&#x9;foreach (var header in InnerRequest.Content.Headers)&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;if (header.Value.Count() == 1)&#xA;&#x9;&#x9;&#x9;&#x9;headers.Add(header.Key, header.Value.First());&#xA;&#x9;&#x9;&#x9;else&#xA;&#x9;&#x9;&#x9;&#x9;headers.Add(header.Key, header.Value.ToList());&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;return headers;&#xA;&#x9;}&#xA;}&#xA;&#xA;&#xA;To be fair, this implementation was created very early on, and no one ever actually spent any time looking it since (why would they? it worked, and quite well). The problem is the number of copies that we have, and the fact that to pull a since header, we have to copy all the headers, sometimes multiple times. We replaced this with code that wasn&#x2019;t doing stupid stuff, and we couldn&#x2019;t even find the cost of working with headers in the profiler any longer.&#xA;But that brings up a really interesting question. How could we not know about this sort of thing? I mean, this isn&#x2019;t the first time that we are doing a performance pass on the system. So how come we missed this?&#xA;The answer is that in this performance pass, we are doing something different. Usually we perf-test RavenDB as you would when using it on your own systems. But for the purpose of this suite of tests, and in order to find more stuff that we can optimize, we are actually working with a stripped down client, no caching, no attempt to optimize things across the entire board. In fact, we have put RavenDB in the worst possible situation, all new work, and no chance to do any sort of optimizations, then we start seeing how all of those code paths that were rarely hit started to light up quite nicely.</p>
        <a href="https://ayende.com/blog/169799/excerpts-from-the-ravendb-performance-team-report-the-long-tale-of-a-lambda" target="_blank"><h1 class="title mb-6">Excerpts from the RavenDB Performance team report</h1></a>
        <p class="mb-2">by Oren Eini</p>
        <p class="mb-6 flex gap-1.5">
                    <span>
                                    <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                                         xmlns="http://www.w3.org/2000/svg"><path
                                            xmlns="http://www.w3.org/2000/svg"
                                            d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
            posted on: January 22, 2015
        </p>
        <p class="max-w-full w-full line-clamp-5 text-justify mb-20">This nugget was discovered by Tal, who was measuring write throughput and noticed that a lot of the time wasn&#x2019;t being handled in the proper code path, but on something on the side that seemed&#x2026; off.  prefetchingQueue.Aggregate(0, (x,c) =&gt; x &#x2B; SelectSerializedSizeOnDiskIfNotNull(c)) &gt; context.Configuration.AvailableMemoryForRaisingBatchSizeLimit) This piece of code is responsible for heuristics deep inside the bowels of RavenDB. In fact, it is the piece that decide whatever we have enough memory to index directly from memory or do we need to start dumping stuff and pay the I/O cost of them later.  As a result, this piece of code is called once for every document save. It was also quite wildly inefficient. The Aggregate implementation was pretty much as you imagined it, and it took three times as much time as actually process the rest of the request. The underlying reason was that we kept doing a foreach and a delegate invocation on each an every call. The more documents we had coming in, the more work we had to do. Shlemiel the painter at his best. We first saw a major improvement by just removing the Aggregate() call in favor of a purpose built function that summed all those details for us directly. Next, we changed things so instead of doing O(N) work per request, we could do an O(1) work by doing this work one bit at a time and aggregating it on the fly. So whenever we added or removed something to the prefetching queue, we would also make sure to add / remove that from the global tally. Once that is done, we saw almost 18% improvement in high write scenarios, because we weren&#x2019;t just busy counting how much stuff we have in memory to figure out if we can put things in memory. I can&#x2019;t emphasize enough how important it is that the work throughout was done using a profiler (in our case, the excellent dotTrace) because if dotTrace wouldn&#x2019;t have point a big finger at this line of code, we would have never have considered this to be problematic.</p>
        <div class="button flex justify-between">
            <a href="248.html"><span class="back arrow"></span></a>

            <a href="250.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>
<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	">Â© Relatively General
                        .NET 2024<span
                            class="inline-block">&nbsp;ðŸš€&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="/about/"> About </a>
    </nav>
</footer>
</body>
</html>