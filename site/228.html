
<!DOCTYPE html>
<html class="scroll-smooth" lang="en-US" data-theme="light">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <title>Page 228 &#x2022; Relatively General .NET</title>
    <link href="favicon.ico" rel="icon" sizes="any">
    <link href="images/apple-touch-icon.png" rel="apple-touch-icon">
    <meta content="hsl()" name="theme-color">
    <meta content="website" property="og:type">
    <meta content="Home" property="og:title">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="/pagefind/pagefind-ui.css">
    <!-- Google Analytics -->
    <script>
        // Only load GA if consent is given
        function loadGA() {
            const script = document.createElement('script');
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-MDFXJY3FCY';
            script.async = true;
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }

            gtag('js', new Date());
            gtag('config', 'G-MDFXJY3FCY');
        }

        // Check if consent was previously given
        if (localStorage.getItem('cookieConsent') === 'accepted') {
            loadGA();
        }
    </script>
    <!-- End Google Analytics -->
</head>
<body class="mx-auto flex min-h-screen max-w-3xl flex-col bg-bgColor px-4 pt-16 font-mono text-sm font-normal text-textColor antialiased sm:px-8">
<a class="sr-only focus:not-sr-only focus:fixed focus:start-1 focus:top-1.5" href="#main">
    skip to content
</a>
<header class="group relative mb-28 flex items-center sm:ps-[4.5rem]" id="main-header">
    <div class="flex sm:flex-col">
        <a aria-current="page" class="inline-flex items-center hover:filter-none sm:relative sm:inline-block"
           href="index.html">
            <img class="me-3 sm:absolute sm:start-[-4.5rem] sm:me-0 sm:h-16 sm:w-16 w-16" src="images/giphy.gif"
                 alt=""/>
            <span class="text-xl font-bold sm:text-2xl">Relatively General .NET</span>
        </a>
        <nav aria-label="Main menu"
             class="absolute -inset-x-4 top-14 hidden flex-col items-end gap-y-4 rounded-md bg-bgColor/[.85] py-4 text-accent shadow backdrop-blur group-[.menu-open]:z-50 group-[.menu-open]:flex sm:static sm:z-auto sm:-ms-4 sm:mt-1 sm:flex sm:flex-row sm:items-center sm:divide-x sm:divide-dashed sm:divide-accent sm:rounded-none sm:bg-transparent sm:py-0 sm:shadow-none sm:backdrop-blur-none"
             id="navigation-menu">
            <a aria-current="page" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline underline"
               href="index.html"> Home </a><a
                aria-current="" class="px-4 py-4 underline-offset-2 sm:py-0 sm:hover:underline " href="about.html">
                About </a>
        </nav>
    </div>
    <site-search class="ms-auto" id="search">
        <button id="open-search"
                class="flex h-9 w-9 items-center justify-center rounded-md ring-zinc-400 transition-all hover:ring-2"
                data-open-modal="">
            <svg aria-label="search" class="h-7 w-7" fill="none" height="16" stroke="currentColor"
                 stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="16"
                 xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" stroke="none"></path>
                <path d="M3 10a7 7 0 1 0 14 0 7 7 0 1 0-14 0M21 21l-6-6"></path>
            </svg>
        </button>
        <dialog aria-label="search"
                class="h-full max-h-full w-full max-w-full border border-zinc-400 bg-bgColor shadow backdrop:backdrop-blur sm:mx-auto sm:mb-auto sm:mt-16 sm:h-max sm:max-h-[calc(100%-8rem)] sm:min-h-[15rem] sm:w-5/6 sm:max-w-[48rem] sm:rounded-md">
            <div class="dialog-frame flex flex-col gap-4 p-6 pt-12 sm:pt-6">
                <button id="close-search"
                        class="ms-auto cursor-pointer rounded-md bg-zinc-200 p-2 font-semibold dark:bg-zinc-700"
                        data-close-modal="">Close
                </button>
                <div class="search-container">
                    <div id="cactus__search"/>
                </div>
            </div>
        </dialog>
    </site-search>
    <theme-toggle class="ms-2 sm:ms-4">
        <button id="theme-toggle" class="relative h-9 w-9 rounded-md p-2 ring-zinc-400 transition-all hover:ring-2"
                type="button">
            <span class="sr-only">Dark Theme</span>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-100 opacity-100 transition-all dark:scale-0 dark:opacity-0"
                 fill="none" focusable="false" id="sun-svg" stroke-width="1.5" viewBox="0 0 24 24"
                 xmlns="http://www.w3.org/2000/svg">
                <path
                    d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18Z"
                    stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M22 12L23 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 2V1" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M12 23V22" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 20L19 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M20 4L19 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 20L5 19" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M4 4L5 5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
                <path d="M1 12L2 12" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-7 w-7 -translate-x-1/2 -translate-y-1/2 scale-0 opacity-0 transition-all dark:scale-100 dark:opacity-100"
                 fill="none" focusable="false" id="moon-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 0h24v24H0z" fill="none" stroke="none"></path>
                <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
                <path d="M17 4a2 2 0 0 0 2 2a2 2 0 0 0 -2 2a2 2 0 0 0 -2 -2a2 2 0 0 0 2 -2"></path>
                <path d="M19 11h2m-1 -1v2"></path>
            </svg>
        </button>
    </theme-toggle>
    <mobile-button>
        <button aria-expanded="false" aria-haspopup="menu" aria-label="Open main menu"
                class="group relative ms-4 h-7 w-7 sm:invisible sm:hidden" id="toggle-navigation-menu" type="button">
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 transition-all group-aria-expanded:scale-0 group-aria-expanded:opacity-0"
                 fill="none" focusable="false" id="line-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M3.75 9h16.5m-16.5 6.75h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
            <svg aria-hidden="true"
                 class="absolute start-1/2 top-1/2 h-full w-full -translate-x-1/2 -translate-y-1/2 scale-0 text-accent opacity-0 transition-all group-aria-expanded:scale-100 group-aria-expanded:opacity-100"
                 fill="none" focusable="false" id="cross-svg" stroke="currentColor" stroke-width="1.5"
                 viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </button>
    </mobile-button>
</header>


<main id="main" data-pagefind-body>
    <section aria-label="Blog post list">
        <article id="article-2271">
            <a href="https://ayende.com/blog/184386-A/reviewing-faster-when-the-data-hits-the-disk" target="_blank">
                <h2 class="title mb-6" id="article-2271">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 05, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">So far, I ignored anything in FASTER about how the data actually hits the disk. Based on my reading of the code and the paper, here is what I think that is going on. FASTER works in segments and in conjunction with its allocator. When you create a new instance, you have to define what would be the log size. From looking at the code, they seem to be favoring 16GB as the default size of the log. This is passed to PersistentMemoryMalloc, which uses pages of 32MB each to manage the memory. Out of these 16GB, 14.4GB are considered to be mutable and 1.6 GB is considered to be read only. On startup, this class allocates two pages (64MB). Whenever FASTER needs more memory, such as to store a new record, it will eventually call to this method:Again we have num_slots that actually means size in bytes, but I&#x2019;ll leave my pet peeves aside. You can see that this allocates from tail of the page use Reserve, which does an atomic operation. If we run out of space in the 32MB page, the caller need to call NewPage() to handle the new allocation. This plays together with the buffer management and the epoch. In particular, here is how a new page is allocated in the normal case. Assuming we just started and we consumed 64MB of memory, the new entry will allocate the 3rd page. This will also move the section of read only memory when there is a new page allocated and the number of active pages is beyond 14.4 GB.What this means, in practice, is that FASTER typically has a 14.4GB range in which all operations are working on purely mutable memory. That means that two impressions on the same ad will end up being very close to simply Interlocked.Increment on the relevant value. This is the key for the performance that FASTER exhibits. What happens once we start going beyond the 14.4 GB? FASTER will begin to move data to the read only section. In this case, it means that the any new modifications to the data will create a new copy of it in the mutable section.At the same time, PageAlignedShiftReadOnlyAddress() will also starts an async process of writing these readonly pages to disk. Here is how it works:If the read_only_address was updated, FASTER calls to BumpCurrentEpoch() and will execute OnPagesMarkedReadOnly() when the Epoch moves beyond this range (this works because then it is guaranteed that no one may mutate this memory).&#xA0; That method looks like this:The notion of read_only_address and safe_readonly_only_address is discussed in the paper quite nicely, by the way. AsyncFlushPages() writes the data to disk, as you would expect and updates various in memory structures.Note that just having the data written to disk doesn&#x2019;t remove the in memory copy. It is still available in memory until it is pushed back from the log by new data. Now that we understand how the data goes to the log and then to the disk, I want to figure out how the data is written in to the disk itself. Actual writes are handled here:What you can see is that the destination offset is used to divide the data on disk to sections. Each section is 1GB in size. In other words, the way FASTER works is to write the data in 1 GB segments that are sequential over time. This also plays into the expiration policy that FASTER employs. Because it uses a logs based system, it accumulate data over time and will need to handle that. The current way it deals with the problem is to just delete old files, this gets rid of the data in roughly time based order, which is suitable for the use case that the paper talks about. Another alternative is to read the old files, and move the still valid entries to the start. That doesn&#x2019;t seem to be implemented and I think it will be pretty hard to do and likely consume a lot of resources.I&#x2019;ll probably have another summary post about FASTER, but that is pretty much it. I&#x2019;ve ignored other parts (recovery, several state machines used to handle internal state, etc), but they aren&#x2019;t important to grokking what it is actually doing. It is an interesting codebase, but it feels&#x2026; incomplete. But I&#x2019;ll reserve such thoughts to the summary post.</p>
        </article>
        <article id="article-2272">
            <a href="https://ayende.com/blog/184385-A/reviewing-faster-reading-data-from-disk" target="_blank">
                <h2 class="title mb-6" id="article-2272">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 04, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">One of the things that FASTER claims is that it is suitable for larger than memory datasets with its hybrid log approach. I briefly went over that code during my review, but I want to dedicate this post to discussing how FASTER work with the disk.FASTER is using async I/O on Linux &amp; Windows to do its I/O, which present its own challenges, in particular, how do you handle an operation that is going to need to hit the disk ( to read old data). Another thing that I would like to discover is how does it save the data to disk. We&#x2019;ll start from the reading data part.Reading in FASTER looks like this:You pass a context, a callback and serial number. I&#x2019;m not sure what the serial is about, I think it is about checkpoints, but not sure. You&#x2019;ll be called with the results once the operation executed. Here is the core of the Read method:FASTER first checks the in memory details, and if it isn&#x2019;t there it is either not found or on disk. This is actually really interesting, because it implies that FASTER keep track of all of the data items purely in memory. Let&#x2019;s go to InternalRead and figure out how that works. We already looked into most of that in the previous post FindEntry is called to find the entry by it&#x2019;s hash. FASTER keep all the hashes in memory, even while it is writing entries to disk. This way, it can easily answer if an entry exists or not. Note that as I read things, if FASTER has more than a certain number of values, hash collision rate is going to reach high percentage, requiring often expensive I/O to figure out whatever the value exists.If the value is in memory, your ReadContext.GetAtomic() method will be called. Here is one such implementation:Where the value was defined as:If the value has already been moved to the read only section, it will use the Get() method, instead, as an optimization. If the value is not on the mutable section or the read only section, it is on the disk, in which case we have this code:&#xA0;The go_async() method just records the status of the operation when we started the async process, it doesn&#x2019;t actually invoke anything async. That is done in the caller code, Read().This, in turn, gets us to this piece of code:Note that the code is full of handling of the current phase of the thread. I&#x2019;m ignoring all of these for now, they aren&#x2019;t important. The next thing to look at is the async I/O request, which gets us to:We first register the pending I/O, then actually starts to process the async call. Except that not really. AsyncGetFromDisk() isn&#x2019;t actually doing I/O.&#xA0; Instead, it seems to be focused on limiting the number of concurrent I/O operations that are going on.In this case, if there are more than 120 pending I/Os, it will call io_getevents() in Linux and GetQueuedCompletionStatus() and try to process any completed I/O immediately. ProtectAndDrain is more interesting. It asks the epoch to complete any pending operations. Such actions are the creation of a new segment file or the moving of a segment from memory to disk.I find it interesting that FASTER chose to stall the thread until all pending I/Os are completed. Given their model, it would make more sense to push such operation into the thread ops and resume process other requests. I guess that they expect this to be either a rare case or using this for throttling overall system load. You might also have noticed the num_records arguments, this is used in the hlog method:That was confusing, I expected this to be the number of records (as in, how many records are read from disk) but this is the number of bytes to read.The C&#x2B;&#x2B; memory model make async code a bit complex. In particular, if you&#x2019;ll look at the first code snippet in this post, you&#x2019;ll see that we pass a stack allocated struct to the Read() method. Because this method can complete in an async manner, what FASTER will do is to perform a deep copy of the data. Combine that with lambda&#x2019;s capturing state, and I&#x2019;m pretty sure that this code will cause a very subtle memory corruption in rare cases.What I think will happen is that we capture by ref the stack variable and in 99% of the cases, we&#x2019;ll run this in sync mode, meaning that there will be no issues. Only if the value needs to be read from disk will you get an issue. Because that function will already return but you still have the callback (and the captured reference now pointing to something completely different) still active. I think that a C&#x2B;&#x2B; developer would recognize this, and the fact that C&#x2B;&#x2B; require you to be explicit about your captures make this a lot easier to deal with. It is important to note that there is no good way to actually handle the async nature of certain operations here. Any code that actually handle the operation need to go in the callback. Another aspect to remember is that just reading from the disk doesn&#x2019;t mean that you got the right value. You might have gotten a hash collision:In other words, if you have a way to generate hash collisions, as soon as the value hits the disk, you are going to be facing with making N disk I/O requests to find if you have the value or not.&#xA0; Denial of service attacks against hash tables are well known and represent a significant risk of to services. Next on my list if seeing how FASTER is actually writing the data to disk, but that will be in a separate post.</p>
        </article>
        <article id="article-2273">
            <a href="https://andrewlock.net/why-isnt-my-asp-net-core-environment-specific-configuration-loading/" target="_blank">
                <h2 class="title mb-6" id="article-2273">Why isn&#x27;t my ASP.NET Core environment-specific configuration loading?</h2>
            </a>
            <p class="mb-2">by Andrew Lock</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 04, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In this post I describe an issue I was having in which my application wouldn&#x27;t load my appsettings.Development.json file when running in Docker on Linux&#x2026;</p>
        </article>
        <article id="article-2274">
            <a href="https://www.stevejgordon.co.uk/running-aws-dynamodb-locally-for-net-core-developers" target="_blank">
                <h2 class="title mb-6" id="article-2274">Running AWS DynamoDB Locally for .NET Core Developers</h2>
            </a>
            <p class="mb-2">by Steve Gordon</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 03, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">For a recent set of .NET Core based microservices I have found myself using AWS DynamoDB as a data store. I recently discovered that AWS provides (and have done for 5 years!) a local version of DynamoDB which is perfect for testing applications offline and without the need to set up actual DynamoDB tables in [&#x2026;]</p>
        </article>
        <article id="article-2275">
            <a href="https://ayende.com/blog/184354-A/reviewing-faster-the-hash-structure" target="_blank">
                <h2 class="title mb-6" id="article-2275">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: September 03, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Continuing my stroll through the FASTER codebase, I want to try to get to the core stuff, not just the periphery. This is a bit hard, because there is a lot of code here and it seems to be hard to find where the real action is happening. I decided to find how FASTER is handling Get and Put operations.&#xA0;&#xA0; There is something called InternalHashTable inside FasterKv, which seems promising,&#xA0; so I&#x2019;m going to follow up on that. Interestingly enough, it shows up as:So there are some funky stuff here to consider too, but we&#x2019;ll deal with that later, for now, I want to understand what it is doing with the InternalHashTable. Inside that class, there is the notion of bukcets:And a bucket is:This starts to get interesting for me, so let&#x2019;s dig deeper into HashBucketEntry, where they use the same union trick I talked about in my previous posts, this allow to easily define an atomic version of it with very little effort.There is also the overflow entry definition, which looks like this:I got to say, I&#x2019;m really liking this approach for handling data packing as well as multi threading concerns. It also plays very well with the actual cache line architecture of modern CPUs.There is also the KeyHash struct, whose heart is this:So far, this lines us very neatly to how the FASTER paper talks about things. Given a KeyHash, here is how you get it&#x2019;s bucket:This simply index into the buckets_ array by taking the (size_ &#x2013;1) bits from the hash itself. That tells me that the FASTER structure is very sensitive to the choice of hash function that will be used. This SO answer has some amazing detail on analysis of the output of hash functions with different outputs, which can give you some idea about why this matters so much. This post is an in depth discussion of this, as well of why the choice of hash function matters. This is enough for me to stop everything and try to find what kind of hash function is actually being used here.The user get to define their own hash function, and if they do so badly (for example, use the identity function since they have an 8 bytes value and they need an 8 bytes hash) that is going to be fun. The function that they seem to be using in their examples is this one:A bit of searching on the interweb didn&#x2019;t narrow it down to something specific, it may be something that they wrote specifically for that. Given that the paper doesn&#x2019;t mention this, it doesn&#x2019;t seem to be something special.Given that 40343 is a prime, it seems like a pretty common pattern of multiple by a prime with each 16 bits portion of the key. The idea is that the multiplication by prime will spread the bits around. No idea how high the quality of this hash function is, since actual analysis would take at least a few hours. At least at a glance,&#xA0; it doesn&#x2019;t seem to be awful, but I do wonder whatever something like FNV-1. In fact, this is very similar, but with different prime and offset and with addition instead of XOR. The actual InternalHashTable class doesn&#x2019;t actually do something, there are a few functions around checkpointing and recovery, but they aren&#x2019;t very interesting at this point. I&#x2019;m going back to actually working with the has table and looked at how reads work. They end up in the InternalRead method which does the majority of the work inside the FindEntry function. The first thing that happens there is:The first line is there to handle growing the hash table on the fly and will be ignored for now. As you can see, this basically just gives me the relevant bucket. Here is the next stage, once we have a bucket, we need to find the relevant entry that matches what we are looking for. Here is the code:You can see that there are a bunch of stuff going on here. First, we run over the known entries in the bucket, trying to find an entry with the same tag. You can see the tentative usage, which is used to sync up between concurrent readers and writers. There may be more items in the bucket than we have space for, so there is also the concept of overflow. This is basically a linked list of 7 items at a time and likely to be pretty fast (frequently already in the higher tiers of the cache for commonly accessed data). Now that we have the entry, let&#x2019;s see what is done with it. I&#x2019;m currently reading through the InternalRead code. Just finding the matching hash doesn&#x2019;t really help us, we may have hash collisions, this is handled here:This is the first time that we actually run into the hybrid log (hlog here). But the basic idea is pretty obvious. Either the key match, or we have a pointer to the previous entry. I&#x2019;m not seeing any handling of complete mismatch, though. I&#x2019;m pretty sure that this is a bug (the behavior is different in the C# version).This is enough for now, from here the InternalRead code is starting to do things with the hlog, state machine, etc. I&#x2019;m going to handle that in a separate post.</p>
        </article>
        <article id="article-2276">
            <a href="https://ayende.com/blog/184353-A/reviewing-faster-working-with-the-file-system" target="_blank">
                <h2 class="title mb-6" id="article-2276">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 31, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In my last post I dove into the Epoch implementation. The Epoch is explained very nicely in the paper, and the code follows the paper pretty closely. The code make sense, but I still lack the proper&#x2026; feeling for how it is actually being used. The Epoch allows you to register code that will be executed when the epoch is updated, which is the key to how FASTER is making progress, but while I can see that this is being called from the allocators, I haven&#x2019;t really grokked it yet. I&#x2019;m going to back to the faster.h file and see what I can glean from there.Because of the template utilization, it is kinda hard to figure out what exactly is going on, I&#x2019;m going to look at some of the examples and try to figure out what it is doing there. Here is one instance of this class:AdId and NumClicks are just two ways to provide operations on 8 bytes keys and values. I like these examples because they provide good use case to talk about FASTER usage.This code leads me to the FileSystemDisk, which is defined as:In the FileSystemFile, we have this code:This is pretty simple, but I was quite amused by this, because this is C# API sneaking up again in the C&#x2B;&#x2B; code. There is also this:I&#x2019;m not sure what this bundle is, though. I run into this code in the class:This is&#x2026; not nice, in my eyes. Based on this code, whoever allocated this instance also allocated a buffer large enough to include more data there. This is fairly common, since you want to work with such data together, but I find it ugly / risky because it means that there are multiple locations that needs to be aware of it. I would like it better if they just passed the pointer explicitly. That would avoid this snippet:Which I find pretty annoying to read. What is stranger is that to use this, you have to write (bundle_t has been typedef for the FileSystemSegmentBundle):I get what is going on here, but I just find it really awkward to handle. There are multiple places where you need knowledge of this allocation pattern and I don&#x2019;t believe that the benefit of placing all of the data together is that important. For that matter, given the importance of not using new explicitly in modern C&#x2B;&#x2B;, I&#x2019;m sure that there are other ways to achieve the same goal that would be more natural.Going through the code, we now have:I decided to make this post about the file system usage, because there is a lot of pretty complex code here that I would like to understand. I finally figured out what the S is, this is the segment size:This means that the earlier definition of FasterKv basically defined Segment Size of 1 GB in size. I&#x2019;m not sure what these segments are, though. I&#x2019;m pretty sure that this is how they manage time base expiration, but I&#x2019;m not certain. Following upward from the creation of a new segment, we have WriteAsync, like so:You can see that the segment number is basically just the file id, and if the file does not already exists, we call OpenSegment on it. Afterward, we call WriteAsync on that specific file. I&#x2019;ll look into how that work in a bit, this isn&#x2019;t that interesting at the moment. Right now I want to dig into OpenSegment. I removed some error handling here, but the gist of it is clear. The actual code also handles threading and errors, which I omitted. You can see that it creates the new files, copying them from the existing value. Then it creates a context that holds the old files and pass it to BumpCurrentEpoch.When FASTER is sure that no one else is looking at this epoch, it will call the callback and delete / dispose the old files. This is a nice way to ensure consistency. LMDB does something similar with its transactions&#x2019; table. So now we know that whenever we write at a 1GB boundary, FASTER will generate a new epoch. What about the actual writing? Here is what this looks like (the Linux impl):On Linux, this ends up being:This is then checked in TryComplete:This is called FasterKv.CompletePending(), which seems to be called occasionally by FASTER. On Windows, this is using async I/O and callbacks to handle this.Okay, this is already long enough, but I got a handle on how FASTER is writing to disk, even though I don&#x2019;t know yet what it is doing with that. I also saw an actual use of Epoch that made sense (clearing old data once no one is looking at that).</p>
        </article>
        <article id="article-2277">
            <a href="https://ayende.com/blog/184321-A/reviewing-faster-digging-into-the-c-impl" target="_blank">
                <h2 class="title mb-6" id="article-2277">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 30, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">After going over the paper and the managed implementation, I&#x2019;m ready to start with the C&#x2B;&#x2B; implementation. I have higher hopes for this code. As I started browsing the C&#x2B;&#x2B; code, it occurred to me that the way the C#&#x2019;s implementation handles dynamic code generation is pretty much how templates in C&#x2B;&#x2B; work. I wonder if this was the trigger for that.The C&#x2B;&#x2B; code reads a lot more naturally to me. There are some nice tricks that are used there that are a joy to read. For example, take a look at Address manipulation:The colon syntax are a way to express bitfields in C. But the real fun part for me is the idea of control_. What is this for? Well, it runs out that in addition to Address, the also defined AtomicAddress, whose implementation need to provide atomic operation on address. This is implemented in the following manner:I find this a really elegant way to handle this requirement.Another amusing observation is that almost all the code in FASTER is in .h files, because of the heavy use of templates. I wonder how that affects compilation speed and how that would play in larger projects.It is in faster.h that we start to get into the interesting bits. I first run into this guy:This maps pretty closely to what I have actually seen the C# code does, but in C&#x2B;&#x2B; it is a much more natural approach that dynamic compilation on the fly as it did in C#. Next we have the constructor, which looks like this:The epoch_ field is auto initialized by the compiler and is not shown here. This indicates that FASTER can handle up to 2.1 billion entries in total, which seems to be a strange limit for a data store that is expected to handle hundreds of thousands of operations per second. I&#x2019;m going to jump around the codebase a bit, because I want to follow exactly what is going on when initializing this class. The first place to look is the epoch. The idea of epoch is described in the paper, so I&#x2019;m not going to repeat it. The code defines a struct that is 64 bytes in size (cache line sized, to avoid false sharing), this is used to store a thread specific value and is used to maintain most of the invariants of the epoch.When switching between epochs, there are actions that needs to be run, here is what this looks like in the code. I must say, this really mess up with my mind, because we have C#&#x2019;s naming conventions (TryPop, TryPush) in C&#x2B;&#x2B; code. It&#x2019;s like the code couldn&#x2019;t decide what shape it wanted to be in either language.The number of threads that can take part is limited by this value:Right now, this is set to 96, which means that if you need more threads than that, you&#x2019;ll get a runtime error. This fits nicely with the model FASTER uses of long running threads, but I don&#x2019;t see how it can play well with actually accepting commands from network / other location. As part of it&#x2019;s constructor, this method is called, which actually does the real work of setting up the epoch.I&#x2019;m not really sure at this point why it is allocating two additional entries beyond the specified size. When a thread start running FATER code, it needs to register itself with the Epoch, this is done in the Protect() call. Going into the Thread class reveals a simple table of values that are used to give ids to the threads that asked to get an id. This is done in this function:It took me a couple of times of reading the first two lines to understand what is going on here. This is an awesome way to handle a circular buffer scanning. It is very clear and saves a bunch of code ( at the cost of doing mod operation, which can be usually be masked if the value is known at compile time and is a power of 2, which in this case it is not). I&#x2019;m probably going to use this the next time I need to implement scanning through a ring buffer. Then we have computing the earliest safe epoch:The first of these methods is elegant, it does a simple read from the table, reading potentially stale values. This doesn&#x2019;t matter, because the worst thing that can happen is that we&#x2019;ll keep a previous epoch for longer than it is required. The second one reads wrong to me, but I&#x2019;ll have to dig deeper into the C&#x2B;&#x2B; memory model more deeply for this. The problem is that this seems like it is relying on the CPU to update its state somehow. But I don&#x2019;t see any instruction that would force it to. I think that the set to safe_to_reclaim_epoch (which is std::atomic&lt;uint64_t&gt;) will use memory_order_seq_cst for the operation, but I&#x2019;m not sure how that would impact reads from the table_. Also, I want you to pay attention to the variable names here. Private member fields:Public member fields:And then we have SpinWaitForSafeToReclaim that uses:safe_to_reclaim_epoch &#x2013; public member fieldsafe_to_reclaim_epoch_ &#x2013; method argument I&#x2019;m not sure if this a common practice in C&#x2B;&#x2B;, but this is really confusing to me. This is enough for now, I&#x2019;m going to keep going thought the C&#x2B;&#x2B; code in my next post. There hasn&#x2019;t been anything really interesting so far, just digging into the code and getting a feel as to how it is put together.</p>
        </article>
        <article id="article-2278">
            <a href="https://ayende.com/blog/184289-A/reviewing-faster-lets-check-these-numbers" target="_blank">
                <h2 class="title mb-6" id="article-2278">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 29, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Before heading to the C&#x2B;&#x2B; implementation, I thought I would take the time to just walk through the FASTER codebase as it is performing a simple operation. The access violation error that I previously run into has been fixed, so I could run the benchmark. Here is my configuration:I got the following results, when running on a single thread.Total 142,603,719 ops done&#xA0; in 30 secs.This is about 4.7 million operations per second, which is certainly nice. I then decided to compare this to ConcurrentDictionary to see what kind of performance that would give me. I made the following changes, which I&#x2019;ll admit are pretty brute force way to go about it. But note that this is probably significantly less efficient then I could probably write it. Nevertheless, using ConcurrentDictionary with a single thread in the same benchmark gives me:Total 84,729,062 ops done&#xA0; in 30 secs.There isn&#x2019;t much call for using this on a single thread, though. My machine has 20 cores, so let&#x2019;s see what happens when I give FASTER its head, shall we?2,330,054,219 ops done&#xA0; in 30.021 secs.That is impressive, with about 77,668,473 operations per second. On the other hand, this is what happened when I run with 20 threads and ConcurrentDictionary:671,071,685 ops done&#xA0; in 30.024 secs.This gives us &#x201C;only&#x201D; 22,369,056 operations per second. It is clear that FASTER is much better, right? The problem is that it isn&#x2019;t much faster enough. What do I mean by this? I used idiomatic C# for the ConcurrentDictionary usage and got with 1/4 of FASTER&#x2019;s perf. The FATER codebase is doing native calls and unsafe manipulation, dedicated allocation, etc. I expect to get better perf at that point, but &#x201C;merely&#x201D; 400% improvement isn&#x2019;t enough for the kind of effort that was put into this. I run the concurrent dictionary in a sampling profiler, with 20 threads, and I got the following results. On the other hand, using FASTER for the same scenario gives:This is really interesting. You can see that the FASTER option spends all its time in either: InternalUpsert or inside the RunYcsb method (which is actually the store.Read() method that was inlined). What is more interesting is that there are no additional calls there. The InternalUpsert call is 219 lines of code, and the code uses [MethodImpl(MethodImplOptions.AggressiveInlining)] quite aggressively (pun intended). On the other hand, the ConcurrentDictionary implementation has to make virtual method calls on each call. There are several ways to handle this, including using generic struct that can eliminate most of the virtual calls. This is effectively what FASTER is doing, without the generics. FASTER also benefits from pre-allocating everything upfront. If you&#x2019;ll look at the profiler results, you can see that these are the major source of &#x201C;slowness&#x201D; in the benchmark.Given the nature of the benchmark, I feel that it is unfair to compare FASTER to persistent data stores and it should be compared more closely to a concurrent hash map. Given that this is effectively what FASTER is doing in this showcase benchmark, that seems a lot more fair. I checked the literature and we have this paper talking about concurrent hash maps where we see (Figure 2.a) numbers that near to 300 millions ops/sec for pure writes and 600 millions ops/sec for reads.</p>
        </article>
        <article id="article-2279">
            <a href="https://ayende.com/blog/184257-A/reviewing-faster-lets-start-with-managed-code" target="_blank">
                <h2 class="title mb-6" id="article-2279">Reviewing FASTER</h2>
            </a>
            <p class="mb-2">by Oren Eini</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 28, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">Last post commented on the FASTER paper, now I&#x2019;m getting to reading the code. This is a pleasant change of scenery for me, since FASTER is written in C# (there is a C&#x2B;&#x2B; port that I&#x2019;ll also be going through later). As someone who spend most of their time in C#, that make it much easier to go through the code. On the other hand, this was clearly written by someone who spent most of their time in C&#x2B;&#x2B;. This means that naming conventions and the general approach to writing the code sometimes directly contradict C# conventions. Some of that really bugs me.The first thing I did was to try to run the benchmark on my own machine, to get relative numbers. It died with an AccessViolationException, which was a disappointment. I&#x2019;m going to ignore that and just read through the code. One thing that I did noticed when reading through the benchmark code is that this piece:This maps closely to some of the things they mentioned in the paper, where each thread refresh every 256 ops and complete pending operations every 65536 ops. The reason I call this out is that having this done in what effectively is a client code is a bad idea in term of design. The benchmark code is operating under continuous stream of operations and can afford to amortize such things. However, real code need to deal with client code that isn&#x2019;t well behaving and you can&#x2019;t assume that you&#x2019;ll be operating in this kind of environment.Based on the semantics discussed in the paper and what the code is showing me, I would assume that the general model for actually using this is to spawn off a bunch of threads and then listen to some data source. For example, a socket. On each network read, the thread would apply a batch of operations. Note that this means that you have to deal with threads that may be arbitrarily delayed. I would expect that under such a scenario, you&#x2019;ll see a very different performance profile. You won&#x2019;t have all threads working in tandem and staying close to one another. When getting to the code itself, I started with the native portions, trying to figure out what FASTER is doing with the lowest level of the system. It is mostly advanced file operations (things like telling the OS to don&#x2019;t defrag files, allow to allocate disk space without zeroing it first, etc). As far as I can see, this isn&#x2019;t actually being called from the current code, but I assume that they at least tested out this approach. Another native code they have is related to calling __rdtsc(), which they use in the HiResTimer class. This can be replaced completely by the .NET Stopwatch class and I believe that dropping the adv-file-ops and readtsc native projects is possible and straightforward, allowing for a fully managed FASTER impl. Note that it is still using a lot of interop calls, it seems, but at least so far, I think that most of them are not necessary. To be fair, given the way the code is structured, a lot of the native code is about I/O with pointers, which until the Great Spanification in .NET Core was PITA to deal with.In general, by the way, the code reads more as a proof of concept than a production codebase. I notice this in particular with the general approach for errors handling. Here are two examples:This is from the native code, from which it is a PITA to return errors. However, writing to the console from a library is not an error reporting strategy. What really bugged me was this code, from the MallocFixedPageSize code:If there is any error in the process of pinning memory, just ignore it? Leave the memory pinned? Here is another example that made me cringe:Moving on to the CodeGen directory, it gets interesting. The paper talks about dynamic code generation, but I didn&#x2019;t expect to see such wide usage of this. In particular, large sections of the code (13 files, to be exact, over 6000 lines of code) are dynamically loaded, transformed and compiled on the fly when you create the hashtable. I understand the reasoning for this, you want to get the JIT to compile the best possible code that it can for the specific operations you execute. However, this make it pretty hard to follow what is going on there. In particular, code generating code make it harder to follow what end up actually going on. There are also better ways to do it. Either through generic struct parameters to specialize the code or only generating the dedicated connecting methods as needed and not recompiling large portions on the fly. The Device directory isn&#x2019;t really interesting. Mostly pretty trivial I/O operations, so I&#x2019;m not going to discuss it in depth.Next, getting to the Epoch, which was really interesting to read in the paper. The actual implementation raise a few questions. The Epoch value in an 32 bits integer, that means that it will wrap fairly quickly. It looks like the Epoch is bumped every time you need a new page. Given the operations rate that are reported, I would expect it to happen on a regular basis (this is also required for the system to progress properly and sync up). My reading is that wrapping of the Epoch counter will result in Bad Things Going On.There there is this:Size, in this case, is always set to 128. The size of Entry is 64 bytes, this means that this call will allocate 8,320 bytes in Gen0, immediately pin it and never let it go. This is going to result in memory fragmentation. It would be better to allocate this on the Large Object Heap and avoid the issue. In fact, the same issue can be seen in the memory allocation, where the code does:In This case, PageSize is 65,536, however, and given any value except a byte, this will automatically go to the Large Object Heap anyway. I&#x2019;m going to be a bit ungenerous here, but I&#x2019;m not sure if this was intentional or not.I&#x2019;m firmly convinced that this is pure POC code, here is the snippet that finally did it for me, from the BumpCurrentEpoch() code. Note that I don&#x2019;t mind the Thread.Sleep() here, it make sense in context, but the Console.WriteLine cinched the deal for me. This is not something that you can take a use, but something to look at as you implement this properly.I have to say that I find it very hard to go through the code, mostly because it&#x2019;s in C# and there are certain expectations that I have from the code which are routinely violated. I think that I&#x2019;m going to stop reading the C# codebase and switch over to the C&#x2B;&#x2B; implementation. I expect this to be more idiomatic, both because it is the second time this was written and because the people writing the code are clearly more using to writing in C&#x2B;&#x2B;.</p>
        </article>
        <article id="article-2280">
            <a href="https://andrewlock.net/running-smoke-tests-for-asp-net-core-apps-in-ci-using-docker/" target="_blank">
                <h2 class="title mb-6" id="article-2280">Running smoke tests for ASP.NET Core apps in CI using Docker</h2>
            </a>
            <p class="mb-2">by Andrew Lock</p>
            <p class="mb-6 flex gap-1.5">
                    <span>
                        <svg width="1.25rem" fill="currentColor" viewBox="0 0 24 24"
                             xmlns="http://www.w3.org/2000/svg"><path
                                xmlns="http://www.w3.org/2000/svg"
                                d="M12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4ZM2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22C6.47715 22 2 17.5228 2 12ZM12 6C12.5523 6 13 6.44772 13 7V11.5858L15.7071 14.2929C16.0976 14.6834 16.0976 15.3166 15.7071 15.7071C15.3166 16.0976 14.6834 16.0976 14.2929 15.7071L11.2929 12.7071C11.1054 12.5196 11 12.2652 11 12V7C11 6.44772 11.4477 6 12 6Z"></path></svg>
                    </span>
                posted on: August 28, 2018
            </p>
            <p class="max-w-full w-full line-clamp-5 text-justify mb-20">In this post I&#x27;ll describe how to use Docker to run a smoke test as part of a CI build pipeline to check that an ASP.NET Core app is able to start up&#x2026;</p>
        </article>
        <div class="button flex justify-between">
            <a href="227.html"><span class="back arrow"></span></a>

            <a href="229.html"><span class="next arrow"></span></a>
        </div>
    </section>
</main>

<footer
    class="mt-auto flex w-full flex-col items-center justify-center gap-y-2 pb-4 pt-20 text-center align-top font-semibold text-gray-600 dark:text-gray-400 sm:flex-row sm:justify-between sm:text-xs">
    <div class="me-0 sm:me-4">
        <div class="flex flex-wrap items-end gap-x-2">
            <ul class="flex flex-1 items-center gap-x-2 sm:flex-initial">
                <li class="flex">
                    <p class="flex items-end gap-2 justify-center flex-wrap	"> Relatively General
                        .NET 2025<span
                            class="inline-block">&nbsp;&nbsp;Theme: Astro Cactus</span>

                        <a class="inline-block sm:hover:text-link" href="https://github.com/chrismwilliams/astro-cactus"
                           rel="noopener noreferrer " target="_blank">
                            <svg width="1em" height="1em" viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6"
                                 focusable="false" data-icon="mdi:github">
                                <symbol id="ai:mdi:github">
                                    <path fill="currentColor"
                                          d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path>
                                </symbol>
                                <use xlink:href="#ai:mdi:github"></use>
                            </svg>
                            <span class="sr-only">Github</span>
                        </a>
                    </p>
                </li>
            </ul>
        </div>
    </div>
    <nav aria-label="More on this site" class="flex gap-x-2 sm:gap-x-0 sm:divide-x sm:divide-gray-500">
        <a class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="index.html"> Home </a><a
            class="px-4 py-2 sm:py-0 sm:hover:text-textColor sm:hover:underline" href="about.html"> About </a>
    </nav>
</footer>
<script src="js/script.js?id=af8f4559935e7bf5bf6015373793411d"></script>
<script src="/pagefind/pagefind-ui.js"></script>

<!-- Cookie Consent Banner -->
<div class="cookie-consent" id="cookieConsent">
    <div>
        <p class="text-sm">We use cookies to analyze our website traffic and provide a better browsing experience. By
            continuing to use our site, you agree to our use of cookies.</p>
    </div>
    <div class="cookie-consent-buttons">
        <button class="cookie-consent-decline" onclick="declineCookies()">Decline</button>
        <button class="cookie-consent-accept" onclick="acceptCookies()">Accept</button>
    </div>
</div>

<script>
    // Cookie consent management
    function showCookieConsent() {
        const consent = localStorage.getItem('cookieConsent');
        if (!consent) {
            document.getElementById('cookieConsent').classList.add('show');
        }
    }

    function acceptCookies() {
        localStorage.setItem('cookieConsent', 'accepted');
        document.getElementById('cookieConsent').classList.remove('show');
        loadGA(); // Load Google Analytics after consent
    }

    function declineCookies() {
        localStorage.setItem('cookieConsent', 'declined');
        document.getElementById('cookieConsent').classList.remove('show');
    }

    // Show the consent banner only for EU visitors (you can add more country codes as needed)
    fetch('https://ipapi.co/json/')
            .then(response => response.json())
            .then(data => {
                const euCountries = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 'PT', 'RO', 'SK', 'SI', 'ES', 'SE'];
                if (euCountries.includes(data.country_code)) {
                    showCookieConsent();
                } else {
                    // For non-EU visitors, automatically load GA
                    if (!localStorage.getItem('cookieConsent')) {
                        localStorage.setItem('cookieConsent', 'accepted');
                        loadGA();
                    }
                }
            })
            .catch(() => {
                // If we can't determine location, show the consent banner to be safe
                showCookieConsent();
            });
</script>
</body>
</html>
